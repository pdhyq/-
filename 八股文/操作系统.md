# 内存管理

## 虚拟内存

如果每个进程都直接通过物理地址访问内存，进程之间就会相互影响，为每个进程都分配独立的虚拟内存，进程之间互不干涉，由操作系统将虚拟地址转化为物理地址。不同进程之间运行时就不会发生冲突。提升了安全性的同时，也方便进行内存管理。

物理地址和虚拟地址之间的转换依靠MMU组件完成



## 分段

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。**不同的段是有不同的属性的，所以就用分段（*Segmentation*）的形式把这些段分离出来。**

> 一段程序中，不同的代码区域的功能逻辑不同，依据这些将他们分为了不同的段。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。

**地址映射**

通过段表进行映射。虚拟地址包括段号和段内偏移量。具体过程是通过段号查询段表找到该段的起始地址，然后加上偏移量，得到最终的物理地址。

<img src="https://oss.javaguide.cn/github/javaguide/cs-basics/operating-system/segment-virtual-address-composition.png" alt="分段机制下的地址翻译过程" style="zoom:50%;" />

段表中还存有诸如段长(可用于检查虚拟地址是否超出合法范围)、段类型（该段的类型，例如代码段、数据段等）等信息（不仅仅只有图上那些信息）

**缺点：**

* 会导致外部内存碎片：每个段的长度不固定，就产生了多个不连续的小物理内存，导致新的程序无法被装载，所以**会出现外部内存碎片**的问题。内存的资源利用率也就低了

* 内存交换的效率低：因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。

  > [内存覆盖及内存交换-CSDN博客](https://blog.csdn.net/weixin_46269257/article/details/116277738)



## 分页

**分页机制（Paging）** 把主存（物理内存）分为连续等长的物理页，应用程序的虚拟地址空间划也被分为连续等长的虚拟页

在分页机制下，应用程序虚拟地址空间中的任意虚拟页可以被映射到物理内存中的任意物理页上，因此可以实现物理内存资源的离散分配。分页机制按照固定页大小分配物理内存，使得物理内存资源易于管理，可有效避免分段机制中外部内存碎片的问题。

**地址映射**

通过页表进行映射，每个程序都有一个对应的页表。虚拟地址包括页号+页内偏移量。具体过程就是通过页号查询页表找到物理页号，然后加上偏移量找到最后的地址。

<img src="https://oss.javaguide.cn/github/javaguide/cs-basics/operating-system/paging-virtual-address-composition.png" alt="分页机制下的地址翻译过程" style="zoom:67%;" />

页表中还存有诸如访问标志（标识该页面有没有被访问过）、脏数据标识位等信息。

**多级页表：**

> 原因：单级页表意味着所有的页表项都要连续存放在内存中，当一个进程所要占用的虚拟内存过大，页表相应也会更大（ppt）。根据局部性原理可知，很多时候，进程在一段时间内只需要访问某几个页面 就可以正常运行了。因此没有必要让整个页表都常驻内存。所以可以把页表再分页并离散存储



**TLB**

> 本质上是一块高速缓存



**换页机制**

换页机制的思想是当物理内存不够用的时候，操作系统选择将一些物理页的内容放到磁盘上去，等要用到的时候再将它们读取到物理内存中。也就是说，换页机制利用磁盘这种较低廉的存储设备扩展的物理内存。



**请求分页/页缺失**

在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序。 在请求分页系统中，每当要访问的页面不在内存时，便产生一个缺页中断，然 后由操作系统的缺页中断处理程序处理中断。



**页面置换算法**

若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。

* 最佳页面置换算法：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率。该算法无法实现，只是理论最优的页面置换算法，可以作为衡量其他置换算法优劣的标准。
* 先进先出算法：总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
* 时钟页面置换算法：可以认为是一种最近未使用算法，即逐出的页面都是最近没有使用的那个。
* 最少使用页面置换算法：和 LRU 算法比较像，不过该置换算法选择的是之前一段时间内使用最少的页面作为淘汰页。
* 最近最久未使用算法：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。



## 分页机制和分段机制有哪些共同点和区别？

页是信息的物理单位。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管 理上的需要，完全是系统行为，对用户是不可见的。 

段是信息的逻辑单位。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻 辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名。 

页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。 

分页的用户进程地址空间是一维的，程序员只需给出一个记忆符即可表示一个地址。 

分段的用户进程地址空间是二维的，程序员在标识一个地址时，既要给出段名，也要给出段内地址。

分段比分页更容易实现信息的共享和保护。

<img src="img/image-20240526104128900.png" alt="image-20240526104128900" style="zoom: 67%;" />



## 段页机制

结合了段式管理和页式管理的一种内存管理机制，把物理内存先分成若干段，每个段又继续分成若干大小相等的页。

在段页式机制下，地址翻译的过程分为两个步骤：

1. 段式地址映射。
2. 页式地址映射。



## 局部性原理

- **时间局部性**：由于程序中存在一定的循环或者重复操作，因此会反复访问同一个页或一些特定的页，这就体现了时间局部性的特点。为了利用时间局部性，分页机制中通常采用缓存机制来提高页面的命中率，即将最近访问过的一些页放入缓存中，如果下一次访问的页已经在缓存中，就不需要再次访问内存，而是直接从缓存中读取。
- **空间局部性**：由于程序中数据和指令的访问通常是具有一定的空间连续性的，因此当访问某个页时，往往会顺带访问其相邻的一些页。为了利用空间局部性，分页机制中通常采用预取技术来预先将相邻的一些页读入内存缓存中，以便在未来访问时能够直接使用，从而提高访问速度。



# 进程和线程

线程与进程的比较如下：

- 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执行的时间和空间开销；

对于，线程相比进程能减少开销，体现在：

- 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
- 线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
- 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
- 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；

所以，不管是时间效率，还是空间效率线程比进程都要高



区别：

- 线程是进程划分成的更小的运行单位,一个进程在其执行的过程中可以产生多个线程。
- 线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。
- 线程执行开销小，但不利于资源的管理和保护；而进程正相反

有了进程为什么还需要线程?

- 进程切换是一个开销很大的操作，线程切换的成本较低。
- 线程更轻量，一个进程可以创建多个线程。
- 多个线程可以并发处理不同的任务，更有效地利用了多处理器和多核计算机。而进程只能在一个时间干一件事，如果在执行过程中遇到阻塞问题比如 IO 阻塞就会挂起直到结果返回。
- 同一进程内的线程共享内存和文件，因此它们之间相互通信无须调用内核。





















