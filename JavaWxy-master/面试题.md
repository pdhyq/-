## 面试问题

### Java基础

#### 1、WeakHashMap的适用场景

WeakHashMap正是由于使用的是弱引用，因此它的对象可能被随时回收。更直观的说，当使用 WeakHashMap 时，即使没有删除任何元素，它的尺寸、get方法也可能不一样。比如：

（1）调用两次size()方法返回不同的值；第一次为10，第二次就为8了。

（2）两次调用isEmpty()方法，第一次返回false，第二次返回true；

（3）两次调用containsKey()方法，第一次返回true，第二次返回false；

（4）两次调用get()方法，第一次返回一个value，第二次返回null；

是不是觉得有点恶心，这种飘忽不定的东西好像没什么用，试想一下，你准备使用WeakHashMap保存一些数据，写着写着都没了，那还保存个啥呀。

不过有一种场景，最喜欢这种飘忽不定、一言不合就删除的东西。那就是**缓存**，**WeakHashMap 的这个特点特别适用于需要缓存的场景**。在缓存场景下，由于内存是有限的，不能缓存所有对象，因此就需要一定的删除机制，淘汰掉一些对象。（最适合做缓存得应该是软引用）

#### 2、接口与抽象类的区别？
- 一个类只能继承一个抽象类，但可以实现多个接口
- 抽象类可以有构造器，但接口不能有构造器
- 抽象类中可以包含非抽象的普通方法，接口中的所有方法必须都是抽象的
- 抽象类中的抽象方法的访问类型可以是public，protected和默认类型，但接口中的抽象方法只能是public类型的
- 抽象类中的变量的访问类型可以任意，但接口中定义的变量只能是public static final类型
  ————————————————
  原文链接：https://blog.csdn.net/jiong9412/article/details/126730033

#### 3、什么是泛型？

Java泛型是 JDK5 引入的一个新特性。Java 泛型可以使编写的代码被不同的类型对象所复用，使用泛型参数可以增加代码的可读性以及稳定性。

编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型。泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。

**泛型的作用：**

- 使用泛型可在编译期间进行类型检测

- 使用 object 类型需要手动添加强制类型转换，降低代码可读性，提高出错概率

- 泛型可以使用自限定类型如 T extends Comparable

**List<?> 和 List 有区别吗? 当然有!**

- List<?>list 表示 list 是持有某种特定类型的 List，但是不知道具体是哪种类型。因此，我们添加元素进去的时候会报错
- List list 表示 list 是持有的元素的类型是 object ，因此可以添加任何类型的对象，只不过编译器会有警告信息。

```java
List<?> list1 = new ArrayList<>();
list1.add("sss"); // 报错
List list2 = new ArrayList<>();
list2.add("sss"); // 警告信息
```

**? extends xxx  和 ?  super xxx 有什么区别?**

两者接收参数的范围不同。并且，`<? extends Xxx>` 类型使用声明的泛型参数只能调用 `get()` 方法返回 `Xxx` 类型，调用 `set()` 报错。使用 `<? super Xxx>` 声明的泛型参数只能调用 `set()` 方法接收 `Xxx` 类型，调用 `get()` 报错。

上边界通配符指明了父类型，不确定子类型，因此只能从父类取数据，不能存数据；下边界通配符指明了子类型，不确定父类型，因此只能子类存数据，不能子类取数据。

`?` 子类（不确定的子类）可以转换成父类 ， `?` 父类（不确定的父类）不能转换成子类。

```java
public class Main {
    public static void main(String[] args) {
        List<Animal> animals = Arrays.asList(new Mouse(), new Lion());
        List<? extends Animal> animals1 = new ArrayList<>(animals);

        // 上边界通配符指明了父类型，不确定子类型，因此只能从父类取数据，不能存数据
        // 只能保证取到的数据都为 Animal 的子类，当进行添加时，因为是?参数，不确定添加的元素是否为Number的子类
        Animal animal = animals1.get(0);
        // numbers.set(0, new Mouse());     // 报错 Required type:capture of ? extends Animal     Provided:Mouse
        // numbers.add(new Lion());         // 报错 Required type:capture of ? extends Animal     Provided:Lion
        for (Animal animal1 : animals) {
            System.out.println(animal1);
        }

        // 下边界通配符指明了子类型，不确定父类型，因此只能子类存数据，不能子类取数据。
        // 只能保证存储的数据一定为 Animal 类，保证取出来的元素下边界为 Animal，但是不能确定是 Animal 的哪一个父类
        List<? super Animal> animals2 = new ArrayList<>(animals);
        animals2.add(new Tiger());
        animals2.add(new Animal());
        Object number1 = animals2.get(0);
        for (Object o : animals2) {
            System.out.println(o);
        }
    }
}
```



**<T extends Xxx> 和 <? extends Xxx> 又有什么区别?**

`<T extends Xxx>` 用于定义泛型类和方法，擦除后为 Xxx 类型，`<? extends Xxx>` 用于声明方法形参，接收 Xxx 和其子类型。注意，没有 `<T super Xxx` 这种定义法。

**Class<?> 和 Class 的区别?**

直接使用 Class 的话会有一个类型警告，使用 class<?》 则没有，因为 Class 是一人泛型类，接收原生类型会产生警告。

**小结**

<?> 无限制通配符 

<? extends E> extends 关键字声明了类型的上界，表示参数化的类型可能是所指定的类型，或者是此类型的子类

 <? super E> super 关键字声明了类型的下界，表示参数化的类型可能是指定的类型，或者是此类型的父类

 // 使用原则《Effictive Java》

// 为了获得最大限度的灵活性，要在表示 生产者或者消费者 的输入参数上使用通配符，使用的规则就是：生产者有上限、消费者有下限

1. 如果参数化类型表示一个 T 的生产者，使用 < ? extends T>;

2. 如果它表示一个 T 的消费者，就使用 < ? super T>； 
3. 如果既是生产又是消费，那使用通配符就没什么意义了，因为你需要的是精确的参数类型。

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/java/basic/java-basic-x-generic.html

#### 4、HashMap底层链表转红黑树的阈值为什么是8？红黑树转链表为什么是6？

首先出结论：和hashcode碰撞次数的泊松分布有关，主要是为了寻找一种时间和空间的平衡。

红黑树中的 `TreeNode` 是链表中的 `Node` 所占空间的 `2` 倍，虽然红黑树的查找效率为 `o(logN)` ，要优于链表的 `o(N)`，但是当链表长度比较小的时候，即使全部遍历，时间复杂度也不会太高。固要寻找一种时间和空间的平衡，即在链表长度达到一个阈值之后再转换为红黑树。
之所以是 `8`，是因为 `Java` 的源码贡献者在进行大量实验发现，`hash` 碰撞发生 `8` 次的概率已经降低到了 `0.00000006` ，几乎为不可能事件，如果真的碰撞发生了 `8` 次，那么这个时候说明由于元素本身和 `hash` 函数的原因，此时的链表性能已经已经很差了，操作的 `hash` 碰撞的可能性非常大了，后序可能还会继续发生 `hash` 碰撞。所以，在这种极端的情况下才会把链表转换为红黑树，链表转换为红黑树也是需要消耗性能的，为了挽回性能，权衡之下，才使用红黑树，提高性能的，大部分情况下 `hashMap` 还是使用链表。

红黑树转链表的阈值为 `6`，主要是因为，如果也将该阈值设置于 `8`，那么当hash碰撞在 `8` 时，会反生链表和红黑树的不停相互激荡转换，白白浪费资源。中间有个差值 `7 `可以防止链表和树之间的频繁转换。

假设一下：

如果设计成链表个数超过 `8` 则链表转换成树结构，链表个数小于 `8` 则树结构转换成链表，如果 `HashMap` 不停的插入，删除元素，链表个数在 `8` 左右徘徊，就会频繁的发生红黑树转链表，链表转红黑树，效率会很低下。

————————————————
原文链接：https://blog.csdn.net/weixin_45098370/article/details/120660542

​					[解决哈希冲突（四种方法）](https://blog.csdn.net/qq_48241564/article/details/118613312)

#### 5、HashMap头插法为什么改成尾插法？

1、JDK 1.7及之前，为什么采用头插法

　　但有种说法，我觉得挺有道理：缓存的时间局部性原则，最近访问过的数据下次大概率会再次访问，把刚访问过的元素放在链表最前面可以直接被查询到，减少查找次数

2、既然头插法有链表成环的问题，为什么直到 1.8 才采用尾插法来替代头插法

　　只有在并发情况下，头插法才会出现链表成环的问题，多线程情况下，HashMap 本就非线程安全，这就相当于你在它的规则之外出了问题，那能怪谁？

　　1.8 采用尾插，是对 1.7 的优化

3、既然 1.8 没有链表成环的问题，那是不是说明可以把 1.8 中的 HashMap 用在多线程中

　　链表成环只是并发问题中的一种，1.8 虽然解决了此问题，但是还是会有很多其他的并发问题，比如：上秒 put 的值，下秒 get 的时候却不是刚 put 的值；因为操作都没有加锁，不是线程安全的

**总结：**

1、JDK 1.7 采用头插法来添加链表元素，存在链表成环的问题，1.8 中做了优化，采用尾插法来添加链表元素

2、HashMap 不管在哪个版本都不是线程安全的，出了并发问题不要怪 HashMap，从自己身上找原因

链接：https://www.cnblogs.com/youzhibing/p/13915116.html

[图解jdk1.8 HashMap扩容(与jdk1.7重新计算hash方式不同)](https://blog.csdn.net/u012501054/article/details/103710171)

[HashMap jdk1.7 扩容死锁详解](https://blog.csdn.net/lq6812574/article/details/120737903)

#### 6、Kryo序列化算法

**介绍：**

Kryo 是一个快速序列化/反序列化工具，依赖于字节码生成机制（底层使用了 ASM 库)，因此在序列化速度上有一定的优势，但正因如此，其使用也只能限制在基于 JVM 的语言上。

> 网上有很多资料说 Kryo 只能在 Java 上使用，这点是不对的，事实上除 Java 外，Scala 和 Kotlin 这些基于 JVM 的语言同样可以使用 Kryo 实现序列化。

和 Hessian 类似，Kryo 序列化出的结果，是其自定义的、独有的一种格式。由于其序列化出的结果是二进制的，也即 byte[]，因此像 Redis 这样可以存储二进制数据的存储引擎是可以直接将 Kryo 序列化出来的数据存进去。当然你也可以选择转换成 String 的形式存储在其他存储引擎中（性能有损耗）。

Kryo是一个快速且高效的针对Java对象序列化的框架。它的特点：

1. 序列化的性能非常高
2. 序列化结果体积较小
3. 提供了简单易用的API

Kryo序列化被很多开源项目使用，社区非常活跃，版本迭代也比较快。以下的重大项目中都在使用Kryo

- Apache Hive
- Apache Spark
- Twitter's Chill
- Storm
- Dubbo
- akka-kryo-serialization

由此可见Kryo的确具有很大的优势。但是Kryo是针对Java Object的序列化，对于跨语言方面是不支持的，但是很多场景中比如RPC，Cache，Store场景中一般很少需要对跨语言的支持。因此，Kryo的适用场景也很不错。

**类注册：**

和很多其他的序列化框架一样，Kryo为了提供性能和减小序列化结果体积，提供注册的序列化对象类的方式。在注册时，会为该序列化类生成int ID，后续在序列化时使用int ID唯一标识该类型。

```java
kryo.register(SomeClassA.class);
kryo.register(SomeClassB.class);
```

**线程不安全：**

由于Kryo线程不安全, 意味着每次序列化和反序列化时都需要实例化一次, 或借助ThreadLocal或者对象池来维护以保证其线程安全。

---

链接：https://zhuanlan.zhihu.com/p/397396143

----

Kryo是一种快速、高效的Java对象序列化框架，其原理主要包括对象图遍历、类注册和二进制编码。

对象图遍历：Kryo通过遍历待序列化对象的对象图来获取对象的状态。对象图表示对象及其相关引用的图形结构，通常是一个有向无环图。Kryo使用深度优先搜索算法来遍历对象图，以便获取所有相关对象的状态。

类注册：在进行对象序列化之前，Kryo需要将每个待序列化的类注册到其内部的类注册表中。类注册表维护着类与其相应的序列化/反序列化器之间的映射关系。注册类可以有效减小序列化后的数据大小，并提高序列化/反序列化的性能。

二进制编码：一旦对象图遍历完成并且所有相关的类都已注册，Kryo将根据对象的状态生成相应的二进制编码。二进制编码采用了紧凑的格式，通常包括对象的类信息、字段名称和对应的值。Kryo提供了多种序列化方法，如直接序列化到字节数组、序列化到输出流等。

在反序列化时，Kryo根据二进制编码中的类信息，从类注册表中获取相应的类，并使用对象的构造函数创建对象。然后，Kryo根据二进制编码中的字段信息，将对应的值设置到对象的相应字段中，最终完成对象的反序列化过程。

总的来说，Kryo通过对象图遍历、类注册和二进制编码来实现对象的高效序列化和反序列化。它在性能方面表现出色，并且支持自定义序列化器，以满足不同的序列化需求。

---

Kryo类注册的作用是告诉Kryo序列化框架在序列化和反序列化过程中如何处理特定的Java类。它具有以下几个主要作用：

1. 类映射：通过类注册，Kryo能够建立类与其唯一标识符之间的映射关系。在序列化时，Kryo可以使用类的唯一标识符来表示该类，而不是完整的类名。这样可以减小序列化后的数据大小，提高序列化性能。

2. 提高性能：类注册可以显著提高序列化和反序列化的性能。当Kryo遇到待序列化对象时，它首先检查该对象的类是否已经注册。如果已经注册，则Kryo可以直接使用已知的类信息进行序列化和反序列化操作，而无需再去解析和查找类。这样可以节省时间并降低开销。

3. 解决循环引用：在对象图中存在循环引用的情况下，类注册对于正确序列化和反序列化非常重要。通过注册相关的类，Kryo可以跟踪对象之间的引用关系，并正确处理循环引用，从而避免出现无限递归或栈溢出的情况。

4. 支持多态类型：对于具有继承关系的类，类注册可以确保Kryo能够正确地处理这些多态类型。通过注册所有相关的子类和父类，Kryo可以根据对象的实际类型来进行序列化和反序列化，而不会丢失类型信息。

综上所述，Kryo类注册的作用是建立类与其唯一标识符之间的映射关系，提高序列化和反序列化的性能，解决循环引用问题，并支持多态类型的序列化和反序列化。它是使用Kryo进行高效、快速对象序列化和反序列化的重要步骤。

---

Protostuff是一种高性能的Java序列化框架，它基于Google Protocol Buffers（简称protobuf）协议，并进行了改进和优化。下面是Protostuff序列化的原理：

1. 类注册：和其他序列化框架类似，Protostuff在序列化之前需要进行类注册。类注册的目的是告知Protostuff待序列化和反序列化的Java类的信息，包括字段名称、类型以及相应的顺序。

2. 编码过程：在序列化时，Protostuff首先会根据类的注册信息创建一个Schema对象，该Schema对象描述了待序列化的类的结构。接着，Protostuff将要序列化的对象与Schema进行匹配，依次遍历对象的字段，并将每个字段的值编码为字节序列。

3. 字段编码：对于每个字段，Protostuff使用适当的编码策略将其转换为字节序列。Protostuff提供了多种编码策略，例如Varint、Fixed32、Fixed64以及Length-delimited等，它们可以根据字段类型、大小和语义的不同选择合适的编码方式。

4. 压缩：在编码过程中，Protostuff还支持对字段进行压缩。通过使用压缩算法（如LZ77或Huffman编码），Protostuff可以减小序列化后的数据大小，从而提高网络传输效率和存储空间利用率。

5. 解码过程：在反序列化时，Protostuff使用Schema对象来解析字节序列。它根据Schema中定义的字段顺序逐个读取字节，并将其解码为对应的Java对象。在解码过程中，Protostuff会根据编码策略进行相应的解码操作，将字节序列转换为正确的数据类型和值。

通过以上步骤，Protostuff实现了高效的对象序列化和反序列化。它在性能上表现出色，具有较小的序列化后的数据大小和较快的序列化速度。同时，Protostuff还支持动态和静态模式，可以根据需要选择最适合的使用方式。

---

Kryo和Protostuff是两种不同的Java序列化框架，它们在实现方式、性能、使用场景和侧重点等方面存在一些区别。下面是它们之间的主要区别：

1. 实现方式：Kryo是基于Java对象图的序列化框架，通过直接访问对象的字段来进行序列化和反序列化。而Protostuff是基于Google Protocol Buffers协议的序列化框架，使用Schema对象描述待序列化类的结构，并将对象的字段值编码为字节序列。

2. 性能：Kryo和Protostuff都是高性能的序列化框架，但在某些特定场景下它们的性能可能有所差异。一般情况下，Kryo的序列化速度较快，适合对大量数据进行频繁的序列化和反序列化操作；而Protostuff在序列化后的数据大小和网络传输效率方面表现较好，特别适用于网络通信和存储等场景。

3. 使用场景：由于Kryo是基于对象图的序列化框架，它对于非常复杂的对象结构和嵌套对象的处理更加方便和高效。因此，在需要序列化复杂对象或者具有继承等特殊结构的场景下，Kryo是一个不错的选择。而Protostuff适用于对数据进行高效压缩和网络传输的场景，尤其是对于数据结构相对简单、字段数量较少的情况。

4. API使用方式：Kryo的API相对较为简单和直观，可以直接操作Java对象，通过注册类即可进行序列化和反序列化。而Protostuff使用起来稍微复杂一些，需要先定义Schema对象描述类的结构，然后通过RuntimeSchema将Schema与实际类实例关联起来，最后使用Protostuff进行序列化和反序列化。

5. 兼容性：由于Kryo和Protostuff采用不同的序列化算法和编码方式，它们之间的序列化格式是不兼容的。这意味着使用Kryo序列化的数据无法直接使用Protostuff进行反序列化，反之亦然。因此，在使用中需要注意选择合适的序列化框架并保持一致。

综上所述，Kryo和Protostuff在实现方式、性能、使用场景和API使用方式等方面存在一些区别。具体选择哪个框架应根据实际需求和场景来决定。

#### 7、什么是菱形继承？

两个子类继承同一个父类而又有子类同时继承这两个子类。

<img src="asset\菱形继承.png" alt="image-20220104152325761" style="zoom:50%;" />

```java
public class DiamondInheritanceDemo {
    public static void main(String[] args) {
        GrandFather son = new Son();
        son.say();
    }

    interface GrandFather {
        default void say() {
            System.out.println("GrandFather say.");
        }
    }

    interface Father1 extends GrandFather {
        @Override
        default void say() {
            System.out.println("Father1 say.");
        }
    }

    interface Father2 extends GrandFather {
        @Override
        default void say() {
            System.out.println("Father2 say.");
        }
    }

    // 编译报错：Son inherits unrelated defaults for say() from types Father1 and Father2
    // 运行报错：java: 类 Son从类型 Father1 和 Father2 中继承了say() 的不相关默认值
    static class Son implements Father1, Father2 {
        
    }
}
```

判断标准是什么

- 类方法优先级最高。类或父类中声明的方法的优先级高于任何声明为默认方法的优先级。

  - ```java
    public class Son implements Father1,Father2{
        @Override
        public void say() {
            System.out.println("hello,I'm Son");
        }
    }
    ```

- 函数签名相同时，优先选择拥有最具体实现的默认方法的接口。

  - ```java
    public class Son implements Father1{
    	
    }
    ```

- 继承多个接口的类必须通过显示覆盖和调用期望方法，显示指定使用哪一个方法的实现。

  - ```java
    public class Son implements Father1,Father2{
    
        @Override
        public void say() {
            Father2.super.say();
        }
    }
    ```

对于Java而言，我们无需担心代码会有[菱形继承](https://so.csdn.net/so/search?q=菱形继承&spm=1001.2101.3001.7020)问题，不解决菱形继承问题，是无法通过编译阶段的！

#### 8、0.1 + 0.2 = 0.3 ？

不是的，0.1 和 0.2 这两个数字用二进制表达会是一个一直循环的二进制数，比如 0.1 的二进制表示为 0.0 0011 0011 0011… （0011 无限循环)，对于计算机而言，0.1 无法精确表达，这是浮点数计算造成精度损失的根源。

因此，IEEE 754 标准定义的浮点数只能根据精度舍入，然后用「近似值」来表示该二进制，那么意味着计算机存放的小数可能不是一个真实值。

0.1 + 0.2 并不等于完整的 0.3，这主要是因为这两个小数无法用「完整」的二进制来表示，只能根据精度舍入，所以计算机里只能采用近似数的方式来保存，那两个近似数相加，得到的必然也是一个近似数。

主要是**因为有的小数无法可以用「完整」的二进制来表示，所以计算机里只能采用近似数的方式来保存，那两个近似数相加，得到的必然也是一个近似数**。

#### 9、Exception 和 Error 的区别？

在Java中，Exception和Error都是继承自Throwable类的子类。它们之间的主要区别在于：

1. Exception通常是由程序执行过程中出现了某种异常情况导致的，例如输入错误或网络连接中断等。这些异常情况可以被捕获并处理，以避免程序崩溃或出现其他不良后果。
2. Error则通常表示系统内部错误或资源不足等问题，例如OutOfMemoryError（内存不足）、StackOverflowError（栈溢出）等。这些问题通常不能被程序本身所解决，而需要操作系统或虚拟机来进行处理。

总的来说，Exception表示可预见的、可处理的异常，而Error则表示不可恢复的错误或系统故障。因此，在编写代码时，应该尽量避免抛出Error，并且尽可能处理所有的异常情况。

Java中一些常见的Error包括：

1. OutOfMemoryError：当JVM无法为新对象分配内存时会抛出此错误。
2. StackOverflowError：当方法调用栈溢出时会抛出此错误。
3. NoClassDefFoundError：当一个类在编译时存在但在运行时找不到时会抛出此错误。
4. AssertionError：当断言语句失败时会抛出此错误。
5. UnsatisfiedLinkError：当一个本地方法库无法加载时会抛出此错误。

需要注意的是，这些Error通常在代码中不会被直接捕获和处理，而是应该通过优化代码或增加系统资源来解决。

#### 10、Java 的 mock

Java的mock是一种测试技术，用于在单元测试中模拟依赖对象的行为。这种技术可以通过创建虚拟对象来模拟真实对象的行为，从而减少对真实对象的依赖性。

使用mock对象，可以在测试过程中模拟依赖对象的行为，例如模拟数据库或网络请求，并在测试中使用这些模拟对象代替真实对象，以便更好地控制测试环境和结果。Mock对象通常可根据需要返回特定值、抛出异常等。

Java中有多个mock框架可供选择，例如Mockito和EasyMock。这些框架提供了丰富的API和方法，用于创建和配置mock对象，并支持验证mock对象的行为和交互。

#### 11、什么是热部署？

热部署指的是在应用程序运行时，不需要重新启动应用程序就可以更新或者替换某些组件或者代码。通过热部署，我们可以在应用程序运行过程中实时地修改和调试代码，而不需要停止和重新启动整个应用程序，这样可以极大提高开发和调试的效率。

热部署主要有两种方式：一种是基于类加载器的热部署，另一种是基于模块化系统的热部署。

**基于类加载器的热部署**是指在应用程序运行时，通过自定义的类加载器，动态加载新的类文件并替换旧的类文件，从而实现热部署。但是这种方式存在一定的局限性，例如无法替换静态变量、方法签名等。

**基于模块化系统的热部署**则通过将应用程序分解成多个独立的模块，在运行时动态地安装、卸载、更新模块，从而实现热部署。相比于基于类加载器的热部署，基于模块化系统的热部署更为灵活，并且可以支持更广泛的场景。

基于类加载器的热部署：

> 基于类加载器的热部署是一种常见的技术，可以在应用程序运行时动态地替换某些类的实现，从而达到热更新的效果。它的基本原理是通过创建一个新的类加载器来加载新的类文件，并替换旧的类加载器，从而使得应用程序能够使用最新的代码。
>
> 下面是基于类加载器的热部署的一些细节：
>
> 1. 类加载器的层次结构
>
> Java 中的类加载器具有层次结构，一般情况下子类加载器都会优先委派给父类加载器进行加载。因此，在进行热部署时，需要创建一个新的类加载器，并将其设置为要替换的类的父类加载器，这样新的类就能优先被加载。
>
> 2. 保证类的唯一性
>
> 不同的类加载器之间可能会出现类的重复加载问题，因此在热部署时需要特别注意类的唯一性。一般来说，可以通过自定义类加载器，并覆盖其中的 `findClass()` 方法，在加载类时判断该类是否已经被加载过了。如果已经加载过，则直接返回已加载的类；否则继续从磁盘中加载最新的类文件。
>
> 3. 避免内存泄漏
>
> 由于类加载器本身也是 Java 对象，因此在进行热部署时需要特别注意内存泄漏问题。一般来说，可以通过使用弱引用或者软引用等方式来管理类加载器对象，从而及时释放不再使用的类加载器。
>
> 4. 对静态变量的影响
>
> 由于静态变量是跟类绑定的，因此在热部署时需要特别注意对静态变量的影响。如果新的类文件中修改了静态变量的值，那么旧的类加载器加载的类仍然会使用旧的值，而新的类加载器加载的类则会使用新的值。因此，在热部署时需要特别注意对静态变量的修改，以免导致程序出现异常。
>
> 基于类加载器的热部署虽然比较灵活，但也存在一些限制。例如，它不能替换某些特殊的类（如 Java 核心类库），也不能替换某些被 JVM 缓存的类。因此，在实际应用中需要结合具体的情况来选择适合的热更新方案。

----

故事进展 :

- 总公司需要临时核算工资。程序员改了jar包后无法及时生效，需要重启OA系统。

- 如何实现关键代码的热加载 ?

解决思路 :

- 无法操作ClassLoader的缓存，那就直接创建一个新的出来。

拓展思考

- 热加载机制到底是好是坏?

  - 运行过程中创建多个ClassLaoder实例，会产生大量的垃圾对象，增加GC线程的压力。
  - 测试时，直接调试java代码的方法: JRebel操作加载器中的类缓存。Arthas。


故事进展:

- XBIUCA三不小心在OA系统中其他人在某一次调试过程仲留下一个SalaryCaler类，热加载全部失效了?

解决思路:

-  双亲委派机制使得每次加载的都是AppClassLoader中的类，打破双亲委派，使用自己的类加载器中的类。

拓展思考

- 如何打破双亲委派? 打破双亲委派后，加载了多少个类?
- 同一个类在多个类加载器中有不同的副本，如何把这此副本都拿出来?

#### 12、为什么有了字节流还要有字符流？

Java中提供了字节流和字符流两种I/O流，虽然字节流可以读写任意类型的数据，包括纯文本，但是字符流更适合处理文本数据。

原因如下：

1. 字节流以字节为单位进行读写，对于文本文件中的字符数据（例如Unicode编码），需要额外处理才能得到完整的字符信息，操作较为繁琐。

2. 字符流则直接以字符为单位进行读写，避免了解析和转换过程，方便快捷。

3. 字符流支持缓冲，可以减少访问磁盘或网络等数据源的次数，提高效率。

4. 对于国际化环境，字符流可以很好地处理不同字符集的文本数据，而字节流则需要自行实现字符集转换，较为复杂。

综上所述，字符流比字节流更适合处理文本数据，在实际开发中也建议优先使用字符流。

----

不管是文件读写还是网络发送接收，信息的最小存储单元都是字节。 **那为什么 I/O 流操作要分为字节流操作和字符流操作呢？**

个人认为主要有两点原因：

- 字符流是由 Java 虚拟机将字节转换得到的，这个过程还算是比较耗时。
- 如果我们不知道编码类型就很容易出现乱码问题。

------

著作权归所有 原文链接：https://javaguide.cn/java/io/io-basis.html

#### 13、CopyOnWrite

Copy-On-Write (COW) 是一种并发编程中的优化技术，主要用于读多写少的场景。它的核心思想是在进行写操作时，不直接修改原始数据，而是创建一个新的副本进行修改，从而实现读写的并发性。

Copy-On-Write 的优点：
1. 线程安全：Copy-On-Write 数据结构在写操作时创建了新的副本，不会影响原始数据，因此可以实现多线程的并发安全性，无需加锁或使用其他同步机制。
2. 高效的读操作：由于读操作不需要加锁，读取原始数据的性能非常高。多个线程可以同时读取数据，不会发生冲突。
3. 降低写操作的开销：由于写操作是在副本上进行的，不会影响原始数据，因此可以避免复制整个数据结构的开销，只需要复制修改的部分数据。

Copy-On-Write 的缺点：
1. 内存消耗：由于每次写操作都会创建一个新的副本，如果写操作频繁或数据量较大，会占用较多的内存空间。
2. 写操作延迟：由于每次写操作都需要复制数据，因此写操作的延迟较高。在写操作频繁的场景下，性能可能会受到影响。
3. 不适用于实时数据：由于每次写操作都需要复制数据，因此对于实时性要求较高的数据，Copy-On-Write 可能无法满足要求。

Copy-On-Write 的应用场景：
1. 配置信息：对于静态的配置信息，多个线程可以同时读取，而且很少修改。使用 Copy-On-Write 可以提供高效的读取操作和线程安全性，例如 Nacos。
2. 缓存：在缓存场景中，读操作通常比写操作频繁。使用 Copy-On-Write 可以提供高效的读取和线程安全性，同时降低写操作的开销。
3. 观察者模式：在观察者模式中，多个观察者可能同时读取被观察对象的状态。使用 Copy-On-Write 可以提供高效的读取和线程安全性。
4. 不可变数据：对于不可变数据结构，任何修改操作都会返回一个新的副本。Copy-On-Write 可以提供线程安全性和高效的读操作。

需要注意的是，Copy-On-Write 适用于读多写少的场景，当写操作频繁或数据量过大时，可能不适合使用 Copy-On-Write，因为复制数据的开销会变得很高。在选择使用 Copy-On-Write 时，需要根据具体的场景和需求进行评估。

---

CopyOnWrite 是它的马甲 底层实现采用了 写入时拷贝 的思想，增删改操作会将底层数组拷贝一份，更改操作在新数组上执行，这时不影响其它线程的**并发读**，**读写分离**。

适合『读多写少』的应用场景。

get 和 迭代 都是弱一致性，得弱一致性就不好

- 数据库的 MVCC 都是弱一致性的表现
- 并发高和一致性是矛盾的，需要权衡

#### 14、Java中内存泄漏的场景

Java中可能导致内存泄漏的场景包括：

1. 对象被无意中持续引用，导致垃圾回收器无法清理它们
2. 静态集合类（如HashMap、ArrayList、ThreadLocal）在不再使用时未进行清除操作，导致其中的对象无法被释放
3. 线程池未正确关闭，导致线程对象一直存在于内存中
4. 资源未正常关闭，如数据库连接、文件流等
5. 大量创建临时对象或频繁创建匿名内部类，导致内存占用过高
6. 内存泄漏相关的第三方库或框架问题
7. 使用缓存时没有设置合适的过期时间或缓存清理机制，导致缓存中的对象一直存在，无法被释放。
8. 内部类持有外部类的引用，导致外部类无法被垃圾回收机制回收。
9. 在大量使用反射、动态代理等技术时，如果不小心产生了大量无用的代理对象，就会导致内存泄漏。

为了避免内存泄漏，需要注意及时释放不再使用的对象和资源，并进行代码优化和测试。

#### 15、Java的标记接口

**Java 标识接口**

标识接口是没有任何方法和属性的接口，它仅仅表明它的类属于一个特定的类型，供其他代码来测试允许做一些事情。

使用标记接口的唯一目的是使得可以用 **instanceof** 进行类型查询，例如：

```
if(obj instanceof Cloneable) {………} 
```

一些容器例如 Ejb 容器，servlet 容器或运行时环境依赖标记接口识别类是否需要进行某种处理，比如 serialialbe 接口标记类需要进行序列化操作。

- **java.io.Serializable**：未实现此接口的类将无法使其任何状态序列化或反序列化。为保证 serialVersionUID 值跨不同 java 编译器实现的一致性，序列化类必须声明一个明确的 serialVersionUID 值。
- **java.lang.Cloneable**：表明 Object.clone() 方法可以合法地对该类实例进行按字段复制.实现此接口的类应该使用公共方法重写 Object.clone（它是受保护的）。如果在没有实现 Cloneable 接口的实例上调用 Object 的 clone 方法，则会导致抛出 CloneNotSupportedException 异常。
- **java.util.RandomAccess**：用来表明其支持快速（通常是固定时间）随机访问。此接口的主要目的是允许一般的算法更改其行为，从而在将其应用到随机或连续访问列表时能提供良好的性能。
- **java.rmi.Remote**：Remote 接口用于标识其方法可以从非本地虚拟机上调用的接口。任何远程对象都必须直接或间接实现此接口。只有在“远程接口”（扩展 java.rmi.Remote 的接口）中指定的这些方法才可远程使用。

#### 16、为什么jdk动态代理只能代理接口？

是因为JDK动态代理本身机制决定的，首先在java里面动态代理是 `Proxy.newProxyInstance()`这个方法来实现的，它需要传入被动态代理的一个接口类，还是取决于JDK动态代理的的一个底层实现，JDK动态代理会在程序运行期间，去动态生产一个代理类，叫`$ProxyO`,那么这个动态生成的代理类会去继承一个 `java.lang.reflect.Proxy`这样一个**类**，同时还会去实现被代理类的接口，在java里面不支持多种继承的，而每个动态代理都继承一个Proxy，所以就导致的JDK里面的动态代理只能代理接口，而不能代理实现类。

#### 17、缓冲池

```java
数字缓冲池：-128~127
Integer a = new Integer(1), b = new Integer(1);
System.out.println(a == b); // false

Integer a = new Integer(1), b = 1;
System.out.println(a == b); // false

Integer a = 1, b = 1;
System.out.println(a == b); // true

-----

short s = 1;
s++; // true
s += 1; // true
s = s + 1; // false
```

#### 18、线程安全的集合

线程安全的集合有 `Vector、HashTable、Stack、ArrayBlockingQueue、ConcurrentHashMap、ConcurrentLinkedQueue` 等。

Vector相当于 ArrayList 的翻版，是长度可变的数组，Vector的每个方法都加了 synchronized 修饰符，是线程安全的。

Hashtable是一个线程安全的集合,是单线程集合，它给几乎所有public方法都加上了synchronized关键字。

Stack继承于Vector， 栈是后进先出的。

ArrayBlockingQueue是一个阻塞队列,底层使用数组结构实现,按照先进先出(FIFO)的原则对元素进行排序。

ConcurrentHashMap 采用了分段锁(Segment)，HashTable的加锁方法是给每个方法加上synchronized关键字，线程安全。

ConcurrentLinkedQueue是一种FIFO的无界队列，是线程安全的，它适用于“高并发”的场景。

#### 19、红黑树

**性质：**

红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。

性质1. 节点是红色或黑色。

性质2. 根节点是黑色。

性质3. 所有叶子都是黑色。（叶子是NUIL节点）

性质4. 每个红色节点的两个子节点都是黑色。（从每个叶子到根的所有路径上不能有两个连续的红色节点）

性质5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

<img src="asset\红黑树.png" alt="在这里插入图片描述" style="zoom:80%;" />

**插入**

`红黑树规定，插入的节点必须是红色的。而且，二叉查找树中新插入的节点都是放在叶子节点上。`所以，关于插入操作的平衡调整，有这样两种特殊情况，但是也都非常好处理。

1. 如果插入节点的父节点是黑色的，那我们什么都不用做，它仍然满足红黑树的定义。

2.　如果插入的节点是根节点，那我们直接改变它的颜色，把它变成黑色就可以了。

3. 其他：都会违背红黑树的定义，于是我们就需要进行调整，调整的过程包含两种基础的操作：左右旋转和改变颜色。

<img src="asset\红黑树插入流程.png" alt="在这里插入图片描述" style="zoom: 80%;" />

<img src="asset\红黑树节点关系.png" alt="在这里插入图片描述" style="zoom:80%;" />

**删除**

删除操作的平衡调整分为两步，第一步是针对删除节点初步调整。初步调整只是保证整棵红黑树在一个节点删除之后，仍然满足最后一条定义的要求，也就是说，每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；第二步是针对关注节点进行二次调整，让它满足红黑树的第三条定义，即不存在相邻的两个红色节点。

1. 针对删除节点初步调整
红黑树的定义中“只包含红色节点和黑色节点”，经过初步调整之后，为了保证满足红黑树定义的最后一条要求，有些节点会被标记成两种颜色，“红 - 黑”或者“黑 - 黑”。如果一个节点被标记为了“黑 - 黑”，那在计算黑色节点个数的时候，要算成两个黑色节点。

这里具体有：三种情况

2. 针对关注节点进行二次调整
经过初步调整之后，关注节点变成了“红 - 黑”或者“黑 - 黑”节点。针对这个关注节点，我们再分四种情况来进行二次调整。二次调整是为了让红黑树中不存在相邻的红色节点。

这里具体有：四种情况

**提问：**

1. 如何理解红黑树定义的＂任何相邻的节点都不能同时为红色＂？
      如果一个结点是红色的，则它的两个孩子都是黑色的．也就是说只要用线连起来的都不能同时是红色

2. 如何理解红黑树定义的＂每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点； ＂？
      nullptr ．

3. 为什么插入的节点偏偏是红色呢？

   将插入的结点着色为红色，不会违背 “性质 4”。而少违背一条性质，就意味着我们需要处理的情况越少。

4. 为什么红黑树的定义中，要求叶子节点是黑色的空节点？或者说是到底那里方便了？

   只要满足这一条要求，那在任何时刻，红黑树的平衡操作都可以归结为上面的那几种情况。而且是简洁的．

5. 给红黑树添加黑色的空的叶子节点，会不会比较浪费存储空间呢?

<img src="asset\红黑树存储空节点.png" alt="在这里插入图片描述" style="zoom: 67%;" />

[红黑树实现原理](https://blog.csdn.net/liushengxi_root/article/details/86073971)

主：[红黑树原理简单解析](https://blog.csdn.net/huangwen001/article/details/119799167)

#### 20、Java8新特性

1、Lambda表达式；

2、函数式接口（@FunctionInterface）

3、泛型创建时不需要指定后部分类型

4、接口的默认实现 default

5、Stream流

6、Optional工具类

7、Date API 和 Base 64编码

8、Annotation 支持多重注解

1. **Lambda 表达式**

```java
lambda表达式是一个匿名函数，允许把函数作为一个方法的参数（函数作为参数传递进方法中，可以传递的代码），
使用Lambda 表达式可以使代码变的更加简洁紧凑。
 案例1 Runable - ①无参数无返回值
   // 普通写法
 	Runnable r1 = new Runnable() {
            @Override
            public void run() {
                System.out.println("普通使用");
            }
        };
	// lambda表达式写法  
    Runnable r2 = ()-> System.out.println("lambda表达式使用");
    
 案例2 比较 - ②有参数无返回值
	// 普通写法
 	Comparator<Integer> comparator = new Comparator<Integer>() {
            @Override
            public int compare(Integer o1, Integer o2) {
                return Integer.compare(o1,o2);
            }
        };
        int compare = comparator.compare(12, 21);
        
    //lambda表达式写法    
 	 Comparator<Integer> comparator = (o1,o2)-> Integer.compare(o1,o2);
        int compare = comparator.compare(32,23);
        //③两个或以上的参数，多条执行语句，并且可以有返回值
      Comparator<Integer> comparator = (o1,o2)-> { 
         System.out.println(o1);
        return Integer.compare(o1,o2);};

        
  案例3  Consumer - ④有参数有返回值
     // 普通写法
	 Consumer<String> consumer = new Consumer<String>() {
            @Override
            public void accept(String s) {
                System.out.println(s);
            }
        };
        consumer.accept("普通写法");
        
     //lambda表达式写法    
	 Consumer<String> consumer = (String s)->{System.out.println(s);}；
        consumer.accept("lambda表达式使用");
        //⑤只有一个参数时候小括号可以省略 ⑥只有一条语句时，return与大括号若有，都可以省略
     Consumer<String> consumer = s->{System.out.println(s);}
```

2. **Stream流**

```java
Stream 中文称为 “流”，通过将集合转换为这么一种叫做 “流” 的元素序列，通过声明性方式，能够对集合中的每个元素进行一系列并行或串行的流水线操作。
流与集合的区别
	1.流为特定元素类型的序列值提供接口。但是，与集合不同，流实际上并不存储元素。元素是按需计算的。可以将流视为延迟构造的Collection，可以在需要它们时计算其值。
	2.流操作不会更改其源。相反，它们返回存储结果的新流。
	3.可能无界。集合的大小是有限的，但是流没有。诸如limit（n）或findFirst（）之类的短路操作可以允许对无限流的计算在有限时间内完成。
	4.消耗品。在流的生存期内，流的元素仅被访问一次。如果要重新访问流中的同一元素，则需要根据源重新生成新的流。
中级运营与终端运营
	中间操作将一个流转换为另一流，而终端操作则产生结果。在流上执行终端操作时，将无法再使用该流。
例如，在下面的代码中：
list.stream().filter(s -> s.length() > 2).count();
filter（）是中间操作，而count（）是终端操作。调用count（）时，我们不能再使用该流
常用的中间操作包括：
	筛选，映射，不同，排序，跳过，限制，flatMap
常用的终端操作包括：
	1. forEach，toArray，收集，减少，计数，最小，最大
	2. findFirst，findAny，anyMatch，allMatch，noneMatch
参考自:https://blog.csdn.net/pjh88/article/details/119672779
基本应用：
	1.filter 过滤出年龄大于20的用户
	List<User> users = new ArrayList<>();
	var targetUsers = users.stream().filter(user -> user.getAge()>20).collect(Collectors.toList());
	2.sorted 排序 按照年龄大小排序
	List<User> users = new ArrayList<>();
	var targetUsers = users.stream().sorted(Comparator.comparing(User::getAge())).collect(Collectors.toList());
	3.map 将流中的每一个元素 T 映射为 R（类似类型转换） 将用户信息转成用户名称集合
	var userNames= users.stream().map(User::getName()).collect(Collectors.toList());
	4.distinct() 去重
	var userNames= users.stream().map(User::getName()).distinct().collect(Collectors.toList());
	5.limit 延迟方法，截取Stream流中的前几个元素返回新的Stream流，入参为long类型，没有方法体,若入参的值大于Stream流中的数据的长度则返回由原数据组成的新Stream流
	 users.stream().limit(3).forEach(user -> System.out.println(user.getName()));
	6.concat Stream的静态方法，将多个Stream流的数据按入参顺序合并为一个新的Stream流
	   Stream<String> st1 = Stream.of("aa","bb","cc","dd","ee");
       Stream<String> st2 = Stream.of("AA","BB","CC","DD","EE");
       Stream<String> st3 = Stream.concat(st1,st2);
    7.skip 延迟方法，入参为long类型，没有方法体，跳过前一个Stream流的前几个元素，得到由后面的元素组成的新Stream流
       Stream<String> st1 = Stream.of("aa","bb","cc","dd","ee");
       st1.skip(2).forEach(str -> System.out.println(str));
    8.count 最终方法，没有参数，没有方法体，属于Stream流的最终方法，用于统计Stream流中的数据长度，返回long类型
      long count = users.stream().count();
    9.foreach() 遍历
      users.steam().foreach(user -> user.setCompany("xxx公司"));
    10.flatMap() 将流中的每一个元素 T 映射为一个流，再把每一个流连接成为一个流
      List<String> list = new ArrayList<>();
	  list.add("aaa bbb ccc");
	  list.add("ddd eee fff");
	  list.add("ggg hhh iii");
	  list = list.stream().map(s -> s.split(" ")).flatMap(Arrays::stream).collect(toList());
	 11.groupingBy() 分组
	   Map<Integer,List<User>> =  users.stream().collect(Collectors.groupingBy(User::getSex));
	 12.anyMatch() 有一个匹配则返回true   
	   boolean flag = user.stream().anyMatch(user-> user.getAge() == 25); 
	 13.noneMatch() 没有一个匹配则返回true  
	   boolean flag = user.stream().noneMatch(user-> user.getAge() == 25);
	 14.mapToDouble()/mapToLong()/mapToInt() + sum() 转成double并求值
	   double ageSum = user.stream().mapToDouble(User::getAge()).sum();
	 15.max() + min() + ifPresent() 特殊函数 如果匹配则执行ifPresent()中的函数
	   users.stream().min(Comparator.comparing(User::getAge()).ifPresent(user->  System.out.println("最小年龄的用户为："user.getName()));
	   users.stream().max(Comparator.comparing(User::getAge()).ifPresent(user->  System.out.println("最大年龄的用户为："user.getName()));
	  16.reduce() reduce 操作可以实现从Stream中生成一个值，其生成的值不是随意的，而是根据指定的计算模型。比如，之前提到count、min和max方法，因为常用而被纳入标准库中。事实上，这些方法都是reduce操作	  
		1.一个参数：Optional reduce(BinaryOperator accumulator)，传入求和函数式
		List<Integer> list= Arrays.asList(new Integer[]{1,2,3,4,5,6,7,8,9});
        Integer sum=list.stream().reduce((x,y)->x+y).get();
		2.两个参数：T reduce(T identity, BinaryOperator accumulator)，（默认值，求和函数式）identity参数与Stream中数据同类型，相当于一个的初始值
		List<Integer> numList = Arrays.asList(1,2,3,4,5);
		Integer result = numList.stream().reduce(100, (a,b) -> a + b );
		3.三个参数的没怎么用过
		List<Integer> numList = Arrays.asList(1, 2, 3, 4, 5);
        String result = numList.stream().reduce("__", (a, b) -> a += String.valueOf(b), (x, t) -> null);
```

3. **Optional**

```java
    Optional是一个容器对象，可以包含也可以不包含非null值。Optional在Java 8中引入，目的是解决 NullPointerExceptions的问题。本质上，Optional是一个包装器类，其中包含对其他对象的引用。在这种情况下，对象只是指向内存位置的指针，并且也可以指向任何内容。从其它角度看，Optional提供一种类型级解决方案来表示可选值而不是空引用。
　　在Java 8之前，程序员将返回null而不是Optional。这种方法有一些缺点。一种是没有明确的方法来表示null可能是一个特殊值。相比之下，在API中返回Optional是明确的声明，其中可能没有值。如果我们要确保不会出现空指针异常，则需要对每个引用进行显式的空检查。
　　创建方法
　　1.static <T> [Optional]<T> [empty]()
　　 // Creating an empty optional  创建一个空的Optional实例	　　
    Optional<String> empty = Optional.empty();
   2. static <T> [Optional]<T> [of](T value)
	// Creating an optional using of  创建特定的非空值Optional。
	String name = "java";
	Optional<String> opt = Optional.of(name);
   3. static <T> [Optional]<T> [of](T value)
    //Possible null value 描述指定值的Optional，传入一个空引用，它不会抛出异常，而是返回一个空的Optional对象
     Optional<String> optional = Optional.ofNullable(name());
     private  String  name()
     {
     	String name = "Java";
 	 	return (name.length() > 5) ? name : null;
	 }
	使用方法
	1.isPresent() 如果存在值，则返回true；反之，返回false。如果所包含的对象不为null，则返回true，反之返回false
	2.isEmpty() 如果存在值，则返回false；否则，返回ture。这与isPresent 相反
	3.ifPresent([Consumer]<? super [T]> consumer) 如果存在值，则使用该值调用指定的使用者；否则，什么都不做 
		optional1.ifPresent(s -> System.out.println(s.length()));
	4.get() 如果此Optional中存在值，则返回该值，否则抛出 NoSuchElementException
	5.orElse() orElse() 方法返回包装的值（如果存在）及其参数
		//底层 value != null ? value : other
		String nullName = null;
        String name = Optional.ofNullable(nullName).orElse("default_name");
    6.orElseGet() 该orElseGet() 方法类似于 orElse()。但是，如果没有Optional值，则不采用返回值，而是采用供应商功能接口，该接口将被调用并返回调用的值   
    	//底层 value != null ? value : other.get();
    	String name = Optional.ofNullable(nullName).orElseGet(() -> "john");
    7.orElseThrow() 抛出异常
    	User result = Optional.ofNullable(user).orElseThrow( () -> new IllegalArgumentException());
    8.map() 转换值 filter/flatMap等可以参考stream流
    	User user = new User("anna@gmail.com", "1234");
		String email = Optional.ofNullable(user).map(u -> u.getEmail()).orElse("default@gmail.com");
```

4. **Java 8 默认方法**

 ```java
  java 8 之前，接口与其实现类之间的 耦合度 太高了，当需要为一个接口添加方法时，所有的实现类都必须随之修改。默认方法解决了这个问题，它可以为接口添加新的方法，而不会破坏已有的接口的实现
 	 public interface People{
 	   default void print(){
 	      System.out.println("默认方法");
 	   }
 	}
 	多继承问题
 	public interface Vehicle{
 	   default void print(){
 	      System.out.println("默认方法0");
 	   }
 	}
 	 
 	public interface FourWheeler {
 	   default void print(){
 	      System.out.println("默认方法1");
 	   }
 	}
 	解决方法有两个：
 	1、子类重写默认方法覆盖接口的默认方法；
 	2、使用 super 来调用指定接口的默认方法
 	 //1、重写覆盖
 	public class Car implements Vehicle, FourWheeler {
 	   default void print(){
 	      System.out.println("新默认方法");
 	   }
 	}
 	//2、精确调用
 	public class Car implements Vehicle, FourWheeler {
 	   public void print(){
 	      Vehicle.super.print();
 	   }
 	}
 	静态默认方法 : Java8 支持接口中定义静态方法（需要提供默认实现），写法上将默认方法的default关键字换成static关键字即可
     public interface Vehicle {
     default void print(){
        System.out.println("我是一辆车!");
     }
      // 静态方法
     static void blowHorn(){
        System.out.println("按喇叭!!!");
     }
  }
 注意点
 	1.default 关键字只能在接口中使用（以及用在 switch 语句的 default 分支），不能用在抽象类中。
 	2.接口默认方法不能覆写 Object 类的 equals、hashCode 和 toString 方法。
 	3.接口中的静态方法必须是 public 的，public 修饰符可以省略，static 修饰符不能省略。
 	4.即使使用了 java 8 的环境，一些 IDE 仍然可能在一些代码的实时编译提示时出现异常的提示（例如无法发现 java 8 的语法错误），因此不要过度依赖 IDE。
 ```

5. **函数式接口**

```java
有且仅有一个抽象方法的接口，但是可以有多个非抽象方法的接口。函数式接口可以被隐式转换为 lambda 表达式。Lambda就是Java中函数式编程的体现
1.Function (函数型接口)
	//输入参数 + 输出返回值
	Function<String,String> function = s -> s+"函数";
	function.apply("test");
	// 输入参数 1 + 输入参数 2 + 输出返回值
	BiFunction<String, String, String> biFunction= (s1, s2) -> s1 + s2;
	biFunction.apply("test","test1");

2.Predicate (断定型接口)
	//输入参数 + 输出返回值 Boolean类型
    Predicate<Integer> predicate =(n)->{return n>0;};
	boolean flag = predicate.test(2);
3.Consumer (消费型接口) 只有参数没有返回值
	//输入参数
	Consumer<String> consumer = s -> System.out.println(s); 
	consumer.accept("a");
	//输入参数1 + 输入参数2
	BiConsumer<String, String> biConsumer = (s1, s2) -> System.out.println(s1 + s2);
	biConsumer.accept("a","b");
4.Supplier (供给型接口) 没有参数只有返回值
	//返回值
	Supplier<Integer> supplier = ()-> {return 1024;};
	Integer num = supplier.get();
```

6. **方法引用 lambda表达式的一种简化写法**

```java
对象::实例方法
 //1.1 接口 变量名 = 匿名内部类
        Consumer<String> consumer = new Consumer<String>() {
            @Override
            public void accept(String s) {
                System.out.println(s);
            }
        };
        consumer.accept("consumer1");

        //1.2 接口 变量名 = lambda表达式
        consumer = s -> {
            System.out.println(s);
        };
        consumer.accept("consumer2");

        //1.3 接口 变量名 = 方法引用
        consumer = System.out::println;
        consumer.accept("consumer3");

类::静态方法
	 //匿名内部类写法
        Comparator<Integer> comparator = new Comparator<Integer>() {
            @Override
            public int compare(Integer o1, Integer o2) {
                return Integer.compare(o1, o2);
            }
        };
        System.out.println("comparator.compare(10,20) = " + comparator.compare(10, 20));

        //用lambda表达式简化
        comparator = (o1, o2) -> {
            return Integer.compare(o1, o2);
        };
        System.out.println("comparator.compare(10,20) = " + comparator.compare(10, 20));

        //用方法引用简化
        comparator = Integer::compare;
        System.out.println("comparator.compare(10,20) = " + comparator.compare(10, 20));
类::实例方法
	    Person person = new Person("张三");

        //匿名内部类写法
        Function<Person, String> function = new Function<Person, String>() {
            @Override
            public String apply(Person person) {
                return person.getName();
            }
        };
        System.out.println(function.apply(person));

        //用lambda表达式简化
        function = p -> p.getName();
        System.out.println(function.apply(person));

        //用方法引用简化
        function = Person::getName;
        System.out.println(function.apply(person));

类::new
		Supplier<String> supplier = new Supplier<String>() {
          @Override
          public String get() {
              return new String("abc");
          }
        };
        System.out.println(supplier.get());

        //用lambda表达式简化
        supplier = () -> new String("abc");
        System.out.println(supplier.get());

        //用方法引用简化
        supplier = String::new;
        System.out.println(supplier.get());
```

7. **Base64编码**

```java
import java.util.Base64; //导入包
public class StrConvertBase64 {
	public static void main(String[] args) {
		// 字符串转Base64
		String enCodeStr = getBase64EnCoder("哈哈哈哈");
		System.out.println(enCodeStr);
		// Base64转字符串
		String deCodeStr = getBase64DeCoder("uf65/rn+uf4=");
		System.out.println(deCodeStr);
	}
	/**
	 * Base64编码
	 * @param src
	 * @return
	 */
	public static String getBase64EnCoder(String str) {
		// 将源字符串转为byte数组
		byte [] strBytes = str.getBytes();
		// 链式调用,返回结果
		return Base64.getEncoder().encodeToString(strBytes);
	}
	/**
	 * Base64解码
	 * @param src
	 * @return
	 */
	public static String getBase64DeCoder(String str) {
		// 将Base64编码转为byte数组
		byte [] base64Bytes = Base64.getDecoder().decode(str);
		// 将Byte数组转为String,返回结果
		return new String(base64Bytes);
	}
}
```

8. **链式编程**

```java
原理：链式编程的原理是返回一个this对象，也就是返回对象本身，从而达到链式效果
1.
  StringBuilder buffer = new StringBuilder();
  buffer.append("你").append("好").append("!").append(" ").append("世").append("界");
2.
  String string = String.valueOf("123").concat(",4567890").replace(',', '!').substring(2, 8);
3.
 // 将数组变成一个列表集合
  List<Integer> list = Arrays.asList(5, 3, 7, 5, 4);
 // 获取集合的 Stream 流对象
  list.stream()
          // 相同元素去重
           .distinct()
           // 升序排序
           .sorted((c1, c2) -> c1.compareTo(c2))
           // 遍历
           .forEach(System.out::println);
```

9. **Consumer**

```java
 Java的Consumer接口来自Java 8 引入的java.util.function包
 Consumer是一个功能接口，用来作为lambda表达式或方法引用的任务目标(传递一个参数执行指定的方法)。
 Consumer的功能接口是一个接受单一参数并且不返回任何结果的操作，功能方法为accept(T t)
 accept(T t) 对给定的参数进行操作 
 andThen() 此方法返回一个组合的Consumer，该Consumer先执行原始的Consumer操作，然后按照从左到右的	  顺序执行给定的andThen操作。
 accept(T t) 使用:
 实例1 基本使用
 	 Consumer<String> consumer = s -> System.out.println(s); 
     consumer.accept("use");
 实例2 对基础数据类型操作
 	List<Integer> list = new ArrayList<>();
 	Consumer<Integer> c = i -> list.add(i);
 	c.accept(1);
 	c.accept(2);
 实例3 对象类型操作 User 对象 name 是名字字段
 	Consumer<User> c = user -> System.out.println(user.getName());
 andThen() 使用:default Consumer<T> andThen(Consumer<? super T> after) 必须是同一类型的
 实例1 
 	List<Integer> numList = Arrays.asList(3, 4, 5, 6);
	Consumer<List<Integer>> first= list -> {
	  for (int i = 0; i < list.size(); i++) {
		list.set(i, list.get(i) * list.get(i));
	  }
	};
	Consumer<List<Integer>> second= list -> list.forEach(n -> 				   	System.out.println(n));
	first.andThen(second).accept(numList);
实例2
	 public static void main(String[] args) {
	List<Integer> list = Arrays.asList(12, 13, 14, 15, 16, 17);
	Consumer<List<Integer>> firstConsumer = Task::first;
	Consumer<List<Integer>> secondConsumer = Task::second ;
	Consumer<List<Integer>> lastConsumer = Task::last;
	firstConsumer .andThen(secondConsumer ).andThen(lastConsumer ).accept(list);
  }
}

class Task{
  static void first(List<Integer> list) {
	System.out.println("---first---");
	list.forEach(i -> {
	  System.out.println("first :" + i);
	});
  }
}
```

————————————————
原文链接：https://blog.csdn.net/qq_36488864/article/details/130964395

[Java8十大新特性](https://blog.csdn.net/cdw8131197/article/details/68553148)

#### 21、Java四种访问修饰符

<img src="asset\访问修饰符.png" alt="img" style="zoom: 67%;" />

Java中的访问权限修饰符主要是用来控制类、接口、方法和变量等成员的可见性和访问范围。Java中有四种不同的访问权限修饰符，分别是public、protected、default和private。下面将对这四种访问权限修饰符进行详细介绍，以便更好地理解它们各自的作用和用法。

1、public

public是Java中最常用的访问权限修饰符，它表示公共的意思，被public修饰的类、接口、方法和变量等成员都可以被任何其他类或对象所访问。具体来说，如果一个类被声明为public，则这个类可以被从任何地方访问，无论是在同一个包内还是在不同的包内。同样地，如果一个方法、变量或者接口被声明为public，则它们也可以被其他类或对象从任何地方访问。

2、protected

protected是一种比较特殊的访问权限修饰符，它表示受保护的意思。被protected修饰的类、方法、变量或者接口只能被相同包或其子类中的类或对象所访问。也就是说，protected成员只能在定义它的类的子类中被访问，而不能在同一个包中的其他类或对象中被访问。需要注意的是，即使在子类中访问protected成员时不需要使用类名来限定，但在同一个包中的其他类或对象中访问时，仍需要使用类名来限定。

3、default

default是Java中的默认访问权限修饰符，它表示不指定任何访问权限修饰符时所使用的访问权限。如果一个类、方法、变量或接口没有使用任何访问权限修饰符，则这些成员默认为包级别访问权限，也就是说，只能在同一个包内被访问。可以看出，default修饰符的作用范围介于public和protected之间，它既不像public那样对所有代码都公开可见，也不像protected那样只在子类和相同包内可见。

4、private

private是一种最严格的访问权限修饰符，它表示私有的意思，只有在定义该成员的类内部才能被访问。被private修饰的类、方法、变量或接口只能在自己的类中被调用，无法被同一个包内或者其他包中的其他类或对象所访问。需要注意的是，在一个类中，如果某个成员没有使用任何访问权限修饰符，则默认为private访问权限。

总结

Java中的四种访问权限修饰符是public、protected、default和private。这些修饰符可以在类、接口、方法和变量等成员上使用，用来控制其可见性和访问范围。其中，public表示公共的，可以被任何其他类或对象所访问；protected表示受保护的，只能被相同包或其子类中的类或对象所访问；default表示默认的，只能在同一个包内被访问；private表示私有的，在定义该成员的类内部才能被访问。同时，需要注意的是，Java中的访问权限修饰符是一种强制机制，不能被违反。

### 并发

#### 1、进程间通信方式

进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。IPC的方式通常有**管道**（包括匿名管道和命名管道 Pipe）、**消息队列**（MQ）、**信号量**（Semaphre）、**共享内存**（Shared memory）、**信号**（Signal）、**套接字通信（Socket）**等。

**进程间通信的目的**

- 数据传输：一个进程需要将它的数据发送给另一个进程
- 资源共享：多个进程之间共享同样的资源
- 通知事件：一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）
- 进程控制：有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常

**管道**

管道是Unix中最古老的进程间通信的形式，是半双工的通信方式。我们把从一个进程连接到另一个进程的一个数据流称为一个"管道"。管道是一个只能单向通信的通信管道，如果想要双向通信，那么就建立两个管道。
`管道的本质是内核中的一块缓冲区`

<img src="https://img-blog.csdnimg.cn/6def3bc188184b0b84e9553b100abc3f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2g5aW977yM5Yav5ZCM5a2m,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom:67%;" />

（1）匿名管道

1. 管道是一个只能单向通信的通信信道
2. 管道是面向字节流的
3. 具有血缘关系的进程进行进程间通信，例如父子进程
4. 管道自带同步机制，原子性写入(互斥)
5. 管道也是文件，如果只被当前进程打开，相关进程退出了，会被OS自动关闭。所以管道的声生命周期是随进程的

（2）命名管道

为了解决匿名管道只能具有血缘关系的进程进行通信，引入的命名管道。
命名管道与匿名管道的特点基本一致。
如果我们想在不相关的进程之间交换数据，可以使用FIFO文件来做这项工作，它经常被称为命名管道。
命名管道是一种特殊类型的文件。

**共享内存**

共享内存区是最快的IPC形式。一旦这样的内存映射到共享它的进程的地址空间，这些进程间数据传递不再涉及到内核，换句话说是进程不再通过执行进入内核的系统调用来传递彼此的数据

1. 通过某种调用，在内存中创建一份内存空间！
2. 通过某种调用，让进程"挂接"到这份新开辟的内存空降上！

通过上述这两步操作后，我们就可以使不同的进程看到了同一份资源，就能使不同的进程进行通信了，这种通信方案就叫做共享内存

<img src="https://img-blog.csdnimg.cn/655d7fa031c44bbe9259046bffc18e93.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2g5aW977yM5Yav5ZCM5a2m,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" style="zoom: 80%;" />

**消息队列**

消息队列是消息的链表，是存放在内核中并由消息队列标识符标识。因此是随内核持续的，只有在内核重起或者显示删除一个消息队列时，该消息队列才会真正被删除。**消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区受限等特点**。允许不同进程将格式化的数据流以消息队列形式发送给任意进程，对消息队列具有操作权限的进程都可以使用msgget完成对消息队列的操作控制，通过使用消息类型，进程可以按顺序读信息，或为消息安排优先级顺序。

**信号量**

管道，共享内存，消息队列，它们都是以传输数据为目的的！
信号量不是以传输数据为目的！它是通过共享"资源"的方式，来达到多个进程的同步和互斥的目的！
`信号量的本质：是一个计数器，类似int count。衡量临界资源中的资源数`

**信号**

信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

**套接字通信**

套接字( socket ) ： 套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。

https://blog.csdn.net/qq_56044032/article/details/124349478

https://xiaolincoding.com/os/4_process/process_commu.html#%E7%AE%A1%E9%81%93

#### 2、MarkWord

在hotspot虚拟机中，对象头主要包括两部分 MarkWord和Class Pointer。

- MarkWord 对象标记字段，默认存储的是对象的HashCode，GC的分代年龄(2bit最大表示15)和锁的标志信息等。对于32位的虚拟机MarkWord占32bit，对于64位的虚拟机MarkWord占用64字节。

- Class Pointer Class 对象的类型指针，它指向对象对应的Class对象的内存地址。大小占4字节(指针压缩的情况下为4字节，未进行指针压缩则占8字节)。32位虚拟机MarkWord分布

![在这里插入图片描述](asset\32位MarkWord.png)

64位虚拟机MarkWord分布

![在这里插入图片描述](asset\64位MarkWord.png)

https://blog.csdn.net/weixin_40816843/article/details/120811181

- 偏向锁

![img](asset\java-thread-x-key-schronized-8.png)

- 轻量级锁

<img src="asset\java-thread-x-key-schronized-5.png" alt="img" style="zoom:80%;" />

<img src="https://www.pdai.tech/images/thread/java-thread-x-key-schronized-6.png" alt="img" style="zoom:80%;" />

**锁的优缺点对比**

| 锁       | 优点                                                         | 缺点                                                         | 使用场景                           |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------- |
| 偏向锁   | 加锁和解锁不需要CAS操作，没有额外的性能消耗，和执行非同步方法相比仅存在纳秒级的差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗               | 适用于只有一个线程访问同步块的场景 |
| 轻量级锁 | 竞争的线程不会阻塞，提高了响应速度                           | 如线程成始终得不到锁竞争的线程，使用自旋会消耗CPU性能        | 追求响应时间，同步块执行速度非常快 |
| 重量级锁 | 线程竞争不适用自旋，不会消耗CPU                              | 线程阻塞，响应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 | 追求吞吐量，同步块执行速度较长     |

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/java/thread/java-thread-x-key-synchronized.html

#### 3、进程与线程的区别

程序由指令和数据组成，但这些指令要运行，数据要读写，就必须将指令加载至 CPU，数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程就是用来加载指令、管理内存、管理 IO 的。

1. 进程是资源分配最小单位，线程是程序执行的最小单位；

2. 进程有自己独立的地址空间，每启动一个进程，系统都会为其分配地址空间，建立数据表来维护代码段、堆栈段和数据段，线程没有独立的地址空间，它使用相同的地址空间共享数据；

3. CPU切换一个线程比切换进程花费小；

4. 创建一个线程比进程开销小（进程虚拟内存会占用 4GB [32 位操作系统]，而线程也要大约 4MB）；

5. 线程占用的资源要⽐进程少很多。

6. 线程之间通信更方便，同一个进程下，线程共享全局变量，静态变量等数据，进程之间的通信需要以通信的方式（IPC）进行；（但多线程程序处理好同步与互斥是个难点）

7. 多进程程序更安全，生命力更强，一个进程死掉不会对另一个进程造成影响（源于有独立的地址空间），多线程程序更不易维护，一个线程死掉，整个进程就死掉了（因为共享地址空间）；

8. 进程对资源保护要求高，开销大，效率相对较低，线程资源保护要求不高，但开销小，效率高，可频繁切换；
   ————————————————
   原文链接：https://blog.csdn.net/wsq119/article/details/82154305

[进程、线程和协程](https://blog.csdn.net/w2009211777/article/details/125514898)

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

**线程上下文切换包括线程的私有数据、寄存器等不共享的数据**；

<img src="asset\进程上下文.png" alt="img" style="zoom: 50%;" />

<img src="asset\线程上下文.png" alt="img" style="zoom: 80%;" />

<img src="asset\协程上下文.png" alt="img" style="zoom:80%;" />

**进程和线程的上下文切换**

- 进程

CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

- 线程

当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；

**当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据**；

所以，线程的上下文切换相比进程，开销要小很多。

---

协程是用户视角的一种抽象，操作系统并没有协程的概念。

协程运行在线程之上，**协程**的主要思想是**在用户态实现调度算法，用少量线程完成大量任务的调度**。

协程需要解决线程遇到的几个问题：

- 内存占用要小，且创建开销要小
  - 用户态的协程，可以设计的很小，可以达到 KB 级别。是线程的千分之一。
  - 线程栈空间通常是MB级别， 协程栈空间最小KB级别。
- 减少上下文切换的开销
  - 让可执行的线程尽量少，这样切换次数必然会少
  - 让线程尽可能的处于运行状态，而不是阻塞让出时间片
  - 多个协程多个协程绑定一个或者多个线程上
  - 当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上（分时复用）。
  - 即使有协程阻塞，该线程的其他协程也可以被 runtime 调度，转移到其他可运行的线程上。
- 降低开发难度
  - goroutine是golang中对协程的实现
  - goroutine底层实现了少量线程干多事，减少切换时间等
  - 程序员可以轻松创建协程，无需去关注底层性能优化的细节

相较进程和线程而言，协程的上下文切换则快了很多， 它只需在【用户态】即可完成上下文的切换，并且需要切换的上下文信息也较少。

那么协程的上下文切换相较线程有哪些提升？

- 协程上下文切换只涉及CPU上下文切换，而所谓的CPU上下文切换是指少量寄存器（PC / SP / DX）的值修改，协程切换非常简单，就是把当前协程的 CPU 寄存器状态保存起来，然后将需要切换进来的协程的 CPU 寄存器状态加载的 CPU 寄存器上就 ok 了。而对比**线程的上下文切换则需要涉及模式切换（从用户态切换到内核态）**、以及 16 个寄存器、PC、SP…等寄存器的刷新；

- 线程栈空间通常是 2M， 协程栈空间最小 2K。

————————————————
版权声明：本文为CSDN博主「小魏的博客」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/w2009211777/article/details/125514898

————————————————
原文链接：https://blog.csdn.net/w2009211777/article/details/125514898

#### 4、共享的long和double变量的为什么要用volatile?

因为long和double两种数据类型的操作可分为高32位和低32位两部分，因此普通的long或double类型读/写可能不是原子的。因此，鼓励大家将共享的long和double变量设置为volatile类型，这样能保证任何情况下对long和double的单次读/写操作都具有原子性。

原文链接：https://pdai.tech/md/java/thread/java-thread-x-key-volatile.html

#### 5、 怎么检测一个线程是否拥有锁？

在`java.lang.Thread`中有一个方法叫`holdsLock()`，它返回true如果当且仅当当前线程拥有某个具体对象的锁。

<img src="asset\ReentrantLock和Synchronized.jpg" style="zoom: 67%;" />

#### 6、AQS

全称是 AbstractQueuedSynchronizer，是构建阻塞式锁和相关的同步器工具的框架，AQS底层使用了模板方法模式；

特点：

- 用 state 属性来表示资源的状态（分独占模式和共享模式），子类需要定义如何维护这个状态，控制如何获取锁和释放锁

  - getState - 获取 state 状态

  - setState - 设置 state 状态

  - compareAndSetState - cas 机制设置 state 状态

  - 独占模式是只有一个线程能够访问资源，而共享模式可以允许多个线程访问资源

- 提供了基于 FIFO 的等待队列来完成获取资源线程的排队工作，类似于 Monitor 的 EntryList

- 条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet

子类主要实现这样一些方法（默认抛出 UnsupportedOperationException）

```java
isHeldExclusively() // 该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int) // 独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int) // 独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int) // 共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
tryReleaseShared(int) // 共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

**AQS数据结构：**

AbstractQueuedSynchronizer类底层的数据结构是使用`CLH(Craig,Landin,and Hagersten)队列`是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。

AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。其中Sync queue，即同步队列，是双向链表，包括head结点和tail结点，head结点主要用作后续的调度。而Condition queue不是必须的，其是一个单向链表，只有当使用Condition时，才会存在此单向链表。并且可能会有多个Condition queue。

![AQS数据结构](asset\AQS数据结构.png)

> 每个线程被阻塞的线程都会被封装成一个Node结点，放入队列。每个节点包含了一个Thread类型的引用，并且每个节点都存在一个状态，具体状态如下。
>
> - `CANCELLED`，值为1，表示当前的线程被取消。
> - `SIGNAL`，值为-1，表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。
> - `CONDITION`，值为-2，表示当前节点在等待condition，也就是在condition queue中。
> - `PROPAGATE`，值为-3，表示当前场景下后续的acquireShared能够得以执行。
> - 值为0，表示当前节点在sync queue中，等待着获取锁

**总结：**

对于AbstractQueuedSynchronizer的分析，最核心的就是sync queue的分析。

- 每一个结点都是由前一个结点唤醒
- 当结点发现前驱结点是head并且尝试获取成功，则会轮到该线程运行。
- condition queue中的结点向sync queue中转移是通过signal操作完成的。
- 当结点的状态为SIGNAL时，表示后面的结点需要运行。

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/java/thread/java-thread-x-lock-AbstractQueuedSynchronizer.html

#### 7、推荐使用 `ThreadPoolExecutor` 构造函数创建线程池

在《阿里巴巴 Java 开发手册》“并发处理”这一章节，明确指出线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。

**为什么呢？**

> 使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源开销，解决资源不足的问题。如果不使用线程池，有可能会造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。

另外，《阿里巴巴 Java 开发手册》中强制线程池不允许使用 `Executors` 去创建，而是通过 `ThreadPoolExecutor` 构造函数的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。

> `Executors` 返回线程池对象的弊端如下(后文会详细介绍到)：
>
> - **`FixedThreadPool` 和 `SingleThreadExecutor`** ： 允许请求的队列长度为 `Integer.MAX_VALUE`,可能堆积大量的请求，从而导致 OOM。
> - **`CachedThreadPool` 和 `ScheduledThreadPool`** ： 允许创建的线程数量为 `Integer.MAX_VALUE` ，可能会创建大量线程，从而导致 OOM。

------

著作权归所有 原文链接：https://javaguide.cn/java/concurrent/java-thread-pool-summary.html

---

[ThreadPoolExecutor关闭线程池原理](https://blog.csdn.net/miaomiao19971215/article/details/108448802) 

[线程池中多余的线程是如何回收的？](https://www.cnblogs.com/kingsleylam/p/11241625.html)

> ```java
> java.util.concurrent.ThreadPoolExecutor#runWorker
> java.util.concurrent.ThreadPoolExecutor#getTask
> boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;
> java.util.concurrent.ThreadPoolExecutor#compareAndDecrementWorkerCount
> java.util.concurrent.ThreadPoolExecutor#processWorkerExit
> ```

https://www.bilibili.com/video/BV1Gg4y1N7pa?p=20

#### 8、在 while 中调用 wait 方法

在while循环里使用wait的目的，是在线程被唤醒的前后都持续检查条件是否被满足。生产者线程如果条件并未改变，那么这个线程并不能被唤醒，可以防止对缓冲区队列误操作。

```java
// The standard idiom for calling the wait method in Java
synchronized (sharedObject) {
	while (condition) {
		sharedObject.wait();
		// (Releases lock, and reacquires on wakeup)
	}
	// do action based upon condition e.g. take or put into queue
}
```

1. 你可以使用wait和notify函数来实现线程间通信。你可以用它们来实现多线程（>3）之间的通信。
2. **永远在synchronized的函数或对象里使用锁对象的wait、notify和notifyAll**，不然Java虚拟机会生成 IllegalMonitorStateException。
3. **永远在while循环里而不是if语句下使用wait**。这样，会在线程暂停恢复后都检查wait的条件，并在条件实际上并未改变的情况下处理唤醒通知。
4. 永远在多线程间共享的对象（在生产者消费者模型里即缓冲区队列）上使用wait。
5. 基于前文提及的理由，更倾向用 notifyAll()，而不是 notify()。用notify()方法只是讲一个因为wait操作处于等待的线程唤醒。可能生产者只是唤醒生产者。而没有唤醒消费者。所以为了防止多线程下假死情况都是用notifyAll()方法

原文链接：https://blog.csdn.net/JQ_AK47/article/details/51591154

#### 9、并发和并行

并发（concurrent）是同一时间应对（dealing with）多件事情的能力（同一时间段多件事情同时运行）

并行（parallel）是同一时间动手做（doing）多件事情的能力（同一时刻多件事情同时运行）

#### 10、synchronized和ReentrantLock哪个性能好？各自的适用场景？

synchronized和ReentrantLock都是Java中常用的线程同步机制，它们有各自适应的场景和优缺点。

synchronized是Java语言层面提供的锁机制，使用非常方便，只需要在关键代码段添加synchronized关键字就可以实现线程同步。synchronized的优点是简单易用、无需手动释放锁，缺点是效率相对较低，特别是在竞争激烈的场合下，容易导致线程长时间等待，从而影响系统性能。

ReentrantLock是Java的高级锁机制，提供了更丰富的功能和更细粒度的控制，例如公平锁、可重入锁、可中断锁、限时锁等，可以满足更复杂的多线程场景。ReentrantLock的优点是灵活性强、效率高，缺点是使用起来相对复杂，需要手动释放锁，如果使用不当容易产生死锁等问题。

总之，在选择synchronized和ReentrantLock时应该根据具体的业务场景进行判断，一般来说：

1. 如果只是简单的线程同步，没有特殊要求，建议使用synchronized。

2. 如果需要更细粒度的控制，例如实现自旋锁、超时等待等功能，建议使用ReentrantLock。

3. 如果需要对锁进行高级操作，例如释放、等待、唤醒等，建议使用ReentrantLock。

4. 如果在Java 5之前的版本中，只能使用synchronized，而在Java 5及以后的版本中，可以使用ReentrantLock。

#### 5、线程上下文切换

因为以下一些原因导致 cpu 不再执行当前的线程，转而执行另一个线程的代码

- 线程的 cpu 时间片用完
- 垃圾回收
- 有更高优先级的线程需要运行
- 线程自己调用了 sleep、yield、wait、join、park、synchronized、lock 等方法

当 Context Switch 发生时，需要由操作系统保存当前线程的状态，并恢复另一个线程的状态，Java 中对应的概念就是程序计数器（Program Counter Register），它的作用是记住下一条 jvm 指令的执行地址，是线程私有的

- 状态包括程序计数器、虚拟机栈中每个栈帧的信息，如局部变量、操作数栈、返回地址等
- Context Switch 频繁发生会影响性能

---

各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个**一个进程切换到另一个进程运行，称为进程的上下文切换**。

CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

---

> 线程上下文切换的是什么？

这还得看线程是不是属于同一个进程：

- 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；
- **当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器、栈等不共享的数据**；

所以，线程的上下文切换相比进程，开销要小很多。

链接：https://xiaolincoding.com/os/4_process/process_base.html

---

线程上下文切换会保存上一个线程的以下内容：

1. 程序计数器（PC）：记录当前线程执行到哪条指令的地址，从而在切换回该线程时，能够恢复执行。
2. 寄存器文件：包括通用寄存器以及栈指针寄存器等，保存线程执行时的变量值和状态信息，在切换回该线程时，能够恢复执行。

进程上下文切换会保存上一个进程的以上内容外，还会保存以下内容：

1. 进程控制块（PCB）：记录进程的运行状态、资源占用情况、进程标识符等信息，在切换回该进程时，能够恢复运行。
2. 用户空间栈、内核栈及其他内存区域：因为进程具有独立的地址空间，所以在进行进程上下文切换时，需要保存当前进程的所有内存区域，以便在切换回该进程时，能够继续运行。

#### 6、线程的状态

- 操作系统角度下的5中状态：

![img](asset\Java线程生命周期.png)

**线程的5个状态** 

1. 新建状态（**New**）：当线程对象对创建后，即进入了新建状态，如：Thread t = new MyThread();

2. 就绪状态（**Runnable**）：当调用线程对象的start()方法（t.start();），线程即进入就绪状态。处于就绪状态的线程，只是说明此线程已经做好了准备，随时等待CPU调度执行，**获取cpu 的使用权,**并不是说执行了t.start()此线程立即就会执行

3. 运行状态（**Running**）：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。 当CPU开始调度处于就绪状态的线程时，此时线程才得以真正执行，即进入到运行状态。注：就 绪状态是进入到运行状态的唯一入口，也就是说，线程要想进入运行状态执行，首先必须处于就绪状态中；

4. 阻塞状态（**Blocked**）：处于运行状态中的线程由于某种原因，暂时放弃对CPU的使用权，，也即让出了cpu timeslice， 停止执行，此时进入阻塞状态，直到其进入到就绪状态，才 有机会再次被CPU调用以进入到运行状态。才有机会再次获得cpu timeslice 转到运行(running)状态 根据阻塞产生的原因不同，阻塞状态又可以分为三种：
   1. 等待阻塞：运行状态中的线程执行wait()方法，使本线程进入到等待阻塞状态；JVM会把该线程放入等待队列(waitting queue)中。
   2. 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，获取synchronized同步锁失败 , 它会进入同步阻塞状态，则JVM会把该线程放入锁池(lock pool)中。
   3. 其他阻塞：通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。

5. 死亡状态（**Dead**）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

----

- JVM角度下的六种状态：

[Java线程](https://so.csdn.net/so/search?q=Java线程&spm=1001.2101.3001.7020)的生命周期分为:**NEW（初始化状态）、RUNNABLE（可运行状态/运行状态）、BLOCKED（阻塞状态）、WAITING（等待状态）、TIMED_WAITING（有时限的等待）、TERMINATED（终止状态）**

<img src="asset\Java线程六种状态.png" alt="在这里插入图片描述" style="zoom: 75%;" />

- **NEW 初始状态**，线程被构建，但是还没有调用 start() 方法

- **RUNNABLE 可运行状态**， 可运行状态包括运行中状态（RUNNING）和就绪状态(READY)

  - 运行中状态（RUNNING) 表示处于该状态的的线程正在运行， 即相应线程对象的run方法所对应的指令正在由处理器执行 。当：

    1. 操作系统执行 yield() 方法

    2. 时间片用完

    3. 来了更高优先级而被抢断
    
       时就会变为就绪状态。
  
  - 就绪状态(READY) 表示正在执行run（）方法，可以通过系统调度来变为可运行状态。

- **BLOCKED 阻塞状态**， 处于这个状态的线程需要等待其他线程释放锁或者等待进入synchronized

  - > 一个处于 blocked 状态的线程正在等待一个监视器锁以进入一个同步的块或方法。
    > 一个处于 blocked 状态的线程正在等待一个监视器锁，在其调用 Object.wait 方法之后，以再次进入一个同步的块或方法。

- **WAITING 等待状态**， 处于这个状态的线程需要等待其他线程对其进行通知或中断等操作，从而进入到下一个状态。

  - > 调用如下3个方法会使线程进入等待状态：
    >
    > - Object.wait()：使当前线程进入等待状态，直到它被其他线程通过notify()或者notifyAll唤醒。该方法只能在同步方法中调用。如果当前线程不是锁的持有者，该方法抛出一个IllegalMonitorStateException异常。
    > - Thread.join()：等待线程执行完毕，底层调用的是Object实例的wait方法；
    > - LockSupport.park()：除非获得调用许可，否则禁用当前线程进行线程调度。

- **TIMED_WAITING 超时等待状态**， 可以在一定时间内自行返回。

  - > 该状态和WAITING类似，差别在于处于该状态的线程并非无限制的等待其他线程执行特定操作，而是处于有时间限制的等待状态，当其他线程没有在指定时间内执行该线程所期望的特定操作时，该线程状态会自动转换为RUNNABLE；
    >
    > 从状态切换图中可以知道调用以下方法将会进入超时等待状态：
    >
    > - Thread.sleep(long millis)：使当前线程睡眠指定时间；
    > - Object.wait(long timeout)：线程休眠指定时间，等待期间可以通过notify()/notifyAll()唤醒；
    > - Thread.join(long millis)：等待当前线程最多执行millis毫秒，如果millis为0，则会一直执行；
    > - LockSupport.parkNanos(long nanos)：除非获得调用许可，否则禁用当前线程进行线程调度指定时间；
    > - LockSupport.parkUntil(long deadline)：同上，也是禁止线程进行调度指定时间；

- **TWEMINATED 终止状态**， 当前线程执行完毕。

链接：https://www.cnblogs.com/aspirant/p/8876670.html

链接：https://blog.csdn.net/acc__essing/article/details/127470780

-----

操作系统层面的线程状态

<img src="asset\进程的状态.png" alt="image-20230416230725005" style="zoom:80%;" />

- 【初始状态】仅是在语言层面创建了线程对象，还未与操作系统线程关联
- 【可运行状态】（就绪状态）指该线程已经被创建（与操作系统线程关联），可以由 CPU 调度执行
- 【运行状态】指获取了 CPU 时间片运行中的状态
  - 当 CPU 时间片用完，会从【运行状态】转换至【可运行状态】，会导致线程的上下文切换

- 【阻塞状态】

  - 如果调用了阻塞 API，如 BIO 读写文件，这时该线程实际不会用到 CPU，会导致线程上下文切换，进入【阻塞状态】

  - 等 BIO 操作完毕，会由操作系统唤醒阻塞的线程，转换至【可运行状态】

  - 与【可运行状态】的区别是，对【阻塞状态】的线程来说只要它们一直不唤醒，调度器就一直不会考虑调度它们

- 【终止状态】表示线程已经执行完毕，生命周期已经结束，不会再转换为其它状态

Java API层面的线程状态：

<img src="asset\JavaAPI层面的线程状态.png" alt="image-20230416231142548" style="zoom:80%;" />

- NEW 线程刚被创建，但是还没有调用 start() 方法
- RUNNABLE 当调用了 start() 方法之后，注意，**Java API** 层面的 RUNNABLE 状态涵盖了 **操作系统** 层面的【可运行状态】、【运行状态】和【阻塞状态】（由于 BIO 导致的线程阻塞，在 Java 里无法区分，仍然认为是可运行）
  - BLOCKED ， WAITING ， TIMED_WAITING 都是 **Java API** 层面对【阻塞状态】的细分，后面会在状态转换一节详述

- TERMINATED 当线程代码运行结束

#### 7、sleep、yeild、wait、join的区别

只有runnable到running时才会占用cpu时间片，其他都会出让cpu时间片。

线程的资源有不少，但应该包含**CPU资源**和**锁资源**这两类。

- sleep(long mills)、yeild()：让出CPU资源，但是不会释放锁资源。
- wait()：让出CPU资源和锁资源。

**sleep和wait的区别：**

1. Thread.sleep(long) 和Thread.yield()都是Thread类的静态方法，在调用的时候都是Thread.sleep(long)/ Thread.yield()的方式进行调用。**而join()是由线程对象来调用。**
2. wait()和notify()、notifyAll()  这三个方法都是java.lang.Object的方法! 
3. **wait用于锁机制，sleep不是，这就是为啥sleep不释放锁，wait释放锁的原因，sleep是线程的方法，跟锁没半毛钱关系，wait，notify,notifyall 都是Object对象的方法，是一起使用的，用于锁机制。**

**最后：** 

1. sleep：Thread类的方法，必须带一个时间参数。**会让当前线程休眠进入阻塞状态并释放CPU（阿里面试题 Sleep释放CPU，wait 也会释放cpu，因为cpu资源太宝贵了，只有在线程running的时候，才会获取cpu片段）**，提供其他线程运行的机会且不考虑优先级，但如果有同步锁则sleep不会释放锁即其他线程无法获得同步锁 可通过调用interrupt()方法来唤醒休眠线程。

2. yield：**让出CPU调度**，Thread类的方法，类似 `sleep` 只是**不能由用户指定暂停多长时间 ，**并且yield()方法**只能让同优先级的线程**有执行的机会。 yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入**到可执行状态后**马上又被执行。调用yield方法只是一个建议，告诉线程调度器我的工作已经做的差不多了，可以让别的相同优先级的线程使用CPU了，没有任何机制保证采纳。

3. wait：Object类的方法(notify()、notifyAll()  也是Object对象)，必须放在循环体和同步代码块中，执行该方法的线程会释放锁，进入线程等待池中等待被再次唤醒(notify随机唤醒，notifyAll全部唤醒，线程结束自动唤醒)即放入锁池中竞争同步锁

4. join：一种特殊的 `wait`，当前运行线程调用另一个线程的join方法，当前线程进入阻塞状态直到另一个线程运行结束等待该线程终止。 注意该方法也需要捕捉异常。等待调用join方法的线程结束，再继续执行。如：t.join();//主要用于等待t线程运行结束，若无此句，main则会执行完毕，导致结果不可预测。

#### 8、同步和互斥

**互斥**是保证临界区的竞态条件发生，同一时刻只能有一个线程执行临界区代码；

**同步**是由于线程执行的先后、顺序不同、需要一个线程等待其它线程运行到某个点。

- 互斥是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。
- 同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。
- 同步其实已经实现了互斥，所以同步是一种更为复杂的互斥。
- 同步是一种特殊的互斥。特殊在要求各线程访问资源有序。

链接：https://www.jianshu.com/p/7ea6684ed93a/

#### 9、内存屏障

可见性

- 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中
- 而读屏障（lfence）保证在该屏障之后，对**共享变量**（不单单是volatile变量）的读取，加载的是主存中最新数据

有序性

- 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后
- 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前

volatile 的底层实现原理是内存屏障，Memory Barrier（Memory Fence）

- 对 volatile 变量的写指令后会加入写屏障
- 对 volatile 变量的读指令前会加入读屏障

**happens-before**

happens-before 规定了对共享变量的写操作对其它线程的读操作可见，它是可见性与有序性的一套规则总结，抛开以下 happens-before 规则，JMM 并不能保证一个线程对共享变量的写，对于其它线程对该共享变量的读可见

- 线程解锁m之前对变量的写，对于接下来对加锁的其它线程对该变量的读可见

```java
static int x;
static Object m = new Object();

new Thread(()->{
    synchronized(m) {
        x=1;
    }
},"t1").start();

new Thread(()->{
    synchronized(m) {
        System.out.println(x);
    }
}, "t2").start();
```

- 线程对 volatile变量的写，对接下来其它线程对该变量的读可见

```java
volatile static int x;

new Thread(()->{
	x= 10;
},"t1").start();

new Thread(()->{
	System.out.println(x);
},"t2").start();
```

- 线程start前对变量的写，对该线程开始后对该变量的读可见

```java
static int x;

x=1;

new Thread(()->{
	System.out.println(x);
},"t2").start();
```

- 线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其它线程调用 tl.isAlive())或 tl.join()等待它结束）

```java
static int x;

Thread t1 = new Thread(()->{
	x=10;
}"t1");t1.start();

t1.join();

System.out.println(x);
```

- 线程 t1 打断 t2 (interrupt)前对变量的写，对于其他线程得知 2 被打断后对变量的读可见(通过t2.interrupted 或 t2.isInterrupted)

```java
static int x;

public static void main(String[] args) {
    Thread t2 = new Thread(()->{
        while(true) {
            if(Thread.currentThread().isInterrupted()) {
                System.out.println(x);
                break;
            }
        }
	},"t2");
	t2.start();
    
	new Thread(()-> {
		sleep(1);
		x= 1;
		t2.interrupt();
    },"t1").start();
    
	while(!t2.isInterrupted()) {
        Thread.yield();
    }
    
	System.out.println(x);
}
```

- 对变量默认值(0，false，null)的写，对其它线程对该变量的读可见
- 具有传递性，如果x hb->y并且y hb-> 那么有x hb>，配合volatile的防指令重排，有下面的例子

```java
volatile static int x;
static int y;

new Thread(()->{
	y = 10;
	x= 20;
},"t1").start();

new Thread(()->{
    // x=29 对 t2 可见，同时 y=1 也对 t2 可见
    System.out.printIn(x);
}"t2").start();
```

#### 10、创建进程的方式

在 Java 中，创建线程的方式有四种：继承 Thread 类、实现 Runnable 接口、实现 Callable 接口和基于线程池创建。

1. 继承 Thread 类

继承 Thread 类是最基本的创建线程的方式。通过继承 Thread 类并重写 run 方法，可以定义自己的线程执行逻辑。该方式比较简单，但是如果需要继承其他类或需要多继承时就不适用了。

应用场景：在对于简单的并发需求，以及不需要跟其他对象进行交互和继承关系时使用。

2. 实现 Runnable 接口

实现 Runnable 接口是另一种创建线程的方式。通过实现 Runnable 接口并实现 run 方法，可以定义自己的线程执行逻辑。与继承 Thread 类相比，实现 Runnable 接口更加灵活，因为它允许在同一个类中实现多个接口。

应用场景：当需要实现多继承或与其他类进行交互时使用。

3. 实现 Callable 接口

实现 Callable 接口是 JDK5 新增的创建线程的方式，与 Runnable 接口相比，Callable 接口不仅可以定义线程执行逻辑，还可以返回执行结果。在使用 Callable 接口创建线程时，必须使用 `FutureTask` 类来包装 Callable 对象，并传递给 Thread 类的构造方法。

应用场景：当需要获取线程执行结果时使用。

4. 通过线程池创建线程

总体来说，对于简单的并发需求和不需要获取线程执行结果时，可以使用继承 Thread 类和实现 Runnable 接口。而如果需要获取线程执行结果，则应该使用实现 Callable 接口。

#### 11、一写多读模型的情况下怎么解决读写冲突的问题？

除了加锁之外，还有一些其他的方案来解决一写多读模型中的读写冲突问题。以下是其中几种常见的解决方案：

1. 无锁并发算法：使用无锁数据结构（如CAS操作）或者基于版本号的并发控制机制来实现，并发读取操作不需要互斥锁，只有写入操作需要保证互斥性。
2. 读写锁：读写锁会允许多个读操作同时进行，而在写操作时会阻塞所有的读写操作，因此可以提高读操作的并发度。
3. 信号量：使用信号量等同步机制，通过计数器的方式实现多个读操作和一个写操作之间的同步与互斥。
4. 消息队列：通过消息队列等通信机制，将读写操作分别放到不同的线程或进程中执行，从而避免了读写锁带来的性能问题。
5. 分离读写操作：将读写操作分别放到不同的数据结构中，这样就可以避免读写之间的冲突，但是需要考虑如何保持数据的一致性。

以上解决方案都有各自的优缺点，具体选择哪种方案需要根据应用场景来进行评估。

#### 12、park 和 unpark

LockSupport 是用来创建锁和其他同步类的**线程原语**

LockSupport 类方法：

- `LockSupport.park()`：暂停当前线程，挂起原语

- `LockSupport.unpark(暂停的线程对象)`：恢复某个线程的运行

与 Object 的 wait & notify 相比

- wait，notify 和 notifyAll 必须配合 Object Monitor 一起使用，而 park，unpark 不必

- park & unpark 是以线程为单位来【阻塞】和【唤醒】线程，而 notify 只能随机唤醒一个等待线程，notifyAll 是唤醒所有等待线程，就不那么【精确】

- park & unpark 可以先 unpark，而 wait & notify 不能先 notify

#### 13、死锁

线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。

产生死锁的四个必要条件：

1. 互斥条件：该资源任意一个时刻只由一个线程占用。
2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。

定位死锁：

- 检测死锁可以使用 jconsole工具，或者使用 jps 定位进程 id，再用 jstack 定位死锁：
- 如果由于某个线程进入了死循环，导致其它线程一直等待，对于这种情况 linux 下可以通过 top 先定位到CPU 占用高的 Java 进程，再利用 top -Hp 进程id 来定位是哪个线程，最后再用 jstack 排查。

------

[ 认识线程死锁](https://javaguide.cn/java/concurrent/java-concurrent-questions-01.html#%E8%AE%A4%E8%AF%86%E7%BA%BF%E7%A8%8B%E6%AD%BB%E9%94%81)

#### 14、锁升级

<img src="asset\锁升级.png" alt="image-20230418114942782" style="zoom: 80%;" />

**锁升级时，线程B获得轻量级锁后，持有偏向锁的线程A还未运行完，此时是A线程和B线程同时进入同步块吗？**

不是的，当线程B获得轻量级锁后，持有偏向锁的线程A还未运行完时，A线程会被挂起，等待B线程执行完同步块并释放锁之后再继续运行。这是因为，在锁升级的过程中，先获取到锁的线程会进入临界区，而其他竞争线程则需要等待第一个线程执行完毕才能进入临界区。

具体来说，当线程B获得轻量级锁后，它会尝试通过自旋来获取锁。如果自旋成功，则可以直接进入临界区执行操作，并在执行完毕之后释放锁。如果自旋失败，则会升级为重量级锁，并阻塞当前线程，让出CPU资源给其他线程使用。

此时，持有偏向锁的线程A就会被挂起，等待B线程执行完同步块并释放锁之后再继续运行。只有等到B线程释放锁之后，A线程才能重新竞争锁，并进入临界区执行操作。

### JVM

#### 1、所有的final修饰的字段都是编译期常量吗?

现在来看编译期常量和非编译期常量, 如：

```java
public class Test {
    // 编译期常量
    final int i = 1;
    final static int J = 1;
    final int[] a = {1,2,3,4};
    // 非编译期常量
    Random r = new Random();
    final int k = r.nextInt();

    public static void main(String[] args) {
		
    }
}
```

k的值由随机数对象决定，所以不是所有的final修饰的字段都是编译期常量，只是k的值在被初始化后无法被更改。

原文链接：https://pdai.tech/md/java/thread/java-thread-x-key-final.html

**常量和静态常量**

常量和静态常量在JVM角度的初始化和赋值有所不同。

首先，常量是在编译阶段就被赋值，并且它们的值在运行时不能被改变。因此，在编译阶段，编译器会将常量的值编译到字节码中。在类加载的过程中，常量会被加载到运行时常量池中。当程序需要使用常量时，实际上是从运行时常量池中取得其值。由于常量的值已经被编译到字节码中，因此在运行时不需要再次计算，直接使用即可。另外，对于final修饰的基本类型和字符串类型的变量，也会被视为常量。

而静态常量则是在类加载阶段进行初始化。静态常量一般是通过static final关键字来定义的，它们在类加载时就被初始化，并且在程序运行期间保持不变。在类加载的过程中，静态常量会被加载到类的常量池中。当程序需要使用静态常量时，就可以直接从常量池中获取其值，而无需重新计算。与常量不同的是，静态常量的值可以是任何类型，而不仅限于基本类型和字符串类型。

总之，**常量和静态常量都是在类加载时进行初始化**，并且它们的值在运行时不能被改变。不同之处在于，**常量的值在编译阶段就已经确定了，而静态常量的值则是在类加载时进行初始化的**。

**总结：**

final基础应用

- final修饰的变量地址值不能改变。
- final修饰的方法不能被重写。
- final修饰的类不能被继承。

并发编程中final可以禁止特定的重排序。

- final保证先写入对象的final变量，后调用该对象引用。
- final保证先读对象的引用，后读该对象的final变量。
- final保证先写入对象的final变量的成员变量，后调用该对象引用。

链接：https://blog.csdn.net/suifeng629/article/details/103042340

#### 2、JMM

**JMM**（[java内存模型](https://so.csdn.net/so/search?q=java内存模型&spm=1001.2101.3001.7020)）Java Memory Model，本身是一个抽象的概念，**不是真实存在的**，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段、静态字段和构成[数组](https://so.csdn.net/so/search?q=数组&spm=1001.2101.3001.7020)对象的元素）的**访问方式**。

JMM同步规定：

（1）线程解锁前，必须把共享变量的值刷新回主内存

（2）线程加锁前，必须读取主内存的最新值到自己的工作内存

（3）加锁解锁是同一把锁

由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方成为栈空间)，**工作内存是每个线程的私有**数据区域，而Java内存模型中规定所有变量都存储在主内存，**主内存是共享内存区域**，所有线程都可访问，但**线程对变量的操作**(读取赋值等)**必须在工作内存**中进行，首先要**将变量从主内存拷贝到自己的工作空间，然后对变量进行操作，操作完成再将变量写回主内存** ，不能直接操作主内存中的变量，各个线程中的工作内存储存着主内存中的变量副本拷贝，因此不同的线程无法访问对方的工作内存，线程之间的通讯(传值) 必须通过主内存来完成,其简要访问过程如下图:

<img src="asset\JMM.png" alt="请添加图片描述" style="zoom:80%;" />

**为什么要有内存模型？**
在传统计算机硬件内存架构中由于CPU 和主内存间存在数量级的速率差，想到了引入了多级高速缓存的传统硬件内存架构来解决，多级高速缓存作为 CPU 和主内间的缓冲提升了整体性能。解决了速率差的问题，却又带来了缓存一致性问题。数据同时存在于高速缓存和主内存中，如果不加以规范势必造成灾难，因此在传统机器上又抽象出了内存模型

<img src="asset\CPU缓存模型.png" alt="请添加图片描述" style="zoom:50%;" />

**JMM内存模型**
Java 语言在遵循内存模型的基础上推出了 JMM 规范，JMM内存模型正是对多线程操作下的一系列规范约束，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。主要目的是为了简化多线程编程，增强程序可移植性的。

为了更精准控制工作内存和主内存间的交互，JMM 还定义了八种操作：lock, unlock, read, load, use, assign, store, write。

```shell
lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占的状态。
unclock（解锁）：作用于主内存的变量，把一个处于锁定的状态释放出来。
read（读取）：作用于主内存的变量，把一个变量的值从主内存传输到线程的工作内存中
load（载入）：作用于工作内存的变量，把read操作从主内存 得到的变量值放入工作内存的变量副本中。
use（使用）：作用于工作内存的变量，把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。
assign（赋值）：作用于工作内存的变量，把一个从执行引擎接收到的值 赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。
store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传递到主内存，以便write操作使用。
write（写入）：作用于主内存的变量，把store操作从工作内存中得到的变量的值放入主内存的变量中。
```

**原子性**：Java内存模型通过 read、load、assign、use、store、write 来保证原子性操作，此外还有lock和unlock，直接对应着synchronized 关键字的 monitorenter 和 monitorexit 字节码指令。

**可见性**：可见性的问题在上面的回答已经说过，Java保证可见性可以认为通过volatile、synchronized、final来实现。

**有序性**：由于处理器和编译器的重排序导致的有序性问题，Java通过volatile、synchronized来保证。

**happen-before 规则**

虽然指令重排提高了并发的性能，但是Java虚拟机会对指令重排做出一些规则限制，并不能让所有的指令都随意的改变执行位置，主要有以下几点：

1. 单线程每个操作，happen-before于该线程中任意后续操作

2. volatile写happen-before与后续对这个变量的读

3. synchronized解锁happen-before后续对这个锁的加锁

4. fifinal变量的写happen-before于fifinal域对象的读，happen-before后续对final变量的读

5. 传递性规则，A先于B，B先于C，那么A一定先于C发生

**说了半天，到底工作内存和主内存是什么？**

主内存可以认为就是物理内存，Java内存模型中实际就是虚拟机内存的一部分。而工作内存就是CPU缓存，他有可能是寄存器也有可能是L1\L2\L3缓存，都是有可能的。

————————————————
原文链接：https://blog.csdn.net/m0_67390963/article/details/126741163

​				https://blog.csdn.net/qq_35757264/article/details/124493844

#### 3、共享内存区划分
1. 共享内存区 = 持久代 + 堆（注;jdk1.8及以上jvm废弃了持久代） 

2. 持久带代= 方法区 + 其他

3. Java堆 = 老年代 + 新生代

4. 新生代 = Eden(伊甸区) + S1（幸存1） + S2（幸存2）

<img src="asset\堆.png" alt="img" style="zoom: 50%;" />

#### 4、为什么分年老代和新生代
1. 新生代(Young Gen)：年轻代主要存放新创建的对象，内存大小相对会比较小，垃圾回收会比较频繁。年轻代分成1个Eden Space和2个Suvivor Space（from 和to）。
2. 老年代(Tenured Gen)：年老代主要存放JVM认为生命周期比较长的对象（经过几次的Young Gen的垃圾回收后仍然存在），内存大小相对会比较大，垃圾回收也相对没有那么频繁。

#### 5、为什么要分为Eden和Survivor?为什么要设置两个Survivor区？

1. 如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代。老年代很快被填满，触发Major GC.老年代的内存空间远大于新生代，进行一次Full GC消耗的时间比Minor GC长得多,所以需要分为Eden和Survivor。

2. Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。

3. 设置两个Survivor区最大的好处就是**减少内存碎片化，提高内存的使用效率**，刚刚新建的对象在Eden中，经历一次Minor GC，Eden中的存活对象就会被移动到第一块survivor space S0，Eden被清空；等Eden区再满了，就再触发一次Minor GC，Eden和S0中的存活对象又会被复制送入第二块survivor space S1（这个过程非常重要，因为这种复制算法保证了S1中来自S0和Eden两部分的存活对象占用连续的内存间，避免了碎片化的发生）。

————————————————
   原文链接：https://blog.csdn.net/illovesoftware/article/details/119490775

#### 6、Java 内存区域和 JMM 有何区别？

这是一个比较常见的问题，很多初学者非常容易搞混。 **Java 内存区域和内存模型是完全不一样的两个东西** ：

- JVM 内存结构和 Java 虚拟机的运行时区域相关，定义了 JVM 在运行时如何分区存储程序数据，就比如说堆主要用于存放对象实例。
- Java 内存模型和 Java 的并发编程相关，抽象了线程和主内存之间的关系就比如说线程之间的共享变量必须存储在主内存中，规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性的

#### 7、打破双亲委派

双亲委派机制是 Java 类加载机制的一个核心概念，它规定了父类加载器优先加载类的原则。破坏双亲委派机制可能会引发一些安全问题和类加载冲突问题，因此一般情况下不建议破坏双亲委派机制。以下是一些可能破坏双亲委派机制的方法：

重写 ClassLoader 的 loadClass() 方法：在重写 loadClass() 方法时，可以将类的加载交给子类加载器来完成，从而破坏双亲委派机制。例如，可以在 Web 应用程序的 ClassLoader 中重写 loadClass() 方法，使得它可以从 Web 应用程序中加载类。

使用 `Thread.currentThread().setContextClassLoader()` 方法：该方法可以在当前线程中设置上下文类加载器，使得类的加载可以交给指定的类加载器来完成，从而破坏双亲委派机制。例如，可以在某个 Web 应用程序中设置上下文类加载器为 Web 应用程序的 `ClassLoader`。

使用 Java 反射机制：使用 Java 反射机制可以在运行时动态创建并加载类，从而破坏双亲委派机制。例如，可以使用 `Class.forName()` 方法或 `ClassLoader.defineClass()` 方法来加载类。

基于SPI机制打破双亲委派：

> SPI（Service Provider Interface）机制是Java中一种服务提供者接口的规范，通过该规范，应用程序可以动态加载实现某个接口的类，从而实现灵活的扩展功能。
>
> 在Java中，类加载器采用双亲委派模型来加载类，即先委派给父类加载器，如果父类加载器无法加载，则由自身加载。这样可以保证类的唯一性和安全性，避免不同类加载器之间的类冲突。
>
> 但是，对于某些实现了SPI机制的接口，其实现类是由第三方库提供的，使用双亲委派模型会导致这些实现类无法被加载。因此，Java的SPI机制打破了双亲委派模型，采用了一种非常简单的机制来加载接口实现类：在classpath下创建一个META-INF/services目录，然后在该目录下创建以服务接口全限定名为名称的文件，文件内容为实现类的全限定名，每行一个，当Java需要加载某个服务接口的实现类时，就会读取该文件并加载其中指定的类。
>
> SPI机制的优点在于，它支持动态发现、装载和卸载服务实现类，使得应用程序可以更加灵活地扩展功能。同时，SPI机制采用了基于接口的编程思想，降低了应用程序与具体实现类之间的耦合度。但是，也需要注意控制第三方库的使用，避免因为SPI机制的灵活性导致安全问题和代码混乱。

需要注意的是，破坏双亲委派机制可能会引发一些安全问题和类加载冲突问题，因此应该谨慎使用。如果需要破坏双亲委派机制，可以通过设置安全策略和使用合适的类加载器来规避这些问题。

链接：https://blog.csdn.net/qq_38158422/article/details/131391691?spm=1001.2014.3001.5506

----

打破双亲委派的方式：

1、自定义类加载器，重写 loadClass 方法，阻止原有的向父类加载器提交加载请求；**（不委派）**

2、SPI机制，即 父类加载器请求子类加载器加载需要的类，两类加载器不一致：**（向下委派）**

- 在某些情况下**父类加载器需要委托子类加载器**去加载class文件。受到加载范围的限制，父类加载器无法加载到需要的文件。
- 以Driver接口为例，DriverManager通过Bootstrap ClassLoader加载进来的，而com.mysql.jdbc.Driver是通过Application ClassLoader加载进来的。由于双亲委派模型，父加载器是拿不到通过子加载器加载的类的。这个时候就需要启动类加载器来委托子类来加载Driver实现，从而破坏了双亲委派。
  https://blog.csdn.net/qq_39404258/article/details/112065471

> 第一，获取线程上下文类加载器，从而也就获得了应用程序类加载器（也可能是自定义的类加载器）
>
> 第二，从META-INF/services/java.sql.Driver文件中获取具体的实现类名“com.mysql.jdbc.Driver”
>
> 第三，通过线程上下文类加载器去加载这个Driver类，从而避开了双亲委派模型的弊端
>
> 原文链接：https://blog.csdn.net/qq_38158422/article/details/131391691

#### 8、什么情况下会触发Full GC？

**Minor GC触发条件：**当Eden区满时，触发Minor GC。

**Full GC触发条件：** 

​	（1）调用System.gc时，系统建议执行Full GC，但是不必然执行 

​	（2）老年代空间不足 

​	（3）方法去空间不足 

​	（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存

​	（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。

---

Full GC一般来说指的是全堆和方法区的垃圾收集。
从大的方面来说，Full GC发生的条件主要可以分为两类。

1. 因为对象在自然情况下到达老年代导致的老年代空间不足

   1. 对象熬过15次垃圾收集，到达晋升到老年代的标准，而晋升到老年代，而**老年代的空间不足**以放下这些内容，会触发Full GC
   2. 由于对象动态年龄判定，而晋升到老年代
   3. 大对象直接进入老年代， 而导致的空间不足
   4. **空间分配担保**， 在进行GC时，最坏的情况是此时Survivor区的对象全部存活着，则to0区和survivor的对象要进入老年代。所以，在进行minor Gc前要检查老年代的最大连续可用空间是否大于年轻代的所有对象总和，如果大于，则可以确保这次垃圾收集是安全的。如果不大于，并且不允许空间分配担保，则要进行Full Gc. 如果不大于，且允许进行空间分配担保，再看看是否大于历次晋升的平均大小，如果大于，则进行一次有“风险”的Minor GC。否则进行Full GC。
      在jdk1.6后，空间分配担保与这个参数无关。只要老年代最大连续可用空间大于新生代对象的大小或者平均大小，就会进行minor gc
   5. **方法区空间不足**
   6. **System.gc()** ，建议执行，不一定会执行

2. 因为在一些特殊情况下的空间不足导致的。

   1. 在CMS垃圾收集器中,由于浮动垃圾的出现，会预留一部分的老年代空间用来承载运行中的用户程序。当达到这个设定的阈值之后，会进行Full GC。
   2. CMS是基于标记-清除算法的，会产生内存碎片问题，当进行若干次GC后，会进行一次Full GC用来合并内存空间。

   原文链接：https://blog.csdn.net/qq_39800266/article/details/122821986

#### 9、GC分类

**GC分类**

我们现在先对其进行逐一分类：

- partial GC: 代表局部垃圾回收，可以有如下细分：

- - young GC（Minor GC）： 指的是对新生代区域垃圾回收
  - old GC：指的是收集老年代，只有 CMS 的 concurrent collection是这个模式
  - Mixed GC：收集整个新生代，和部分老年代，只有G1有这个模式

- Full GC：收集整个过程，包括新生代、老年代、永久代（JDK8之前）

Major GC：可以是指 old GC 也可以是指 Full GC。这是因为JVM规范没有对这些名词有具体的定义，时间久了后就使用混乱了。所以如果讨论 Major GC 的时候需要指定前提到底是讨论的是 old GC 还是 Full GC，比如周志明版的《深入理解虚拟机》就把 old GC 统称为 【Major GC / Full GC】更加不做区分了，这里我们先按照 old GC == Major GC 讨论

**对象分配**

这里我们先回顾一下虚拟机堆内存图：

![img](https://pic3.zhimg.com/80/v2-379f045efadbf8170df3e039b0e2cf56_720w.webp)

首先对象一般都是在新生代中分配的，而且是在 Eden 区中。

一些大对象，比如数组，长字符串等会在老年代中分配，虚拟机提供了一个 -XX:PretenureSize 参数，如果对象大于这个设置的值就直接在老年代分配。

长期存活的对象将进入老年代，这里指的是当 Eden 区达到一定的比例后不能创建新对象，则触发垃圾回收(young GC)，将无用对象清理掉，然后剩余对象复制到某个 Survivor1(S1) 中，同时清空Eden区。

当Eden区再次满了，会再次将 Eden 中的不能清空的对象存到另外一个 Survivor2(S2)， 同时将S1区中的不能清空的对象，也复制到S2中，保证Eden和S1，均被清空。

重复多次(默认15次)Survivor中没有被清理的对象，则会复制到老年代Old(Tenured) 区中。对于晋升老年代的年龄阈值可以用 -XX:MaxTenuringThreshold 设置。

**触发young GC**

由于对象一般情况下是直接在新生代中的 Eden 区进行分配，如果Eden区域没有足够的空间，那么就会触发young GC（Minor GC）。因为 Java 对象大多数具备朝生夕死的特性，所以 young GC（Minor GC）会非常频繁，回收速度也非常快。

**触发Full GC**

Full GC 相对于 Minor GC 来说，停止用户线程的 STW（stop the world）时间过长，至少慢10倍以上，所以要尽量避免，首先说一下Full GC可能产生的原因，接着给出排查方法以及解决策略。

在代码中调用System.gc()方法会建议JVM进行Full GC，但是注意这只是建议，JVM执行不执行是另外一回事儿，不过在大多数情况下会增加Full GC的次数，导致系统性能下降，一般建议不要手动进行此方法的调用，可以通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc。

在YGC之前，会先检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。如果小于，说明YGC是不安全的，则会查看参数 HandlePromotionFailure 是否被设置成了允许担保失败，如果不允许则直接触发Full GC；如果允许，那么会进一步检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果小于也会触发 Full GC

Metaspace（元空间）在空间不足时会进行扩容，当扩容到了-XX:MetaspaceSize 参数的指定值时，也会触发FGC

**Major GC/Old GC**

老年代会在两种情况下触发 Old GC：一是开启分配担保机制，根据历次 Minor GC 后进入老年代的对象大于当前老年代内存大小，判断 Minor GC 有风险，则会触发 Old GC；二是 Minor GC 后剩余对象太多，老年代放不下了也会触发 Old GC。

**Mixed GC**

Mixed GC是G1中特有的概念，当老年代内存占据到了45%就户触发Mixed GC，对新生代和老年代都进行回收。

#### 10、5种方法调用指令

非虚方法:

- 如果方法在编译期就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法。
- 静态方法、私有方法、final方法、实例构造器、父类方法都是非虚方法。

 其他方法称为虚方法

- 子类对象的多态性的使用前提：①类的继承关系；②方法的重写

---

虚拟机中提供了以下几条方法调用指令:

- 普通调用指令:

  1. invokestatic: 调用静态方法，解析阶段确定唯一方法版本
  2. invokespecial: 调用<init>方法、私有及父类方法，解析阶段确定唯一方法版本
  3. invokevirtual: 调用所有虚方法
  4. invokeinterface:调用接口方法

- 动态调用指令:

  5. invokedynamic:动态解析出需要调用的方法，然后执行


前四条指令固化在虚拟机内部，方法的调用执行不可人为干预，而invokedynamic指令则支持由用户确定方法版本。其中invokestatic指令和invokespecial指令调用的方法称为非虚方法，其余的（final修饰的除外，final方法调用使用的是`invokevirtual`，但是`final`方法不能重写，所以认为`final`是非虚方法）称为虚方法。

Lambda 表达式简化了匿名内部类的形式，可以达到同样的效果，但是 Lambda 要优雅的多。虽然最终达到的目的是一样的，但其实内部的实现原理却不相同。

**匿名内部类在编译之后会创建一个新的匿名内部类出来，而 Lambda 是调用 JVM `invokedynamic`指令实现的，并不会产生新类**。

https://mp.weixin.qq.com/s/MqYgxoqL4EPPg4luDqLXUg

---

动态类型语言和静态类型语言

- 动态类型语言和静态类型语言两者的区别就在于对类型的检查是在编译期还是在运行期，满足前者就是静态类型语言，反之是动态类型语言。
- 说的再直白一点就是，静态类型语言是判断变量自身的类型信息:动态类型语言是判断变量值的类型信息，变量没有类型信息，变量值才有类型信息,这是动态语言的一个重要特征。

JVM字节码指令集一直比较稳定，一直到Java7中才增加了一个invokedynamic指令，这是Java为了实现[动态类型语言] 支持而做的种改进。

但是在Java7中并没有提供直接生成invokedynamic指令的方法，需要借助ASM这种感层字节码工具来产生invokedynam1c指令。直到Java8的Lambda表达式的出现，invokedynamic指令的生成，在Java中才有了直接的生成方式。

Java7中增加的动态语言类型支持的本质是对Java虚拟机规范的修改，而不是对Java语言规则的修改，这一块相对来讲比较复杂，增加了虚拟机中的方法调用，最直接的受益者就是运行在Java平台的动态语言的编译器。

#### 11、GC频繁的原因

**YoungGC频繁**

- 危害
  - GC线程消耗的CPU时间过多，容易触发Linux CFS 限制进程的CPU
  - 虽然单次GC停顿较短，但频次高了之后，整个服务的吞吐量会下降
  - GC过于频繁，慢请求产生的临时对象经过几轮YoungGC后容易晋升到老年代
- 原因
  1. Eden区空间过小
  2. 大批量加载数据
  3. 内存分配速率过高

**FullGC频繁**

- 危害
  1. 机器 cpu 负载过高 
  2. 频繁 full gc 告警 
  3. 系统无法请求处理或者过慢， 接口无关  全面性的

- 原因
  1. YGC频繁，晋升对象过多导致（合理分配内存，调大Survivor区）
  2. 空间分配担保机制
  3. System.gc()
  4. 分配大对象过多
  5. 发生内存泄漏，大量对象占用老年代（dump出内存快照，用MAT工具进行分析）
  6. Metaspace加载类过多，导致发生fgc

处理流程（SOP）

![img](asset\整体 GC 问题普适的处理流程.jpg)

![img](asset\根因鱼骨图.png)

[GC原理介绍、排查FGC及线上故障的步骤](https://cloud.tencent.com/developer/article/1953209)

https://tech.meituan.com/2020/11/12/java-9-cms-gc.html

#### 12、Java代码如何在机器上运行？

一句话来总结Java程序是怎么在机器上运行的呢？首先Java程序员编写Java代码，然后Java代码会被编译成class文件，多个class文件会被打包成jar包或者war包。然后JVM加载class文件，然后先解释执行为字节码。程序运行一段时间后，JVM会通过方法调用次数和循环持续判断一个方法是否为热点代码，如果是，会使用分层编译，通过编译线程编译成字节码，在机器上运行。

链接：[Java代码如何在机器上运行？](https://mp.weixin.qq.com/s?__biz=MzI5OTkwODczNw==&mid=2247485571&idx=1&sn=ec8de7975fac9c2142d9a3048f4a74bc&chksm=ec8e236ddbf9aa7b8986bbaeb714d915860545775df395764b088c9af9ca95636c7a6eb73f8f&cur_album_id=1790630490127794178&scene=189#wechat_redirect) 

#### 13、静态类的加载过程



#### 14、类的加载方式

类加载分为**动态加载**和**静态加载**。动态加载是从外存储器中加载类，一般类加载机制分析的也是动态加载。而静态加载本质上是从内存中创建类的实例对象，此时类已经被加载到内存中。

一.静态加载

1. 通过new关键字来创建Test的实例对象。

二.动态加载

1. 通过Class.forName()来加载类，然后调用类的newInstance()方法实例化对象。

2. 通过类加载器的loadClass()方法来加载类，然后调用类的newInstance()方法实例化对象。

链接：https://blog.csdn.net/weixin_42447959/article/details/81255112

#### 15、方法解析

绑定指的是一个方法的调用与方法所在的类(方法主体)关联起来。对java来说，绑定分为静态绑定和动态绑定。

静态绑定：在程序执行前方法已经被绑定（也就是说在编译过程中就已经知道这个方法到底是哪个类中的方法），此时由 编译器或其它连接程序实现。

动态绑定： 在运行时根据具体对象的类型进行绑定。

原文链接：https://blog.csdn.net/fbgbhvgv/article/details/127862780

**1 重写与重载**

Java 虚拟机识别方法的关键在于类名、方法名以及方法描述符(方法的参数类型以及返回类型)，同一个类中有相同方法名以及方法描述符在验证阶段就会报错。

JAVA对方法重写的解析只验证方法参数，而JVM会额外验证返回类型。如果参数相同而返回类型不同时，JVM会额外生成一个桥接方法来实现重写语义。

对方法的重载是在编译阶段完成，对于JVM而言是不存在重载的概念。

Java 虚拟机中的**静态绑定**指的是在解析时便能够直接识别目标方法的情况，而**动态绑定**则指的是需要在运行过程中根据调用者的动态类型来识别目标方法的情况

**动态绑定**过程：
 <1>虚拟机提取对象的实际类型的方法表。
 <2>虚拟机搜索方法签名，此时虚拟机已经知道应该调用哪种方法。（PS：方法的签名包括了：1.方法名 2.参数的数量和类型~~~~返回类型不是签名的一部分。）
 <3>虚拟机调用方法

PS:由于动态绑定需要在运行时确定执行哪个版本的方法实现或者变量，比起静态绑定起来要耗时。

[多态实现原理](https://blog.csdn.net/chuige2013/article/details/129744123)

**2 引用解析**

具体来说，Java 字节码中与调用相关的指令共有五种。

1. invokestatic：用于调用静态方法。
2. invokespecial：用于调用私有实例方法、构造器，以及使用 super 关键字调用父类的实例方法或构造器，和所实现接口的默认方法。
3. invokevirtual：用于调用非私有实例方法。
4. invokeinterface：用于调用接口方法。
5. invokedynamic：用于调用动态方法。

在编译过程中，我们并不知道目标方法的具体内存地址。因此，Java编译器会暂时用符号引用来表示该目标方法，存储在运行时常量池中。在执行前会解析符号引用替换为实际引用。

对于 invokestatic 以及 invokespecial 而言，Java 虚拟机能够直接识别具体的目标方法， 这个过程是静态绑定的。

而对于 invokevirtual 以及 invokeinterface 而言，在绝大部分情况下，虚拟机需要在执行过程中，根据调用者的动态类型，来确定具体的目标方法。

**3 虚方法**

JAVA里所有**非私有的实例方法**调用都会被编译成 invokevirtual 指令，**接口方法**调用会被编译成为 invokeinterface 指令。这两种指令都是虚方法调用。

JVM需要根据调用者的动态类型，来确定虚方法调用的目标方法，这个过程称之为动态绑定。

> 方法表

JVM采用了一种空间换时间的策略来实现动态绑定：它为每一个类都生成一张**方法表**， invokevirtual使用的是虚方法表(vtable),接口使用的是接口方法表(itable)。
方法表本质上是一个数组，每个数组元素指向一个当前类及其祖先类中非私有的实例方法，可以是具体的方法也可以是抽象方法，其满足：

- 子类方法表包含父类方法表的全部方法
- 子类方法在方法表中的索引值，与其所重写的父类方法的索引值相同

静态绑定的方法解析将实际引用将指向具体的目标方法；而动态绑定的方法调用将实际引用指向**方法表的索引值**。

动态绑定过程：执行时JVM获取调用者的实际类型，在该类型对应的方法表中根据索引获取目标方法。

> 内联缓存

内联缓存是一种加快动态绑定的优化技术。它能够缓存虚方法调用中调用者的动态类型，以及该类型所对应的目标方法。

- 单态内联缓存：只缓存了一种动态类型以及它所对应的目标方法
- 多态内联缓存：则缓存了多个动态类型及其目标方法，更热门的动态类型放在前面
- 超多态内联缓存：缓存不命中的一种选择，直接访问方法表，来动态绑定目标方法。

**4 invokedynamic指令**

invokedynamic该指令的调用机制抽象出调用点这一个概念，并允许应用程序将调用点链接至任意符合条件的方法上。

- **方法句柄MethodHandle**是一个强类型的，能够被直接执行的引用。该引用可以指向常规的静态方法或者实例方法，也可以指向构造器或者字段。当指向字段时，方法句柄实则指向包含字段访问字节码的虚构的 getter 或者 setter 方法（不是真实的方法）。
- 方法句柄的类型（MethodType）是由所指向方法的参数类型以及返回类型组成的。用来确认方法句柄是否适配，不关注方法句柄指向的类名和方法名。

invokedynamic将调用点(CallSite)抽象为一个JAVA类，并将原本由JVM控制的方法调用和方法链接暴露给应用程序。运行时每一条 invokedynamic 指令将捆绑一个调用点，并调用该调用点连接的方法句柄。

1. 第一次调用该命令，JVM调用该指令所对应的启动方法来生成调用点，并绑定至该指令中。
2. 之后运行，JVM会直接调用绑定的调用点所链接的方法句柄。
3. 启动方法通过方法句柄指定，方法句柄指向一个返回类型为调用点的静态方法，该方法必需三个参数： Lookup 类实例、指代目标方法的字符串、调用点能够链接的MethodType。

在JDK8的 Lambda 表达式的实现原理也是借助invokedynamic 来实现的：Java 编译器利用 invokedynamic 指令来生成实现了函数式接口的适配器。编译过程中生成一个方法来保存 Lambda 表达式的内容（包括表达式参数以及捕获的变量），捕获的变量需要为final（原理同方法内部类）

#### 16、new 一个对象和反序列一个对象有什么区别？

`new`一个对象和反序列化一个对象都涉及到对象的创建和初始化，但它们在实现方式和应用场景上有一些区别。

1. `new`一个对象：这是在程序中直接通过调用构造函数来创建新的对象实例。使用`new`关键字可以分配内存并初始化对象的各个属性和状态。这种方式适用于在程序执行过程中需要即时创建和使用对象的情况。

   ```java
   MyClass obj = new MyClass(); // 使用new关键字创建MyClass类的实例
   ```

2. 反序列化一个对象：这是将对象从持久化的状态（如文件、数据库、网络传输）中读取并还原成对象实例的过程。对象在序列化时会被转换成字节流或其他形式的持久化数据，反序列化则是将持久化数据重新转换回对象。这种方式适用于需要将对象存储和传输的场景，可以实现对象的持久化和跨系统的数据传递。

   ```java
   FileInputStream fileIn = new FileInputStream("object.ser");
   ObjectInputStream in = new ObjectInputStream(fileIn);
   MyClass obj = (MyClass) in.readObject(); // 从文件中反序列化对象
   in.close();
   fileIn.close();
   ```

总结来说，`new`一个对象适用于在程序运行时动态创建对象，而反序列化一个对象适用于将对象从持久化状态还原为内存中的对象实例。`new`操作是在内存中直接创建对象，而反序列化操作则是通过读取持久化数据恢复对象。

#### 17、记忆集

**记忆集和卡表**

为了解决对象跨代引用所带来的问题，垃圾收集器在新生代中建立了名为记忆集(Remembered Set)的数据结构，用以避免把整个老年代加进GC Roots扫描范围。事实上并不是只是新生代、老年代之间才有跨代引用的问题，所有涉及部分区域收集行为的垃圾收集器，典型如G1,ZGC收集器，都会面临相同的问题，因此我们有必要进一步理清记忆集的原理和实现方式。

**记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构。**下面列举了一些可供选择的记录精度，由高到低依次为：

- 字长精度：每个记录精确到一个机器字长(就是处理器的寻址位数，如常见的32位或64位，这个精度决定了机器访问物理内存地址的指针长度)，该字包含跨代指针。
- 对象精度：每个记录精确到一个对象，该对象里有字段含有跨代指针。
- 卡精度：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。卡精度所指的是用一种称为"卡表"(caed table)的方式实现记忆集，是目前最常用的一种实现方式，卡表与记忆集的关系，类似于Java语言中HashMap与Map的关系。

卡表技术是指：将整个堆划分为一个个指定大小的内存块，这个内存块称为"卡页"，卡页大小在HotSpot中默认为**512**字节，并且维护一个卡表(可以是一个字节数组)。一个卡页的内存中通常包含不止一个对象，只要卡页内有一个(或多个)对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为1，称为这个元素变脏(Dirty),没有则标识为0。

有了卡表之后，我们看看其在实际应用中是怎么工作的。比如在进行Minor GC的时候，我们便不用扫描整个老年代对象，而是在卡表中寻求脏卡，并将脏卡中的对象加入到Minor GC的GC Roots里(Minor GC时JVM将从脏卡中的对象查找，作为GC Roots)。当完成所有脏卡的扫描之后，Java虚拟机便会将所有脏卡的标识位清零。
由于 Minor GC 伴随着存活对象的复制，而复制需要更新指向该对象的引用。因此，在更新引用的同时，我们又会设置引用所在的卡的标识位。

**卡表其实是记忆集的一种实现方式。**
————————————————
原文链接：https://blog.csdn.net/xs925048899/article/details/128922406

### 计算机网络

```
URG：(URGent)紧急
ACK：(ACKnowledgment)确认
PSH：(PuSH)推送
RST：(ReSeT)复位
SYN：(SYNchronization sequence number) 同步序列号
FIN:（FINish）终止
```

```
CLOSED 表示socket连接没被使用。 
LISTENING 表示正在监听进入的连接。 
SYN_SENT 表示正在试着建立连接。 
SYN_RECEIVED 进行连接初始同步。 
ESTABLISHED 表示连接已被建立。 
CLOSE_WAIT 表示远程计算机关闭连接，正在等待socket连接的关闭。 
FIN_WAIT_1 表示socket连接关闭，正在关闭连接。 
CLOSING 先关闭本地socket连接，然后关闭远程socket连接，最后等待确认信息。 
LAST_ACK 远程计算器关闭后，等待确认信号。 
FIN_WAIT_2 socket连接关闭后，等待来自远程计算器的关闭信号。 
TIME_WAIT 连接关闭后，等待远程计算器关闭重发。
MSL：(Maximum Segment Lifetime)
```

Redis-原理篇

#### 1、select、poll 和 epoll

​        select，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。 但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

​        select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。

​        select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。

目前流程的多路复用IO实现主要包括四种: `select`、`poll`、`epoll`、`kqueue`。下表是他们的一些重要特性的比较:

| IO模型 | 相对性能 | 关键思路         | 操作系统      | JAVA支持情况                                                 |
| ------ | -------- | ---------------- | ------------- | ------------------------------------------------------------ |
| select | 较高     | Reactor          | windows/Linux | 支持,Reactor模式(反应器设计模式)。Linux操作系统的 kernels 2.4内核版本之前，默认使用select；而目前windows下对同步IO的支持，都是select模型 |
| poll   | 较高     | Reactor          | Linux         | Linux下的JAVA NIO框架，Linux kernels 2.6内核版本之前使用poll进行支持。也是使用的Reactor模式 |
| epoll  | 高       | Reactor/Proactor | Linux         | Linux kernels 2.6内核版本及以后使用epoll进行支持；Linux kernels 2.6内核版本之前使用poll进行支持；另外一定注意，由于Linux下没有Windows下的IOCP技术提供真正的 异步IO 支持，所以Linux下使用epoll模拟异步IO |
| kqueue | 高       | Proactor         | Linux         | 目前JAVA的版本不支持                                         |

多路复用IO技术最适用的是“高并发”场景，所谓高并发是指1毫秒内至少同时有上千个连接请求准备好。其他情况下多路复用IO技术发挥不出来它的优势。另一方面，使用JAVA NIO进行功能实现，相对于传统的Socket套接字实现要复杂一些，所以实际应用中，需要根据自己的业务需求进行技术选择。

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/java/io/java-io-nio-select-epoll.html

​        原文链接：https://blog.csdn.net/qq_51074048/article/details/126237233

​		视频链接：https://www.bilibili.com/video/BV1r54y1f7bU/?spm_id_from=trigger_reload&vd_source=8f6745987f6d9c4a333570852e433d6c

​        链接：https://xiaolincoding.com/os/8_network_system/selete_poll_epoll.html

​	[原理篇.md](D:\BaiduNetdiskDownload\黑马\Redis\04-原理篇\讲义\原理篇.md)

#### 2、HTTP和HTTPS是什么？
**HTTP**：

超文本传输协议（Hyper Text Transfer Protocol，HTTP）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。

**HTTPS**：
HTTPS （全称：Hyper Text Transfer Protocol over SecureSocket Layer），是以安全为目标的 HTTP 通道，在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性。HTTPS 在HTTP 的基础下加入SSL，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。

**SSL**：
SSL(Secure Sockets Layer 安全套接字协议),及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。TLS与SSL在传输层与应用层之间对网络连接进行加密。
————————————————
原文链接：https://blog.csdn.net/moer0/article/details/122903635

[https证书无效的原因及解决方法](https://cloud.cmy.cn/news/article/72605.html)

#### 3、HTTP和HTTPS的区别？

Http协议和Https协议的区别：传输信息安全性不同、连接方式不同、URL前缀不同、端口不同、证书专申请方式不同、性能不同。

1. HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 SSL 加密传输协议， 数据传输过程是加密的，安全性较好。
2. HTTPS  协议需要到 CA （Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用。
3. HTTP 页面响应速度比 HTTPS 快，主要是因为 HTTP 使用 TCP 三次握手建立连接，客户端和服务器需要交换 3 个包，而 HTTPS除了 TCP 的三个包，还要加上 ssl 握手需要的 9 个包，所以一共是 12 个包。
4. URL 前缀 ：HTTP 的 URL 前缀是 http://，HTTPS 的 URL 前缀是 https://。
5. HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。HTTPS 其实就是建构在 SSL/TLS 之上的 HTTP 协议，所以，要比较 HTTPS 比 HTTP 要更耗费服务器资源。
6. HTTP 的连接很简单，是无状态的。HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。(无状态的意思是其数据包的发送、传输和接收都是相互独立的。无连接的意思是指通信双方都不长久的维持对方的任何信息。)

HTTPS的特点

> 数据保密性：保证数据内容在传输的过程中不会被第三方查看 
> 数据完整性：防止传输的内容被中间人冒充或者篡改 
> 身份校验安全性：通过证书认证客户端访问的是自己的服务器，保证数据到达用户期望的目的地

HTTPS连接过程

<img src="asset\HTTPS1.png" alt="在这里插入图片描述" style="zoom:80%;" />

<img src="asset\HTTPS2.png" alt="img" style="zoom:80%;" />

<img src="asset\HTTPS3.png" alt="在这里插入图片描述" style="zoom:50%;" />

```
1、客户端向服务端发起https请求；
2、服务端生成公钥和私钥；
3、服务端将数字证书（公钥）返回给客户端；
4、客户端进行合法性校验，失败直接提示；
5、校验合法，随机生成双方进行数据通信的 对称加密 的密钥K；
6、使用证书中的公钥传送加密后的 密钥K；
7、服务端使用私钥进行解密获取 密钥K；
8、服务端使用 密钥K 加密网页内容然后返回给客户端；
9、客户端使用 密钥K 解密网页内容并显示。
------
非对称加密：加密客户端传输将来进行进行对称加密通信的 密钥K；（一次）
对称加密：使用 密钥K 进行对称加密数据传输。（无限制）
```

**加密方式：**

使用 SSL/TLS 进行通信的双方需要使用非对称加密方案来通信，但是非对称加密设计了较为复杂的数学算法，在实际通信过程中，计算的代价较高，效率太低，因此，SSL/TLS 实际对消息的加密使用的是对称加密。

> 对称加密：通信双方共享唯一密钥 k，加解密算法已知，加密方利用密钥 k 加密，解密方利用密钥 k 解密，保密性依赖于密钥 k 的保密性。

使用非对称加密，对对称加密的密钥进行加密，保护该密钥不在网络信道中被窃听。这样，通信双方只需要一次非对称加密，交换对称加密的密钥，在之后的信息通信中，使用绝对安全的密钥，对信息进行对称加密，即可保证传输消息的保密性。

————————————————
		原文链接：https://blog.csdn.net/qq_38289815/article/details/80969419

​						   https://blog.csdn.net/weixin_48960759/article/details/122827574

​						   https://blog.csdn.net/weixin_57794111/article/details/126504877

#### 4、HTTP1.0 vs HTTP1.1

**连接方式** : HTTP 1.0 为短连接，HTTP 1.1 支持长连接。

**状态响应码** : HTTP/1.1中新加入了大量的状态码，光是错误响应状态码就新增了24种。比如说，`100 (Continue)`——在请求大资源前的预热请求，`206 (Partial Content)`——范围请求的标识码，`409 (Conflict)`——请求与当前资源的规定冲突，`410 (Gone)`——资源已被永久转移，而且没有任何已知的转发地址。

**缓存处理** : 在 HTTP1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，HTTP1.1 则引入了更多的缓存控制策略例如 Entity tag，If-Unmodified-Since, If-Match, If-None-Match 等更多可供选择的缓存头来控制缓存策略。

**带宽优化及网络连接的使用** :HTTP1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

**Host头处理** : HTTP/1.1在请求头中加入了`Host`字段。

------

著作权归所有 原文链接：https://javaguide.cn/cs-basics/network/http1.0&http1.1.html

#### 5、HTTP常见状态码

HTTP 状态码用于描述 HTTP 请求的结果，比如2xx 就代表请求被成功处理。

![状态码](asset\状态码.png)

**1xx Informational（信息性状态码）**

相比于其他类别状态码来说，1xx 你平时你大概率不会碰到，所以这里直接跳过。

**2xx Success（成功状态码）**

- **200 OK** ：请求被成功处理。比如我们发送一个查询用户数据的HTTP 请求到服务端，服务端正确返回了用户数据。这个是我们平时最常见的一个 HTTP 状态码。
- **201 Created** ：请求被成功处理并且在服务端创建了一个新的资源。比如我们通过 POST 请求创建一个新的用户。
- **202 Accepted** ：服务端已经接收到了请求，但是还未处理。
- **204 No Content** ： 服务端已经成功处理了请求，但是没有返回任何内容。

这里格外提一下 204 状态码，平时学习/工作中见到的次数并不多。

简单来说，204状态码描述的是我们向服务端发送 HTTP 请求之后，只关注处理结果是否成功的场景。也就是说我们需要的就是一个结果：true/false。

举个例子：你要追一个女孩子，你问女孩子：“我能追你吗？”，女孩子回答：“好！”。我们把这个女孩子当做是服务端就很好理解 204 状态码了。

**3xx Redirection（重定向状态码）**

- **301 Moved Permanently** ： 资源被永久重定向了。比如你的网站的网址更换了。
- **302 Found** ：资源被临时重定向了。比如你的网站的某些资源被暂时转移到另外一个网址。

**4xx Client Error（客户端错误状态码）**

- **400 Bad Request** ： 发送的HTTP请求存在问题。比如请求参数不合法、请求方法错误。
- **401 Unauthorized** ： 未认证却请求需要认证之后才能访问的资源。
- **403 Forbidden** ：直接拒绝HTTP请求，不处理。一般用来针对非法请求。
- **404 Not Found** ： 你请求的资源未在服务端找到。比如你请求某个用户的信息，服务端并没有找到指定的用户。
- **409 Conflict** ： 表示请求的资源与服务端当前的状态存在冲突，请求无法被处理。

**5xx Server Error（服务端错误状态码）**

- **500 Internal Server Error** ： 服务端出问题了（通常是服务端出Bug了）。比如你服务端处理请求的时候突然抛出异常，但是异常并未在服务端被正确处理。
- **502 Bad Gateway** ：我们的网关将请求转发到服务端，但是服务端返回的却是一个错误的响应。
- **503 Service Unavailable**：服务不可用，服务已停机。
- **504**： 网关超时。

------

著作权归所有 原文链接：https://javaguide.cn/cs-basics/network/http-status-codes.html

#### 6、Cookie 与 Session 的作用及区别

Cookie：

```
Cookie：其实就是客户端储存的，什么是客户端，就是浏览器存储，能看的见的，在浏览器设置-历史纪录中能看见，能手动清除Cookie。所以它一般都会被用在不重要的地方，因为它很容易被发现（cookie以明文储存信息），而且储存量很小(单个cookie保存的数据不能超过4K)，它的有效期也不咋地，一般你清除一下浏览器就没了，正常20分钟后，cookie生命周期结束.
```

Session:

```
Session:服务端，也是放在服务器上(session的默认失效时间为30分钟),Session是另一种记录客户状态的机制，基于Cookie实现，不同的是Cookie保存在客户端浏览器中，而Session保存在服务器上；客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是Session，客户端浏览器再次访问时只需要从Session中查找该客户的状态就可以了。
```

区别：

```
1、数据存放位置不同：
	cookie数据存放在客户的浏览器上，session数据放在服务器上。
 
2、安全程度不同：
	cookie不是很安全，别人可以从本地的cookie获取你的信息，考虑到安全性应当使用session。
 
3、性能使用程度不同：
	session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用cookie。
 
4、数据存储大小不同：
	单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie，而session则存储在服务端，浏览器对其没有限制。
 
5、会话机制不同：
	可以考虑将登陆信息等重要信息存放为session，其他信息如果需要保留，可以放在cookie中。
 
6、生命周期不同：
	cookie的生命周期是累计的，从创建时，就开始计时，20分钟后，cookie生命周期结束；关机会造成session生命周期的结束，但是对cookie没有影响。
 
7、访问范围不同：
	session为一个用户浏览器独享；cookie为多个用户浏览器共享。
```

[CSRF](https://blog.csdn.net/ihtml5/article/details/115283688) 英文全称是 Cross-site request forgery，所以又称为“跨站请求伪造”，是指黑客引诱用户打开黑客的网站，在黑客的网站中，利用用户的登录状态发起的跨站请求。简单来讲，CSRF 攻击就是黑客利用了用户的登录状态，并通过第三方的站点来做一些坏事。通常是因为将认证信息（SessionId等）存储在Cookie中导致的，因此建议存储在 localStorage 中。

#### 7、连接一个不存在的 IP 地址，会发生什么？

这个问题要分两种情况来思考，不同的情况得到的结论是不同的。

*第一个情况：目标 IP 地址和客户端的 IP 地址是同一个局域网（网络号相同）。*

第一种情况，客户端无法发出 SYN 报文，主要卡在数据链路层。

因为目标地址不存在 IP 地址，客户端的内核在发 arp 请求的时候，广播询问这个目标 IP 地址是谁的，由于网络中不存在该目标 IP 地址，所以没有设备应答客户端的 arp 请求。

由于**客户端无法拿到目标设备的 MAC，这样就没办法组装 MAC 头的信息，所以 SYN 报文无法发送出去**。

*第二个情况：目标 IP 地址和客户端的 IP 地址不在同一个局域网（网络号不同）。*

第二种情况，客户端会先将 SYN 报文发给路由器，然后路由器会继续转发。

由于目标 IP 地址是不存在的，该 SYN 报文会在网络中消亡，因此客户端是不会收到对 SYN 报文的确认报文的，接着**客户端会触发超时重传，重传 SYN 报文，直到重传的次数达到最大次数后，客户端的连接就会被释放**。

可能有的同学好奇，为什么这种情况客户端的 SYN 报文可以发出来？

因为当目标 IP 地址和客户端 IP 地址不在同一个局域网时，客户端客通过路由表的判断，判断到下一步是要将网络报文发送给路由器。

![图片](asset\路由器IP地址.png)

这时候数据链路层的 arp 请求，会广播询问 IP 地址（路由器 IP 地址）是谁的，路由器发现是自己的 IP 地址，于是就会将自己的 MAC 地址告诉客户端。

然后客户端的网络报文中 MAC 头的「目标 MAC 地址」填入的就是路由器的 MAC 地址，于是 SYN 报文就可以发送出去了。

由于目标 MAC 地址是路由器的，所以就会被路由器接收，然后路由器继续通过路由表的判断，转发给下一个路由器，直到找到目标设备。

#### 8、客户端连接一个存在的 IP 地址但是端口不存在，会发生什么？

客户端连接的目标 IP 地址是存在的，那么 SYN 报文就能正确的抵达到目标设备。目标设备收到 SYN 报文后，发现端口号并没有被进程监听，这时候目标设备的内核就会回 RST 报文。客户端收到 RST 报文后，就会释放连接。

#### 9、客户端发送了一个目标 IP 地址存在但是端口不存在的 UDP 报文，此时会发生什么？

如果目标端口不可达，那么数据包还没到传输层（UDP/TCP）就被丢弃了。网络层看到没有进程在监听指定的协议端口，就会送回一个“目标端口不可达”的 ICMP 报文。该错误报文中会包括前 8 个字节的原数据包内容，这就是你在 ICMP 中看到的 UDP 部分。也就是说，UDP 不会像 TCP 那样发送 RST 报文，而是依赖 ICMP 来通知发送方目标端口不可达的错误。这是 UDP 和 TCP 的一个区别，因为 UDP 是面向报文的，而 TCP 是面向字节流的。

#### 10、短时间内大量TIME_WAIT出现的根本原因

**高并发且持续的短连接**

1. 业务上使用了持续且大量的短连接，纯属设计缺陷，例如爬虫服务器就有可能出现这样的问题

2. http请求中connection的值被设置成close，因为服务器处理完http请求后会主动断开连接，然后这个连接就处于TIME_WAIT状态了。持续时间长且量级较大的话，问题就显现出来了。http1.0中，connection默认为close，但在http1.1中connection默认行为是keep-alive，就是因为这个原因

3. 服务器被攻击了，攻击方采用了大量的短连接

**TIME_WAIT状态连接过多的危害**

（1）TIME_WAIT 状态下，TCP连接占用的本地端口将一直无法释放。

（2）如果TIME_WAIT连接把所有可用端口都占完了（TCP端口数量上限是65535）而且还未被系统回收，就会出现无法向服务端创建新的socket连接的情况，此时系统几乎停转，任何链接都不能建立：address already in use : connect 异常。

**重点：解决办法**

1. 代码层修改，把短连接改为长连接，但代价较大

2. 修改 ip_local_port_range，增大可用端口范围，比如1024 ~ 65535

3. 客户端程序中设置socket的 SO_LINGER 选项

4. 打开 tcp_tw_recycle 和tcp_timestamps 选项，快速回收TIME_WAIT状态的socket，有一定风险，且linux4.12之后被废弃

5. 打开 tcp_tw_reuse 和 tcp_timestamps 选项，**允许将TIME_WAIT状态的socket重新用于新的TCP连接**

6. 设置 tcp_max_tw_buckets 为一个较小的值

链接：https://zhuanlan.zhihu.com/p/567088021

#### 11、服务器大量处于CLOSE_WAIT状态的连接原因？

![在这里插入图片描述](https://img-blog.csdnimg.cn/768d6d1ebfd84edd881bd01f36a0215d.png)

从上面的图我们可以知道，CLOSE_WAIT状态是被动关闭方才会出现的状态。
所以，当出现大量CLOSE_WAIT状态的连接时，说明服务端的程序没有调用 `close()` 函数关闭连接，故，状态就不能由close_wait迁移到 last_ack，则系统中会存在很多close_wait状态的连接。

可能的原因如下：

1. 关闭socket不及时：例如I/O线程被意外阻塞，或者I/O线程执行的用户自定义Task比例过高，导致I/O操作处理不及时，链路不能被及时释放。

通常，CLOSE_WAIT 状态在服务器停留时间很短，如果你发现大量的 CLOSE_WAIT 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般有如下几种可能：

1. **程序问题：如果代码层面忘记了 close 相应的 socket 连接**，那么自然不会发出 FIN 包，从而导致 CLOSE_WAIT 累积；或者代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。
2. **响应太慢或者超时设置过小：如果连接双方不和谐，一方不耐烦直接 timeout，另一方却还在忙于耗时逻辑，就会导致 close 被延后**。响应太慢是首要问题，不过换个角度看，也可能是 timeout 设置过小。

#### 12、Netty、Socket和Http

tcp和udp属于传输层协议，只关注 ip 地址和端口号，socket是基于此协议的应用程序的封装，http 是基于 tcp 协议的应用层协议，netty 可以理解为对socket的封装，让网络通信更好用。

Netty 是一个基于NIO的客户、服务器端的编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户、服务端应用。Netty相当于简化和流线化了网络应用的编程开发过程，例如：基于TCP和UDP的socket服务开发。

**1、主体不同**

- **socket**：socket不属于协议范畴，而是一个调用接口（API），是对TCP/IP协议的封装。实现服务器与客户端之间的物理连接，并进行数据传输。

- **http**：HTTP是基于TCP/IP协议的应用层协议，定义的是传输数据的内容的规范。

**2、所处层次不同**

- **socket**：Socket处于网络协议的传输层，主要有TCP/UDP两个协议（当然也有TCP/IP协议族中其他的协议）。

- **http**：HTTP是基于TCP/IP协议的应用层协议。

**3、连接状态不同**

- **socket**：socket连接是长连接，理论上客户端和服务器端一旦建立起连接将不会主动断掉；但是由于各种环境因素可能会使连接断开，比如：服务器端或客户端主机宕机了、网络故障，或者两者之间长时间没有数据传输，网络防火墙可能会断开该连接以释放网络资源。所以当一个socket连接中没有数据的传输，那么为了维持连接需要发送心跳消息。

- **http**：HTTP是基于请求-响应形式并且是短连接，即客户端向服务器端发送一次请求，服务器端响应后连接即会断掉。HTTP是无状态的协议，针对其无状态特性，在实际应用中又需要有状态的形式，因此一般会通过session/cookie技术来解决此问题。

**4、传输数据量不同**

- **socket**：socket传输的数据可自定义，为字节级，数据量小。

- **http**：HTTP的传输速度慢，数据包大。

**5、数据安全性不同**

- **socket**：数据可以加密，数据安全性高，适合Client/Server之间信息实时交互。

- **http**：数据传输安全性差，如实现实时交互，服务器性能压力大。

**6、连接方式不同**

- **socket**：Socket是客户端跟服务器直接使用Socket”套接字”进行连接，并没有规定连接后断开，所以客户端和服务器可保持连接通道，双方都可以主动发送数据。

- **http**：http是客户端用http协议进行请求，发送请求的时候需要封装http请求头，并绑定请求的数据，服务器一般有web服务器配合(当然也非绝对)，http的请求方式为客户端主动发起请求，服务器才能给响应，一次请求完毕后则断开连接，以节省资源，服务器不能主动给客户端发起响应，主要使用类是NSURLConnection。

总的来说，Socket和Netty更加底层，需要开发者自己实现协议、处理数据和异常等问题，但具有更高的灵活性和自由度；而HTTP更加高层，提供了完整的请求/响应模型和丰富的应用场景，但开发者需要遵循协议规范、使用约定好的API来进行开发。

#### 13、C10K问题

c10k问题，指的是：**服务器如何支持10k个并发连接**，也就是concurrent 10000 connection（这也是c10k这个名字的由来）。

**解决方案：**

1. 为每个连接分配一个独立的线程/进程。
2. 同一个线程/进程同时处理多个连接**（IO多路复用）**。

连接：https://blog.csdn.net/chinawangfei/article/details/102780959

#### 14、CDN

CDN全称叫做“Content Delivery Network”，中文叫**内容分发网络**。

CDN（Content Delivery Network, 内容分发网络）是为加快网络访问速度而建立在现有网络之上的分布式网络，它依靠部署在全球各地边缘节点的服务器群，通过负载均衡，内容发布，内容管理和内容存储的功能，由CDN服务器集群分担源站点服务器集群的压力，使用户可以就近获取已缓存的访问资源，避免网络拥堵，加快访问速度。与此同时，CDN是基于DNS解析进行管理的，其利用DNS技术和HTTPS协议确保了传输内容的安全性，保障用户的访问内容的安全性。

---

CDN是内容分发网络（Content Delivery Network）的缩写。它是一种分布式的网络架构，可以将内容（如网页、图片、视频等）缓存在离用户更近的服务器上，以提高用户访问这些内容的速度和可靠性。CDN通常由多个服务器节点组成，这些节点分布在全球各地，用户可以从离自己最近的节点获取所需的内容，从而减少了网络延迟和带宽消耗。CDN还可以提高网站的可用性和抗DDoS攻击能力。

#### 15、Ping命令

Ping命令是网络诊断和测试工具之一，用于测试计算机之间的连接。Ping命令的过程如下：

1. 发送请求：Ping命令发送一个Internet控制消息协议（ICMP）请求数据包到目标主机。

2. 接收响应：如果目标主机能够与请求主机进行通信，则它将返回一个ICMP响应数据包，表明该主机可以被访问。

3. 结果显示：Ping命令接收到响应后，它会显示关于响应时间、数据包大小和成功率等信息。如果没有响应，则显示主机不可达。

在执行Ping命令时，可能会使用参数来更改Ping命令的行为。例如，您可以设置数据包的大小、发送数量和时间间隔等。

需要注意的是，Ping命令只能告诉您主机是否可达，并不能告诉您主机上运行哪些服务或应用程序。因此，在某些情况下，Ping命令并不是解决网络问题的最佳方法。

----

**ICMP**（Internet Control Message Protocol，互联网控制报文协议）是一种基于网络层的协议，它主要被用来在IP网络中传递错误消息和操作消息。

ICMP的主要作用包括：

1. 错误报告：当IP数据包无法到达目的地或者出现其他错误时，ICMP可以产生一个错误消息并将其发送回源地址。例如，当一个路由器无法将数据包转发到下一跳时，它会生成ICMP差错消息并将其返回到源地址。

2. 测试网络可达性：通过发送ICMP Echo Request消息，可以测试一个主机或者路由器是否可以响应，并且可以测量通往该设备的时延。

3. 路径MTU发现：在IP网络中，不同链路的最大传输单元（MTU）可能不同，这意味着如果一个IP数据包比链路MTU更大，则需要分段才能传输。ICMP Path MTU Discovery机制可以帮助发送者找到到达目的地的最大MTU，从而避免分片和重组开销。

4. 辅助协议：ICMP还可以用作辅助协议，用于支持其他协议的正常运行。例如，某些安全协议（如IPSec）需要使用ICMP来传递密钥管理数据。

#### 16、DNS的工作原理

DNS是域名系统（Domain Name System）的缩写，它是互联网上负责将域名解析为IP地址的分布式数据库系统。DNS的工作原理如下：

1. 用户在浏览器中输入一个域名，例如www.google.com。

2. 浏览器会向本地DNS服务器发送一个查询请求，询问该域名对应的IP地址。

3. 如果本地DNS服务器已经缓存了该域名对应的IP地址，则直接返回结果给用户；否则，它会与其他DNS服务器协作，递归地查询该域名对应的IP地址。

4. 如果某个DNS服务器无法处理该查询，则会把查询请求转发给其他DNS服务器，直到找到能够处理该查询的DNS服务器为止。

5. 如果最终找到了该域名对应的IP地址，则将该信息返回给用户，并将查询结果缓存起来，以便下次快速响应查询请求。

6. 如果所有的DNS服务器都无法处理该查询，则返回一个错误消息给用户。

总之，DNS的作用就是将域名转换成相应的IP地址，使得用户可以通过易于记忆的域名来访问互联网上的各种资源。

#### 17、IP寻址过程

IP寻址过程如下：

1. 主机在发送数据时，需要知道目标主机的IP地址。

2. 如果目标主机就在同一子网内，源主机会使用ARP（地址解析协议）查询目标主机的MAC地址，以便将数据包发送给目标主机。

3. 如果目标主机不在同一子网内，则源主机会将数据包发送给默认网关（路由器），由路由器将数据包转发到目标主机所在的网络上。

4. 路由器会根据自己的路由表选择最佳路径将数据包转发出去。

5. 数据包在经过多个路由器之后，最终到达目标主机所在的网络。

6. 目标主机接收到数据包后，会根据自己的IP地址和端口号来判断该数据包是否应该被接收。

总之，IP寻址过程就是为了确定数据包从源主机到目标主机的路径，以确保数据能够在互联网中正确地传输。

#### 18、MAC寻址过程

MAC地址寻址过程如下：

1. 当一台主机需要向另一台主机发送数据时，它首先需要知道目标主机的MAC地址。

2. 如果目标主机就在同一子网内，源主机会使用ARP（地址解析协议）查询目标主机的MAC地址，以便将数据包发送给目标主机。

3. ARP会广播一条ARP请求包到本地网络上的所有设备，询问是否有某个IP地址对应的MAC地址。

4. 如果目标主机在同一子网内且在线，则它会响应ARP请求，回复包含自己MAC地址的ARP应答包。

5. 源主机收到ARP应答包后，就可以直接将数据包封装在以目标MAC地址为目的地的数据帧中，发送给目标主机。

6. 如果目标主机不在同一子网内，则源主机会将数据包发送给默认网关（路由器），由路由器将数据包转发到目标主机所在的网络上。

7. 路由器会根据自己的路由表选择最佳路径将数据包转发出去。

总之，MAC地址寻址过程就是为了确定数据帧从源主机到目标主机的路径，以确保数据能够在局域网内正确地传输。

#### 19、TCP的拥塞控制

TCP的拥塞控制是指TCP协议在网络中传输数据时，通过一系列算法和机制来确保网络不发生拥塞，从而保证数据传输的可靠性和效率。

TCP的拥塞控制主要包括以下几个方面：

1. 慢启动：当一个TCP连接建立后，它会先以一个较小的窗口大小开始发送数据，然后每经过一个往返时间RTT（Round Trip Time），就将窗口大小加倍，直到达到一个阈值。

2. 拥塞避免：当窗口大小达到一个阈值之后，TCP进入“拥塞避免”状态。此时每经过一个RTT，窗口大小仅增加一个MSS（Maximum Segment Size）的大小。

3. 快重传和快恢复：当TCP接收到连续的重复确认（即ACK）时，说明网络出现了拥塞，TCP会立即重传最后一个未确认的报文段，并将拥塞窗口减半，但不会将窗口大小降为1，而是设置为阈值的一半，进入快恢复状态。在快恢复状态下，TCP可以接收新的数据，但只能发送已经被确认的数据。

4. 超时重传：如果TCP在规定时间内没有收到对方的确认信息，则认为这个分组丢失了，TCP会立即重传这个分组。

通过以上这些机制和算法，TCP可以自适应地调整发送速度和窗口大小，以避免网络拥塞，并保证数据的可靠传输。

#### 20、断网了，还能ping通 127.0.0.1 吗？

- `127.0.0.1` 是**回环地址**。`localhost`是**域名**，但默认等于 `127.0.0.1`。
- `ping` 回环地址和 `ping` 本机地址，是一样的，走的是**lo0 "假网卡"**，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前**狠狠拐了个弯**， 将数据插入到一个**链表**后就**软中断**通知 **ksoftirqd** 来进行**收数据**的逻辑，**压根就不出网络**。所以断网了也能 `ping` 通回环地址。
- 如果服务器 `listen` 的是 `0.0.0.0`，那么此时用`127.0.0.1`和本机地址**都可以**访问到服务。

链接：https://mp.weixin.qq.com/s/9tVsCqp7y2xvzT1mwA9EBg

#### 21、交换机、路由器、局域网和广域网

<img src="asset\广域网.png" alt="img" style="zoom:80%;" />

**交换机**

交换机是计算机网络中的重要设备，主要用于在网络中转发数据包。它可以根据数据包的目标地址和路由表信息，将数据包转发到下一个网络设备，从而实现网络中的数据传输。

具体来说，交换机在网络中的作用包括：

1. 数据包转发：交换机可以根据数据包的目标地址和路由表信息，将数据包转发到下一个网络设备，从而实现网络中的数据传输。

2. 广播和组播：交换机可以将广播和组播数据包转发到所有连接的设备，从而实现网络中的广播和组播功能。

3. 网络隔离：交换机可以将不同的网络隔离开来，从而实现网络的安全性和可靠性。

4. 网络管理：交换机可以提供网络管理功能，如端口管理、流量控制、虚拟局域网（VLAN）等，从而帮助网络管理员更好地管理网络。

总之，交换机在计算机网络中扮演着重要的角色，它可以帮助数据包在网络中快速、准确地传输到目标设备，从而保证网络的稳定性和可靠性。

----

网络通信可以通过端对端通信实现，但是这种方式并不适用于大规模的网络环境。在大规模的网络环境中，端对端通信导致网络拥塞、延迟和丢包等问题，从而影响网络的性能和可靠性。

相比之下，使用交换机可以好地管理网络流量，避免网络拥塞和延迟等问题。交换机可以根据数据包的目标地址和路由表信息，将数据包转发到下一个网络设备，从而实现网络中的数据传输。这种方式可以避免数据包在网络中的重复传输冲突，从而提高网络的性能和可靠性。

此外，交换机还可以提供网络管理功能，如端口管理、流量控制、虚拟局域网（VLAN）等，从而帮助网络管理员更好地网络。这些功能可以提高网络的安全性和可靠性，从而保证网络的正常运行。

因此，虽然网络通信通过端对端通信实现，但是在大规模的网络环境中，使用交换机可以更好地管理网络流量，提高网络的性能和可靠性，从而更好地满足用户的需求。

**路由器**

工作在网络层

当两个不同结构的网络须要互连时，能够通过路由器来实现。路由器能够使两个相似或不同体系结构的局域网段连接到一起，以构成一个更大的局域网或一个广域网。

路由器工作在网络层(OSI第三层)，跟电脑一样有自己独立的 MAC 地址，并且能把数据包做一次转发

路由器用来**连接不同的子网**，交换机的MAC地址表只负责自己所在的子网，这样就解决了交换机MAC地址表膨胀问题

<img src="asset\9c0640bf9f01431cb2c6e4e5c635bfe2.png" alt="在这里插入图片描述" style="zoom:80%;" />

**局域网**

连接LAN口

主机A向主机B发送消息

<img src="asset\局域网通信.png" alt="在这里插入图片描述" style="zoom:80%;" />

<img src="asset\watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05hYmFuZG9u,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:80%;" />

**广域网**

连接WAN口

<img src="asset\jyw广域网.png" alt="在这里插入图片描述" style="zoom:80%;" />

https://blog.csdn.net/Nabandon/article/details/106714141

----

**交换机和路由器的区别和作用**

交换机和路由器是计算机网络中常见的两种设备，它们在网络中扮演着不同的角色和起到不同的作用。本文将详细介绍交换机和路由器的区别和作用。

**一、交换机**

交换机是一种用于局域网内部的设备，它主要用于在局域网内部进行数据包的转发和交换。交换机根据MAC地址来决定数据包的转发路径，它可以将数据包从源端口转发到目标端口，实现局域网内部的高速交换。交换机通过物理端口连接各个设备，可以同时支持多个设备之间的通信，提供高速、稳定的网络传输。

交换机的作用主要有以下几个方面：

1. 提供高速的数据传输：交换机可以实现端口之间的直接连接，提供高速的数据传输速率，满足局域网内部设备之间大量数据的传输需求。

2. 实现网络分段：交换机可以将局域网划分为多个虚拟网络，实现网络的分段管理，提高网络的安全性和性能。

3. 支持广播和组播：交换机可以支持广播和组播功能，将广播和组播数据包仅发送给需要的设备，减少网络流量和带宽的占用。

**二、路由器**

路由器是一种用于互联网中的设备，它主要用于连接不同的网络，并根据IP地址来决定数据包的转发路径。路由器可以将数据包从源网络转发到目标网络，实现不同网络之间的通信。路由器具有更强大的路由功能和更复杂的转发决策算法，可以实现不同网络之间的路由选择和数据包的转发控制。

路由器的作用主要有以下几个方面：

1. 实现不同网络之间的连接：路由器可以将不同的网络连接起来，实现不同网络之间的通信和数据传输。

2. 提供网络地址转换（NAT）：路由器可以实现网络地址转换，将局域网内部的私有IP地址转换为公共IP地址，实现局域网与互联网之间的通信。

3. 分割网络流量：路由器可以将流量进行分割和管理，根据不同的流量类型和目的地进行转发控制，提高网络的性能和安全性。

**三、交换机和路由器的区别**

1. 工作层次不同：交换机工作在数据链路层，路由器工作在网络层。

2. 转发决策不同：交换机根据MAC地址进行转发决策，而路由器根据IP地址进行转发决策。

3. 转发方式不同：交换机通过物理端口直接转发数据包，而路由器通过路由表进行转发控制。

4. 范围不同：**交换机用于局域网内部的数据交换，而路由器用于不同网络之间的数据转发**。

5. 功能不同：交换机主要提供高速的数据交换和广播功能，而路由器主要提供网络连接和路由选择功能。

#### 结论

交换机和路由器是计算机网络中常见的两种设备，它们在网络中扮演着不同的角色和起到不同的作用。交换机主要用于局域网内部的数据交换和高速传输，而路由器主要用于不同网络之间的连接和转发控制。了解交换机和路由器的区别和作用，有助于我们更好地理解和配置网络设备，提高网络的性能和安全性。

#### 22、TCP连接，一端断电和进程奔溃有什么区别？

如果「**客户端进程崩溃**」，客户端的进程在发生崩溃的时候，内核会发送 FIN 报文，与服务端进行四次挥手。

但是，「**客户端主机宕机**」，那么是不会发生四次挥手的，具体后续会发生什么？还要看服务端会不会发送数据？

- 如果服务端会发送数据，由于客户端已经不存在，收不到数据报文的响应报文，服务端的数据报文会超时重传，当重传总间隔时长达到一定阈值（内核会根据 tcp_retries2 设置的值计算出一个阈值）后，会断开 TCP 连接；
- 如果服务端一直不会发送数据，再看服务端有没有开启 TCP keepalive 机制？
  - 如果有开启，服务端在一段时间没有进行数据交互时，会触发 TCP keepalive 机制，探测对方是否存在，如果探测到对方已经消亡，则会断开自身的 TCP 连接；
  - 如果没有开启，服务端的 TCP 连接会一直存在，并且一直保持在 ESTABLISHED 状态。

#### 23、TCP、UDP端口问题

> TCP 和 UDP 可以同时绑定相同的端口吗？

可以的。

TCP 和 UDP 传输协议，在内核中是由两个完全独立的软件模块实现的。

当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。

因此， TCP/UDP 各自的端口号也相互独立，互不影响。

> 多个 TCP 服务进程可以同时绑定同一个端口吗？

如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”。

如果两个 TCP 服务进程绑定的端口都相同，而 IP 地址不同，那么执行 bind() 不会出错。

> 如何解决服务端重启时，报错“Address already in use”的问题？

当我们重启 TCP 服务进程的时候，意味着通过服务器端发起了关闭连接操作，于是就会经过四次挥手，而对于主动关闭方，会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。

当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误。

要解决这个问题，我们可以对 socket 设置 SO_REUSEADDR 属性。

这样即使存在一个和绑定 IP+PORT 一样的 TIME_WAIT 状态的连接，依然可以正常绑定成功，因此可以正常重启成功。

> 客户端的端口可以重复使用吗？

在客户端执行 connect 函数的时候，只要客户端连接的服务器不是同一个，内核允许端口重复使用。

TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。

所以，如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。

> 客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？

要看客户端是否都是与同一个服务器（目标地址和目标端口一样）建立连接。

如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。即使在这种状态下，还是可以与其他服务器建立连接的，只要客户端连接的服务器不是同一个，那么端口是重复使用的。

> 如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？

打开 net.ipv4.tcp_tw_reuse 这个内核参数。

因为开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态。

如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。

#### 24、服务端没有listen，客户端发起连接建立会发生什么？没有accept能建立TCP连接吗？

**服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文。**

> 执行 listen 方法时，会创建半连接队列和全连接队列。
>
> 三次握手的过程中会在这两个队列中暂存连接信息。
>
> 所以形成连接，前提是你得有个地方存放着，方便握手的时候能根据 IP + 端口等信息找到对应的 socket。

----

<img src="asset\三次握手.png" alt="TCP三次握手" style="zoom: 50%;" />

服务端代码，对socket执行bind方法可以绑定监听端口，然后执行`listen方法`后，就会进入监听（`LISTEN`）状态。内核会为每一个处于`LISTEN`状态的`socket` 分配两个队列，分别叫**半连接队列和全连接队列**。

<img src="asset\连接队列.png" alt="每个listen Socket都有一个全连接和半连接队列" style="zoom:50%;" />

<img src="asset\三次握手+连接队列.png" alt="半连接队列和全连接队列" style="zoom:50%;" />

- **半连接队列（SYN队列）**，服务端收到**第一次握手**后，会将`sock`加入到这个队列中，队列内的`sock`都处于`SYN_RECV` 状态。
- **全连接队列（ACCEPT队列）**，在服务端收到**第三次握手**后，会将半连接队列的`sock`取出，放到全连接队列中。队列里的`sock`都处于 `ESTABLISHED`状态。这里面的连接，就**等着服务端执行accept()后被取出了。**

看到这里，文章开头的问题就有了答案，建立连接的过程中根本不需要`accept()`参与， **执行accept()只是为了从全连接队列里取出一条连接。**

我们把话题再重新回到这两个队列上。

虽然都叫**队列**，但其实**全连接队列（icsk_accept_queue）是个链表**，而**半连接队列（syn_table）是个哈希表**。

<img src="asset\连接队列结构.png" alt="半连接全连接队列的内部结构" style="zoom:50%;" />

**总结：**

- **每一个**`socket`执行`listen`时，内核都会自动创建一个半连接队列和全连接队列。
- 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。
- `accept方法`只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎**毫无关系**。
- 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了**哈希表**，而全连接队列本质是链表。
- 全连接队列满了，再来第三次握手也会丢弃，此时如果`tcp_abort_on_overflow=1`，还会直接发`RST`给客户端。
- 半连接队列满了，可能是因为受到了`SYN Flood`攻击，可以设置`tcp_syncookies`，绕开半连接队列。
- 客户端没有半连接队列和全连接队列，但有一个**全局hash**，可以通过它实现自连接或TCP同时打开。

https://xiaolincoding.com/network/3_tcp/tcp_no_accpet.html

#### 25、数据包的发送流程

为了发送数据包，两端首先会通过**三次握手**，建立TCP连接。

一个数据包，从聊天框里发出，消息会从**聊天软件**所在的**用户空间**拷贝到**内核空间**的**发送缓冲区（send buffer）**，数据包就这样顺着**传输层、网络层，进入到数据链路层，在这里数据包会经过流控（qdisc），再通过RingBuffer发到物理层的网卡**。数据就这样顺着**网卡**发到了**纷繁复杂**的网络世界里。这里头数据会经过n多个**路由器和交换机**之间的跳转，最后到达**目的机器的网卡**处。

此时目的机器的网卡会通知**DMA**将数据包信息放到`RingBuffer`中，再触发一个**硬中断**给`CPU`，`CPU`触发**软中断**让`ksoftirqd`去`RingBuffer`收包，于是一个数据包就这样顺着**物理层，数据链路层，网络层，传输层**，最后从内核空间拷贝到用户空间里的**聊天软件**里。

<img src="asset\网络发包收包全景图.png" alt="网络发包收包全景图" style="zoom:67%;" />

#### 26、UDP通信

![工作过程](asset\udp通信.png)

UDP（User Datagram Protocol）是一种无连接的传输协议，它不保证数据传输的可靠性和顺序性，但具有传输速度的优点。下面是UDP的一个传输流程：

1. 应用程序将数据打包成UDP数据报，包括源端口号、目的端口号、数据长度和校验和等信息。

2. UDP数据报被传递给IP层，IP根据目的IP地址查找路由表，确定数据报的下一跳地址。

3. 如果下一跳地址与本地地址相同，则直接将UDP数据报传递给目的应用程序；否则，将UDP数据报发送给下一跳地址。

4. 接收方应用程序接收到UDP数据报后，根据源端口号和目的端口号确定数据报的来源和目的地，并进行数据处理。

需要注意的是，UDP协议不提供数据的可靠性和顺序性保证，因此在应用程序中需要自行处理这些问题。同时，UDP协议也不提供拥塞控制和流量控制等机制，因此在网络拥塞或高负载情况下，UDP传输可能会出现丢包或延迟等问题

链接：https://blog.csdn.net/qui910/article/details/125002875

#### 27、一台服务器最多支持多少TCP连接？

因为这里要考虑的是最大数，因此先不考虑连接上的数据收发和处理，仅考虑`ESTABLISH`状态的空连接。那么一台服务端机器上最大可以支持多少条TCP连接？这个连接数会受哪些因素的影响？

- 在不考虑连接上数据的收发和处理的情况下，仅考虑`ESTABLISH状态`下的空连接情况下，一台服务器上最大可支持的TCP连接数量基本上可以说是由内存大小来决定的。
- 四元组唯一确定一条连接，但服务端可以接收来自任意客户端的请求，所以根据这个理论计算出来的数字太大，没有实际意义。另外文件描述符限制其实也是内核为了防止某些应用程序不受限制的打开【`文件句柄`】而添加的限制。这个限制只要修改几个内核参数就可以加大。
- 一个socket大约消耗3kb左右的内存，这样真正制约服务端机器最大并发数的就是内存，拿一台4GB内存的服务器来说，可以支持的TCP连接数量大约是100w+

----

**一条客户端机器最大究竟能支持多少条连接**

和服务端不同的是，客户端每次建立一条连接都需要消耗一个端口。在TCP协议中，端口是一个2字节的整数，因此范围只能是0~65535。那么客户单最大只能支持65535条连接吗？有没有办法突破这个限制，有的话有哪些办法？

- 客户度每次建立一条连接都需要消耗一个端口。从数字上来看，似乎最多只能建立65535条连接。但实际上我们有两种办法破除65535这个限制
  - 方式一，为客户端配置多IP
  - 方式二，分别连接不同的服务端
- 所以一台client发起百万条连接是没有任何问题的

https://juejin.cn/post/7162824884597293086

### MySQL

#### 1、MySQL 幻读被彻底解决了吗？

可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读。

**什么是幻读？**

MySQL 文档是怎么定义幻读（Phantom Read）的:
```
The so-called phantom problem occurs within a transaction when the same query produces different sets of rows at different times. For example, if a SELECT is executed twice, but returns a row the second time that was not returned the first time, the row is a “phantom” row.
```
​		翻译：当同一查询在不同的时间产生不同的行集时，事务中就会出现所谓的幻象问题。例如，如果SELECT执行了两次，但第二次返回的是第一次未返回的行，则该行是“幻影”行。

​		举个例子，假设一个事务在 T1 时刻和 T2 时刻分别执行了下面查询语句，途中没有执行其他任何语句：
```mysql
SELECT * FROM t_test WHERE id > 100;
```
只要 **T1 和 T2 时刻执行产生的结果集是不相同的，那就发生了幻读的问题**，比如：

- T1 时间执行的结果是有 5 条行记录，而 T2 时间执行的结果是有 6 条行记录，那就发生了幻读的问题。
- T1 时间执行的结果是有 5 条行记录，而 T2 时间执行的结果是有 4 条行记录，也是发生了幻读的问题。

**第一个发生幻读现象的场景**

（更新一条不存在的记录后能查询到）

还是以这张表作为例子：

| id   | name | score |
| ---- | ---- | ----- |
| 1    | 小林 | 50    |
|2| 小明 | 60 |
|3| 小红 | 70 |
|4| 小蓝 | 80 |

事务 A 执行查询 id = 5 的记录，此时表中是没有该记录的，所以查询不出来。
```mysql
# 事务 A
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

mysql> select * from t_stu where id = 5;
Empty set (0.01 sec)
```
然后事务 B 插入一条 id = 5 的记录，并且提交了事务。
```mysql
# 事务 B
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

mysql> insert into t_stu values(5, '小美', 18);
Query OK, 1 row affected (0.00 sec)

mysql> commit;
Query OK, 0 rows affected (0.00 sec)
```
此时，事务 A 更新 id = 5 这条记录，对没错，事务 A 看不到 id = 5 这条记录，但是他去更新了这条记录，这场景确实很违和，然后再次查询 id = 5 的记录，事务 A 就能看到事务 B 插入的纪录了，幻读就是发生在这种违和的场景。

```mysql
mysql> update t_stu set name = '小林coding' where id = 5;
Query OK, 1 row affected (0.01 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql> select * from t_stu where id = 5;
+----+--------------+------+
| id | name         | age  |
+----+--------------+------+
|  5 | 小林coding   |   18 |
+----+--------------+------+
1 row in set (0.00 sec)
```
整个发生幻读的时序图如下：

<img src="asset\幻读.png" alt="MySQL 幻读被彻底解决了吗？_数据库_09" style="zoom:80%;" />

在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id = 5 的记录并提交。接着，事务 A 对 id = 5 这条记录进行了更新操作，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。

因为这种特殊现象的存在，所以我们认为 **MySQL Innodb 中的 MVCC 并不能完全避免幻读现象**。

**第二个发生幻读现象的场景**
		除了上面这一种场景会发生幻读现象之外，还有下面这个场景也会发生幻读现象。

- T1 时刻：事务 A 先执行「快照读语句」：`select * from t_test where id > 100` 得到了 3 条记录。
- T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；
- T3 时刻：事务 A 再执行「当前读语句」 `select * from t_test where id > 100 for update` 就会得到 4 条记录，此时也发生了幻读现象。

​		要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 `select … for update` 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。（*我认为这不属于幻读，两次的select不同，第一次为快照读、第二次为当前读*）

**小结**
MySQL InnoDB 引擎的可重复读隔离级别（默认隔离级），根据不同的查询方式，分别提出了避免幻读的方案：

- 针对**快照读**（普通 `select` 语句），是通过 MVCC 方式解决了幻读。

- 针对**当前读**（`select … for update` 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。

我举例了两个发生幻读场景的例子。

​		第一个例子：对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。

​		第二个例子：对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。

​		所以，**MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。**

​		要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 `select … for update` 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。

https://blog.51cto.com/u_15746412/5729860

#### 2、MySQL数据存放在哪个文件？

每创建一个 database（数据库） 都会在 /var/lib/mysql/ 目录里面创建一个以 database 为名的目录，然后保存表结构和表数据的文件都会存放在这个目录里。

比如，我这里有一个名为 my_test 的 database，该 database 里有一张名为 t_order 数据库表。

![图片](asset\my_test.png)

然后，我们进入 /var/lib/mysql/my_test 目录，看看里面有什么文件？

```bash
[root@xiaolin ~]#ls /var/lib/mysql/my_test
db.opt  
t_order.frm  
t_order.ibd
```

可以看到，共有三个文件，这三个文件分别代表着：

- db.opt，用来存储当前数据库的默认字符集和字符校验规则。
- t_order.frm ，t_order 的**表结构**会保存在这个文件。在 MySQL 中建立一张表都会生成一个.frm 文件，该文件是用来保存每个表的元数据信息的，主要包含表结构定义。
- t_order.ibd，t_order 的**表数据**会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.idb）。这个行为是由参数 innodb_file_per_table 控制的，若设置了参数 innodb_file_per_table 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， MySQL 中每一张表的数据都存放在一个独立的 .idb 文件。

#### 3、InnoDB行格式有哪些？

行格式（row_format），就是一条记录的存储结构。

InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。

- Redundant 是很古老的行格式了， MySQL 5.0 版本之前用的行格式，现在基本没人用了。
- 由于 Redundant 不是一种紧凑的行格式，所以 MySQL 5.0 之后引入了 Compact 行记录存储方式，Compact 是一种紧凑的行格式，设计的初衷就是为了让一个数据页中可以存放更多的行记录，从 MySQL 5.1 版本之后，行格式默认设置成 Compact。
- Dynamic 和 Compressed 两个都是紧凑的行格式，它们的行格式都和 Compact 差不多，因为都是基于 Compact 改进一点东西。从 MySQL5.7 版本之后，默认使用 Dynamic 行格式。

 Compact 行格式混个脸熟，它长这样：

<img src="asset\Compact行格式.png" alt="图片" style="zoom:80%;" />

可以看到，一条完整的记录分为「记录的额外信息」和「记录的真实数据」两个部分。

接下里，分别详细说下。

**记录的额外信息**

记录的额外信息包含 3 个部分：变长字段长度列表、NULL 值列表、记录头信息。

**1. 变长字段长度列表**

varchar(n) 和 char(n) 的区别是什么，相信大家都非常清楚，char 是定长的，varchar 是变长的，变长字段实际存储的数据的长度（大小）不固定的。

所以，在存储数据的时候要把这些数据占用的字节数也存起来，存到「变长字段长度列表」里面，读取数据的时候才能根据这个「变长字段长度列表」去读取对应长度的数据。其他 TEXT、BLOB 等变长字段也是这么实现的。

为了展示「变长字段长度列表」具体是怎么保存变长字段占用的字节数，我们先创建这样一张表，字符集是 ascii（所以每一个字符占用的 1 字节），行格式是 Compact，t_user 表中 name 和 phone 字段都是变长字段：

```mysql
CREATE TABLE `t_user` (
  `id` int(11) NOT NULL,
  `name` VARCHAR(20) NOT NULL,
  `phone` VARCHAR(20) DEFAULT NULL,
  `age` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB DEFAULT CHARACTER SET = ascii ROW_FORMAT = COMPACT;
```

现在 t_user 表里有这三条记录：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQkITAxCDjy9WzELAXsXl4az0u26X1WuSuyk6EQTg0vI0brXZcyxWs1Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

接下来，我们看看看看这三条记录的行格式中的 「变长字段长度列表」是怎样存储的。

先来看第一条记录：

- name 列的值为 a，长度是 1 字节，十六进制 0x01
- phone 列的值为 123，长度是 3 字节，十六进制 0x03
- age 列和 id 列不是变长字段，所以这里不用管。

这些变长字段的长度值会按照列的顺序**逆序存放**（等下会说为什么要这么设计），所以「变长字段长度列表」里的内容是「 03 01」，而不是 「01 03」。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQgykvoAyVhmdaklWGuDu5YY1BVibOaNI9Ina8Eic0wlJWibSF1icgYADykA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

同样的道理，我们也可以得出**第二条记录**的行格式中，「变长字段长度列表」里的内容是「 04 02」，如下图：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQT9DBO7KTu1l4FG70OLicGZ1eTCSdaQRlzSVuE7Hs5Npl0icNPM6ElWQw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

**第三条记录**中 phone 列的值是 NULL，**NULL 是不会存放在行格式中记录的真实数据部分里的**，所以「变长字段长度列表」里不需要保存值为  NULL 的变长字段的长度。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQWDibwTliclVLzOSc4h73qmOnNYDFVrgz19bhu7l3uGOiagibq8GLdcldEw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

> 为什么「变长字段长度列表」的信息要按照逆序存放？

这个设计是有想法的，主要是因为「记录头信息」中指向下一个记录的指针，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。

「变长字段长度列表」中的信息之所以要逆序存放，是因为这样可以**使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中，这样就可以提高 CPU Cache 的命中率**。

同样的道理， NULL 值列表的信息也需要逆序存放。

如果你不知道什么是 CPU Cache，可以看这篇文章：[面试官：如何写出让 CPU 跑得更快的代码？](http://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247486022&idx=1&sn=8bb5a066d81f77523a06cd09251055da&chksm=f98e4eeccef9c7fa61c1a1f46c0935d7b4ea62fa4406cafe831d52fd24f9fc52db51bb21f62e&scene=21#wechat_redirect)，这属于计算机组成的知识。

> 每个数据库表的行格式都有「变长字段字节数列表」吗？

其实变长字段字节数列表不是必须的。

**当数据表没有变长字段的时候，比如全部都是 int 类型的字段，这时候表里的行格式就不会有「变长字段长度列表」了**，因为没必要，不如去掉以节省空间。

所以「变长字段长度列表」只出现在数据表有变长字段的时候。

**2. NULL 值列表**

表中的某些列可能会存储 NULL 值，如果把这些 NULL 值都放到记录的真实数据中会比较浪费空间，所以 Compact 行格式把这些值为 NULL 的列存储到 NULL值列表中。

如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。

- 二进制位的值为`1`时，代表该列的值为NULL。
- 二进制位的值为`0`时，代表该列的值不为NULL。

另外，NULL 值列表必须用整数个字节的位表示（1字节8位），如果使用的二进制位个数不足整数个字节，则在字节的高位补 `0`。

还是以 t_user 表的这三条记录作为例子：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQkITAxCDjy9WzELAXsXl4az0u26X1WuSuyk6EQTg0vI0brXZcyxWs1Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

接下来，我们看看看看这三条记录的行格式中的 NULL 值列表是怎样存储的。

先来看**第一条记录**，第一条记录所有列都有值，不存在 NULL 值，所以用二进制来表示是酱紫的：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQworohLkPEe6vUx1cLsLhRd0wrngUpYBnkLicdFgqITP3KQ08fXTHv6g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

但是 InnoDB 是用整数字节的二进制位来表示NULL值列表的，现在不足 8 位，所以要在高位补 0，最终用二进制来表示是酱紫的：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQpoxAjdsDiaRAuopUib7xAc6UK595sApm4Jb9Cfoe9Auo6jv10OUkoP5Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

所以，对于第一条数据，NULL 值列表用十六进制表示是 0x00。

接下来看**第二条记录**，第二条记录 age 列是 NULL 值，所以，对于第二条数据，NULL值列表用十六进制表示是 0x04。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQcXxNzeibtw2CWFnSu01aalZj8EDBoyvoIaiceVU1xQVic7wWrA1jJmQrQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

最后**第三条记录**，第三条记录 phone 列 和 age 列是 NULL 值，所以，对于第三条数据，NULL 值列表用十六进制表示是 0x06。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQYCIvIZ5VcjWtoeeOUL7cY0KNt1fV7bCImwzK9L7uCDwK53lzPl0CLQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

我们把三条记录的 NULL 值列表都填充完毕后，它们的行格式是这样的：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQjAz5Y1kMiczGzibwzGpu6ibr6USruDaaicfsmYTiaiclTArb5QP3EooQs8WA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

> 每个数据库表的行格式都有「NULL 值列表」吗？

NULL 值列表也不是必须的。

**当数据表的字段都定义成 NOT NULL 的时候，这时候表里的行格式就不会有 NULL 值列表了**。所以在设计数据库表的时候，通常都是建议将字段设置为  NOT NULL，这样可以节省 1 字节的空间（NULL 值列表占用 1 字节空间）。

**3. 记录头信息**

记录头信息中包含的内容很多，我就不一一列举了，这里说几个比较重要的：

- delete_mask ：标识此条数据是否被删除。从这里可以知道，我们执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1。
- next_record：下一条记录的位置。从这里可以知道，记录与记录之间是通过链表组织的。在前面我也提到了，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。
- record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录

**记录的真实数据**

记录真实数据部分除了我们定义的字段，还有三个隐藏字段，分别为：row_id、trx_id、roll_pointer，我们来看下这三个字段是什么。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQFGoFXJTHNZllGUuRfY2fSbox8icGC4d8NHpcsPQYxUVRQg1kbLe6KPQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

- row_id

如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。

- trx_id

事务id，表示这个数据是由哪个事务生成的。trx_id是必需的，占用 6 个字节。

- roll_pointer

这条记录上一个版本的指针。roll_pointer 是必需的，占用 7 个字节。

如果你熟悉 MVCC 机制，你应该就清楚 trx_id 和 roll_pointer 的作用了，如果你还不知道 MVCC 机制，可以看完[这篇文章](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247508002&idx=1&sn=9a59db214082ca8810dcdcb4af43c17c&scene=21#wechat_redirect)，一定要掌握，面试也很经常问 MVCC 是怎么实现的。

链接：https://mp.weixin.qq.com/s/sqW51yqeAXcDs9r84UFP7A

#### 4、MySQL 的 NULL 值是怎么存放的？

MySQL 的 Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分。

NULL值列表会占用 1 字节空间，当表中所有字段都定义成 NOT NULL，行格式中就不会有 NULL值列表，这样可节省 1 字节的空间。

#### 5、MySQL 怎么知道 varchar(n) 实际占用数据的大小？

MySQL 的 Compact 行格式中会用「变长字段长度列表」存储变长字段实际占用的数据大小。

#### 6、varchar(n) 中 n 最大取值为多少？

**「变长字段长度列表」占用的字节数最大不会不超过 2 字节**。2 个字节的最大值是 65535（十进制），从这里可以推测一行记录最大能存储 65535 字节的数据，但是这个是包含「变长字段字节数列表所占用的字节数」和「NULL值列表所占用的字节数」。

如果一张表只有一个 varchar(n)  字段，且允许为 NULL，字符集为 ascii。varchar(n) 中 n 最大取值为 65532。

计算公式：65535 - 变长字段字节数列表所占用的字节数 - NULL值列表所占用的字节数 = 65535 - 2 - 1 = 65532

#### 7、行溢出后，MySQL 是怎么处理的？

如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。

Compact 行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQPxyPYiaDmGYPCWtQcCjILVVBFYcdegBSRGly002A7wRYqZ355MBdM0w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

Compressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZd2iaBC1ShwqhoV6S62KgArQuefMn6WqB6zasQia0khtGble9ibPRynyfzhmXEtdSNf72UJFbmnibBVoA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

#### 8、一行数据中的多个NULL字段值在磁盘上怎么存储

1. **一行数据里的NULL值不能直接存储**

在磁盘上存储的一行数据里有另一块特殊的数据区域，就是NULL值列表。

这个所谓的NULL值列表，顾名思义，说的就是一行数据里可能有的字段值是NULL，比如有一个name字段，它是允许为NULL的，那么实际上在存储的时候，如果你没给它赋值，它这个字段的值就是NULL。

由于它是个NULL，说明什么值都没有。实际上在磁盘上存储数据的时候，一行数据里的NULL值是肯定不会直接按照字符串的方式存放在磁盘上浪费空间的。

2. **NULL值是以二进制bit位来存储的**

一个表中的所有NULL值，不通过字符串在磁盘上存储，而是通过二进制的bit位来存储，一行数据里假设有多个字段的值都是NULL，那么这多个字段的NULL，就会以bit的形式存储在NULL值列表中。

假设当前有个表，有5个字段：name address gender job school ，其中的gender是CHAR(1)，其他的是VARCHAR(10~50不等）的字段类型，而除了第一个字段声明了NOT NULL的，其他4个字段都可能是NULL。

如果该表有一行数据存储到磁盘的话，举例来说它的格式是： “jack NULL m NULL xx_school”，它的字段里有两个字段都是NULL。

3. **结合案例来思考一行数据的磁盘存储格式**

前面说过，一行数据在磁盘上的存储格式应该是下面这样的：

> 变长字段长度列表 | NULL值列表 | 记录头信息 | column1=value1 | column2=value2 | … | columnN=valueN |

如果该表有一行数据存储到磁盘的话，举例来说它的格式是： “jack NULL m NULL xx_school”，它的字段里有两个字段都是NULL。

只有name和school两个变长字段是有值的，把他们的长度按照逆序放在变长字段长度列表中就可以了，如下所示：

> 0x09 0x04 NULL值列表 头信息 column1=value1 column2=value2 … columnN=valueN

接着来看NULL值列表，这个NULL值列表是这样存放的，所有允许值为NULL的字段。只要是允许你为NULL的字段，在这里每个字段都有一个二进制bit位的值，如果bit值是1说明是NULL，如果bit值是0说明不是NULL。

以上面的例子，也就是一行数据的值是 “jack NULL m NULL xx_school” 来说，他这里有四个变长字段，其中2个字段是null，2个字段不是null，所以4个bit位应该是： 1010。

由于实际放在NULL值列表的时候，是按逆序放的，所以在NULL值列表里，放的是： 0101，整体这一行数据看着是下面这样的：

> 0x09 0x04 0101 头信息 column1=value1 column2=value2 … columnN=valueN

另外由于它实际NULL值列表存放的时候，不会仅仅是4个bit位，一般起码是8个bit位的倍数，如果不足8个bit位就高位补0，所以实际存放看起来是如下的：

> 0x09 0x04 00000101 头信息 column1=value1 column2=value2 … columnN=valueN

4. **磁盘上的一行数据是如何读取出来的？**

在上面的原理分析中，一行数据的磁盘数据存储格式如下：

> 0x09 0x04 00000101 头信息 column1=value1 column2=value2 … columnN=valueN

那么如果想要将他从磁盘上读取出来。

首先要把变长字段长度列表和NULL值列表读取出来，通过综合分析一下，就知道有几个变长字段，哪几个变长字段是NULL，因为NULL值列表里谁不是NULL都一清二楚。

如果是变长字段的值，就按照他的值长度来读取，如果是NULL，就知道它是个NULL，没有值存储，如果是定长字段，就按照定长长度来读取，这样就可以完美的把一行数据的值都读取出来了。

#### 9、MySQL事务的ACID是怎么保证的，或者说是怎么实现的

**MySQL事务的ACID，其中（C）一致性是最终目的。**

保证一致性的措施有：
**A**原子性：靠undo log来保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功是sql。
**D**持久性：靠redo log来保证，MySQL修改数据的时候会在redo log中记录一份日志数据，就算数据没有保存成功，只要日志保存成功了，数据仍然不会丢失。
**I**隔离性：靠数据库的锁，加上MVCC实现的。
**C**一致性：一致性是由其他三大特征保证，同时程序代码要保证业务上的一致性。既需要数据库层面保证，又需要应用层面进行保证，并且MySQL底层通过两阶段提交事务保证了事务持久化时的一致性。
————————————————
原文链接：https://blog.csdn.net/YangYoung_/article/details/117195841

#### 10、MySQL的两阶段提交

bin log适用于数据恢复、主从复制（维护集群内数据的一致性），redo log用于崩溃恢复，undo log相对于前面两种日志更好理解些，就是为了回滚事务用的。虽然它们都属于持久化的保证，但是侧重点不同。

在执行更新语句过程，会记录`redo log`与`binlog`两块日志，以基本的事务为单位，`redo log`在事务执行过程中可以不断写入，而`binlog`只有在提交事务时才写入，所以`redo log`与`binlog`的写入时机不一样。

**两阶段提交过程**

InnoDB引擎更新一条指定数据的过程如下：

<img src="asset\MySQL两阶段提交.png" alt="在这里插入图片描述" style="zoom:80%;" />

<img src="asset\MySQL两阶段提交JavaGuide.png" alt="img" style="zoom: 67%;" />

可以看到，InnoDB在写redo log时，并不是一次性写完的，而有两个阶段，Prepare与Commit阶段，这就是"两阶段提交"的含义。

**为什么要写两次redo log，写一次不行吗？**

redo log与binlog都写一次的话，也就是存在以下两种情况：

1. 先写binlog，再写redo log：当前事务提交后，写入binlog成功，之后主节点崩溃。在主节点重启后，由于没有写入redo log，因此不会恢复该条数据。而从节点依据binlog在本地回放后，会相对于主节点多出来一条数据，从而产生主从不一致。
2. 先写redo log，再写binlog：当前事务提交后，写入redo log成功，之后主节点崩溃。在主节点重启后，主节点利用redo log进行恢复，就会相对于从节点多出来一条数据，造成主从数据不一致。

因此，只写一次redo log与binlog，无法保证主节点崩溃恢复与从节点本地恢复数据的一致性。

**在两阶段提交的情况下，是怎么实现崩溃恢复的呢？**

首先比较重要的一点是，在写入 `redo log` 时，会顺便记录 XID，即当前事务 id。在写入 `binlog` 时，也会写入 XID。因此存在以下三种情况：

1. 如果在写入 `redo log` 之前崩溃，那么此时 `redo log` 与 `binlog `中都没有，是一致的情况，崩溃也无所谓。

2. 如果在写入 `redo log prepare` 阶段后立马崩溃，之后会在崩恢复时，由于 `redo log` 没有被标记为 commit。于是拿着 `redo log` 中的 XID 去 `binlog` 中查找，此时肯定是找不到的，那么执行回滚操作。

3. 如果在写入 `binlog` 后立马崩溃，在恢复时，由 `redo log` 中的 XID 可以找到对应的 `binlog`，这个时候直接提交即可。

总的来说，在崩溃恢复后，只要 `redo log` 不是处于 commit 阶段，那么就拿着 `redo log` 中的 XID 去 `binlog` 中寻找，找得到就提交，否则就回滚。在这样的机制下，两阶段提交能在崩溃恢复时，能够对提交中断的事务进行补偿，来确保 `redo log` 与 `binlog` 的数据一致性。

   ————————————————
   原文链接：https://blog.csdn.net/TABE_/article/details/124935324

#### 11、redo log、undo log、binlog

[undo log, redo log, binlog](https://xiaolincoding.com/mysql/log/how_update.html)

**redo log**

　　重做日志，记录的是事务提交时数据页的物理修改。

　　作用：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。

　　内容：物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。

**undo log**

　　回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志。

​				当insert的时候，产生的undo log日志只在回滚时需要，在事务提交后，可被立即删除。

​				而update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读时也需要，不会立即被删除。

　　作用：保存了事务发生之前的数据的一个版本，可以用于回滚

​					同时可以提供多版本并发控制下的读（MVCC），也即非锁定读

　　内容：逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。

**binlog**

　　归档日志（[二进制](https://so.csdn.net/so/search?q=二进制&spm=1001.2101.3001.7020)日志）

　　作用：用于主从复制中，从库利用主库上的 `binlog` 进行重播，实现主从同步。
				   用于数据库恢复。

　　内容：逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句，记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但不包括数据查询（SELECT、SHOW）语句。

但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。

　　binlog 有三种模式：Statement（基于 SQL 语句的复制）、Row（基于行的复制） 以及 Mixed（混合模式）

​		写入机制：`binlog`的写入时机也非常简单，事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。因为一个事务的`binlog`不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为`binlog cache`。

**redo log和binlog的不同**

1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
3. redo log 是循环写的，空间固定会用完；`binlog` 是可以追加写入的。“追加写”是指 `binlog` 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
4. redo log用于崩溃恢复（事务，恢复事务已提交但未写入数据表的数据）；`binlog` 用于数据库恢复、MySQL主从复制，并且不具备崩溃自动恢复的能力。

<img src="https://img-blog.csdnimg.cn/fea6fbecbe5f40699673bcee8b167a78.png#pic_center" alt="在这里插入图片描述" style="zoom:80%;" />

​	https://blog.csdn.net/qq_37469055/article/details/118371794

#### 12、为什么有了binlog还要有redo log？

1. binlog会记录所有与MySQL数据库有关的日志记录，包括InnoDB, MyISAM，Heap等其他存储引起的日志。而redo log只记录innodb引擎本身的日志。
2. binlog记录的是关于一个事务的具体操作内容，即该日志是逻辑日志。而redo log记录的是关于每个页的更改的物理情况。
3. 写入时间不同。binlog仅在事务最终commit前写入，只写磁盘一次，不论这个事务有多大。而redo log在事务进行过程中会不停的写入。

​	它们分工是不同的。binlog用来做数据归档，但不具备崩溃恢复的能力，也就是说如果系统突然崩溃，重启后可能会有部分数据丢失。innodb将所有对页面的修改操作写入一个专门的文件，并在数据库启动时从此文件进行恢复操作。

————————————————
原文链接：https://blog.csdn.net/hhy107107/article/details/110847342

#### 13、为什么说 [redo log](https://www.zhihu.com/search?q=redo log&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2280710259}) 具有崩溃恢复的能力？

前面我们说过，[MySQL Server](https://www.zhihu.com/search?q=MySQL Server&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2280710259}) 层拥有的 bin log 只能用于归档，不足以实现崩溃恢复（crash-safe），需要借助 InnoDB 引擎的 redo log 才能拥有崩溃恢复的能力。所谓[崩溃恢复](https://www.zhihu.com/search?q=崩溃恢复&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2280710259})就是：即使在数据库宕机的情况下，也不会出现操作一半的情况

至于为什么说 redo log 具有崩溃恢复的能力，而 [binlog](https://www.zhihu.com/search?q=bin log&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2280710259}) 没有，我们先来简单看一下这两种日志有哪些不同点：

1）**适用对象不同**：

- binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用
- 而 redo log 是 InnoDB 引擎特有的

2）**写入内容不同**：

- binlog 是[逻辑日志](https://www.zhihu.com/search?q=逻辑日志&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2280710259})，记录的是这个语句的原始逻辑，比如 “给 id = 1 这一行的 age 字段加 1”
- redo log 是[物理日志](https://www.zhihu.com/search?q=物理日志&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2280710259})，记录的是 “在某个数据页上做了什么修改”

3）**[写入方式](https://www.zhihu.com/search?q=写入方式&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2280710259})不同**：

- binlog 是可以追加写入的。“追加写” 是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志
- redo log 是循环写的，空间固定会被用完

可以看到，redo log 和 binlog 的一个很大的区别就是，一个是循环写，一个是追加写。也就是说 **redo log 只会记录未刷入磁盘的日志**，已经刷入磁盘的数据都会从 redo log 这个有限大小的[日志文件](https://www.zhihu.com/search?q=日志文件&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2280710259})里删除，因此具备“**崩溃恢复**”的功能。

而 binlog 是追加日志，保存的是**全量的日志**，因此具备“**归档**”的功能。这就会导致一个问题，那就是没有标志能让 InnoDB 从 binlog 中判断哪些数据已经刷入磁盘了，哪些数据还没有。

举个例子，binlog 记录了两条日志：

```
记录 1：给 id = 1 这一行的 age 字段加 1
记录 2：给 id = 1 这一行的 age 字段加 1
```

假设在记录 1 刷盘后，记录 2 未刷盘时，数据库崩溃。重启后，只通过 binlog 数据库是无法判断这两条记录哪条已经写入磁盘，哪条没有写入磁盘，不管是两条都恢复至内存，还是都不恢复，对 id = 1 这行数据来说，都是不对的。

但 redo log 不一样，只要**刷入磁盘的数据，都会从 redo log 中被抹掉**，数据库重启后，直接把 redo log 中的数据都恢复至内存就可以了。

这就是为什么说 redo log 具有崩溃恢复的能力，而 binlog 不具备。

链接：https://blog.csdn.net/minghao0508/article/details/127763412

#### 14、聚集索引和非聚集索引的区别？

聚集索引一个表只能有一个，而非聚集索引一个表可以存在多个

聚集索引存储记录是物理上连续存在，而非聚集索引是逻辑上的连续

聚集索引物理存储按照索引排序，而非聚集索引物理存储不按照索引排序

#### 15、数据库SQL调优的几种方式

**一、创建索引**

1. 要尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
2. (1) 在经常需要进行检索的字段上创建索引，比如要按照表字段username进行检索，那么就应该在姓名字段上创建索引，如果经常要按照员工部门和员工岗位级别进行检索，那么就应该在员工部门和员工岗位级别这两个字段上创建索引。
   (2) 创建索引给检索带来的性能提升往往是巨大的，因此在发现检索速度过慢的时候应该首先想到的就是创建索引。
   (3) 一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。索引并不是越多越好，索引固然可以提高相应的 select 效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。

**二、避免在索引上使用计算或者函数操作**

1. 在where字句中，如果索引列是计算或者函数的一部分，DBMS的优化器将不会使用索引而使用全表查询,函数属于计算的一种,同时在in和exists中通常情况下使用EXISTS，因为in不走索引。

```mysql
效率低：select * from user where salary*22>11000(salary是索引列)

效率高：select * from user where salary>11000/22(salary是索引列)
```

**三、使用预编译查询**

1. 程序中通常是根据用户的输入来动态执行SQL，这时应该尽量使用参数化SQL,这样不仅可以避免SQL注入漏洞攻击，最重要数据库会对这些参数化SQL进行预编译，这样第一次执行的时候DBMS会为这个[SQL语句](https://so.csdn.net/so/search?q=SQL语句&spm=1001.2101.3001.7020)进行查询优化并且执行预编译，这样以后再执行这个SQL的时候就直接使用预编译的结果，这样可以大大提高执行的速度。

**四、调整Where子句中的连接顺序**

1.  DBMS一般采用自下而上的顺序解析where字句，根据这个原理 <u>表连接最好写在其他where条件之前</u>  ，那些可以过滤掉最大数量记录。

**五、尽量将多条SQL语句压缩到一句SQL中**

​    每次执行SQL的时候都要建立网络连接、进行权限校验、进行SQL语句的查询优化、发送执行结果，这个过程是非常耗时的，因此应该尽量避免过多的执行SQL语句，能够压缩到一句SQL执行的语句就不要用多条来执行。

**六、用where字句替换HAVING字句**

​    避免使用HAVING字句，因为HAVING只会在检索出所有记录之后才对结果集进行过滤，而where则是在聚合前刷选记录，如果能通过where字句限制记录的数目，那就能减少这方面的开销。HAVING中的条件一般用于聚合函数 的过滤，除此之外，应该将条件写在where字句中。

**七、使用表的别名**

​    当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减 少哪些友列名歧义引起的语法错误。

**八、用union all替换union**

​    当SQL语句需要union两个查询结果集合时，即使检索结果中不会有重复的记录，如果使用union这两个结果集 同样会尝试进行合并，然后在输出最终结果前进行排序，因此如果可以判断检索结果中不会有重复的记录时候，应该用union all，这样效率就会因此得到提高。

**九、考虑使用“临时表”暂存中间结果**

​    简化SQL语句的重要方法就是采用临时表暂存中间结果，但是，临时表的好处远远不止这些，将临时结果暂存在临时表，后面的查询就在tempdb中了，这可以避免程序中多次扫描主表，也大大减少了程序执行中“共享锁”阻塞“更新锁”，减少了阻塞，提高了并发性能。
但是也得避免频繁创建和删除临时表，以减少系统表资源的消耗。

**十、只在必要的情况下才使用事务begin translation**

​    SQL Server中一句SQL语句默认就是一个事务，在该语句执行完成后也是默认commit的。其实，这就是begin tran的一个最小化的形式，好比在每句语句开头隐含了一个begin tran，结束时隐含了一个commit。
有些情况下，我们需要显式声明begin tran，比如做“插、删、改”操作需要同时修改几个表，要求要么几个表都修改成功，要么都不成功。begin tran 可以起到这样的作用，它可以把若干SQL语句套在一起执行，最后再一起commit。 好处是保证了数据的一致性，但任何事情都不是完美无缺的。Begin tran付出的代价是在提交之前，所有SQL语句锁住的资源都不能释放，直到commit掉。
可见，如果Begin tran套住的SQL语句太多，那数据库的性能就糟糕了。在该大事务提交之前，必然会阻塞别的语句，造成block很多。
Begin tran使用的原则是，在保证数据一致性的前提下，begin tran 套住的SQL语句越少越好！有些情况下可以采用触发器同步数据，不一定要用begin tran。

**十一、尽量避免使用游标**

​    尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。

**十二、用varchar/nvarchar 代替 char/nchar**

​    尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。

**十三、查询select语句优化**

       1. 任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段，即使是表中所有的字段都要查询，在数据量比较大的表中，字段全写上也是比 * 号查询速度要快。
       2. 应尽量避免在 where 子句中对字段进行 null 值判断，否则将可能导致引擎放弃使用索引而进行全表扫描（根据数据分布选择），

```sql
select id from t where num is null 
```

可以在num上设置默认值0，确保表中num列没有null值，
然后这样查询：

```sql
select id from t where num=0
select id from t where num=10 or num=20
```

 可以这样查询：

```sql
select id from t where num=10
union all
select id from t where num=20
```

​    3. 不能前置百分号，否则会导致索引失效

```sql
select id from t where name like ‘%abc%’
```

若要提高效率，可以考虑全文检索。

​    4. 对于连续的数值，能用 between 就不要用 in 了：

```sql
select id from t where num in(1,2,3) # 会根据数据范围选择是否使用索引

效率高：select id from t where num between 1 and 3
```

​    5. 如果查询的两个表大小相当，那么用in和exists差别不大。

例如：表A（小表），表B（大表）

```sql
select * from A where cc in (select cc from B) # 效率低，用到了A表上cc列的索引； 
select * from A where exists(select cc from B where cc=A.cc) # 效率高，用到了B表上cc列的索引。 
```

相反的

```sql
select * from B where cc in (select cc from A) # 效率高，用到了B表上cc列的索引；
select * from B where exists(select cc from A where cc=B.cc) # 效率低，用到了A表上cc列的索引。 
```

**十四、更新Update语句优化**

​    如果只更改1、2个字段，不要Update全部字段，否则频繁调用会引起明显的性能消耗，同时带来大量日志

**十五、 删除Delete语句优化语句**

​    最高效的删除重复记录方法 ( 因为使用了ROWID，oracle)例子：

```sql
DELETE FROM EMP E WHERE E.ROWID > (SELECT MIN(X.ROWID) FROM EMP X WHERE X.EMP_NO = E.EMP_NO);
```

**十六、插入Insert语句优化**

​    在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。

​	使用批量插入或者使用 load 命令批量加载文件数据。

​	https://blog.csdn.net/weixin_43108539/article/details/106280297

#### 16、limit深分页慢的原因以及解决方式

<img src="https://img-blog.csdnimg.cn/img_convert/57687629365dee1b0e801d545327f4f0.webp?x-oss-process=image/format,png" alt="img" style="zoom: 67%;" />

https://blog.csdn.net/qq_26222859/article/details/47360911

#### 17、MySQL建表时注意什么？

MySQL建表的经验有很多，下边列举一些：

1、注意选择存储引擎，如果要支持事务需要选择InnoDB。

2、注意字段类型的选择，对于日期类型如果要记录时分秒建议使用datetime，只记录年月日使用date类型，对于字符类型的选择，固定长度字段选择char，不固定长度的字段选择varchar，varchar比char节省空间但速度没有char快；对于内容介绍类的长广文本字段使用text或longtext类型;如果存储图片等二进制数据使用blob或longblob类型；对金额字段建议使用DECIMAL；对于数值类型的字段在确保取值范围足够的前提下尽量使用占用空间较小的类型，

3、主键字段建议使用自然主键，不要有业务意义，建议使用int unsigned类型，特殊场景使用bigint类型。

4、如果要存储text、blob字段建议单独建一张表，使用外键关联。

5、尽量不要定义外键，保证表的独立性，可以存在外键意义的字段。

6、设置字段默认值，比如：状态、创建时间等。

7、每个字段写清楚注释。

8、注意字段的约束，比如：非空、唯一、主键等。

#### 18、树型表的标记字段是什么？如何查询MySQL树型表？

树型表的标记字段是parentid即父结点的id。

查询一个树型表的方法：

1）当层级固定时可以用表的自链接进行查询。

2）如果想灵活查询每个层级可以使用mysql递归方法，使用with RECURSIVE 实现。

#### 19、那为什么每一次提交事务，要刷新redo log 到磁盘中呢，而不是直接将buffer pool中的脏页刷新到磁盘呢 ?

因为在业务操作中，我们操作数据一般都是**随机读写**磁盘的，而不是顺序读写磁盘。 而redo log在往磁盘文件中写入数据，由于是日志文件，所以都是**顺序写**的。顺序写的效率，要远大于随机写。 这种先写日志的方式，称之为 WAL（Write-Ahead Logging）。

#### 20、SQL语句在MySQL中的执行过程

<img src="asset\MySQL语句执行过程.png" alt="image-20230417153013644" style="zoom:70%;" />

**1 查询语句**

说了以上这么多，那么究竟一条 SQL 语句是如何执行的呢？其实我们的 SQL 可以分为两种，一种是查询，一种是更新（增加，修改，删除）。我们先分析下查询语句，语句如下：

```sql
select * from tb_student  A where A.age='18' and A.name=' 张三 ';
```

结合上面的说明，我们分析下这个语句的执行流程：

- 先检查该语句是否有权限，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先查询缓存，以这条 SQL 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。

- 通过分析器进行词法分析，提取 SQL 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student，需要查询所有的列，查询条件是这个表的 id='1'。然后判断这个 SQL 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。

- 接下来就是优化器进行确定执行方案，上面的 SQL 语句，可以有两种执行方案：

  ```text
    a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。
    b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。
  ```

  那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。

- 进行权限校验，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。

**2 更新语句**

以上就是一条查询 SQL 的执行流程，那么接下来我们看看一条更新语句如何执行的呢？SQL 语句如下：

```mysql
update tb_student A set A.age='19' where A.name=' 张三 ';
```

我们来给张三修改下年龄，在实际数据库肯定不会设置年龄这个字段的，不然要被技术负责人打的。其实这条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志啦，这就会引入日志模块了，MySQL 自带的日志模块是 **binlog（归档日志）** ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 **redo log（重做日志）**，我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：

- 先查询到张三这一条数据，如果有缓存，也是会用到缓存。
- 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时记录 redo log，此时 redo log 进入 prepare 状态，然后告诉执行器，执行完成了，随时可以提交。
- 执行器收到通知后记录 binlog，然后调用引擎接口，提交 redo log 为 commit 状态。
- 更新完成。

**总结**

- MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用，redolog 只有 InnoDB 有。

- 引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。

- 查询语句的执行流程如下：权限校验（如果命中缓存）--->查询缓存--->分析器--->优化器--->权限校验--->执行器--->引擎

- 更新语句执行流程如下：分析器---->权限校验---->执行器--->引擎---redo log(prepare 状态)--->binlog--->redo log(commit状态

------

著作权归所有 原文链接：https://javaguide.cn/database/mysql/how-sql-executed-in-mysql.html

#### 21、MySQL的自增值一定是连续的吗？

众所周知，自增主键可以让聚集索引尽量地保持递增顺序插入，避免了随机查询，从而提高了查询效率。但实际上，MySQL 的自增主键并不能保证一定是连续递增的。

保存位置：

1）MyISAM 引擎的自增值保存在数据文件中；

2）InnoDB 引擎的自增值，其实是保存在了内存里，并没有持久化。第一次打开表的时候，都会去找自增值的最大值 `max(id)`，然后将 `max(id)+1` 作为这个表当前的自增值。实际上，**到了 MySQL 8.0 版本后，自增值的变更记录被放在了 redo log 中，提供了自增值持久化的能力** ，也就是实现了“如果发生重启，表的自增值可以根据 redo log 恢复为 MySQL 重启前的值”。

不连续的情况：

1. 自增初始值和自增步长设置不为 1
2. 唯一键冲突
3. 事务回滚
4. 批量插入（如 `insert...select` 语句）

参考：https://javaguide.cn/database/mysql/mysql-auto-increment-primary-key-continuous.html#%E8%87%AA%E5%A2%9E%E5%80%BC%E4%B8%8D%E8%BF%9E%E7%BB%AD%E7%9A%84%E5%9C%BA%E6%99%AF

#### 22、MySQL索引失效的情况

1、在索引列上带有运算；

2、在索引列上使用函数；

3、使用%XXX左模糊查询，因为mysql是最左原则，使用XXX%右模糊查询是可以使用索引的，但是左模糊违背了最左原则所以不行；

4、使用范围运算，not in，in， >，< 都不行，使用 in 以及 not in 走不走索引，实际和 Mysql 的版本以及表中的数据量有关系，在 8.0 之后的版本 IN 通常是走索引的，当 IN 后面的数据在数据表中超过30%的匹配时是全表扫描，不走索引，因此IN走不走索引和后面的数据量有关系；

5、查询的字段不是索引的最左字段，同样是因为最左原则；

6、字段类型不匹配，常见的隐式数据类型转换，mobile=1356不会走索引，会转换为字符串可以查询但是，mobile='1356'会走索引；**注意：当字段类型为数字时，无论参数类型为字符串还是数字都会走索引。**

7、or条件左边的是索引字段，右边的不是。也不会走索引，因为or是一个并集，只有两侧都有索引才能生效；

8、数据分布，如果MySQL评估使用索引比全表更慢，则不使用索引。因为索引是用来**索引少量数据**的，如果通过索引查询返回大批量的数据，则还不如走全表扫描来的快，此时索引就会失效。（>=、<=、is null 、 is not null、in、not in）。

> 因为在MySQL中，数字和字符串的比较是将字符串转为数字再进行比较的。如果查询时用字符串那么被转换的是SQL中的字符串，这样不会影响表索引。而如果查询时用的是数字，字段格式是字符串，意味着表中的数据格式需要转换，用字符串格式建立的索引是不匹配的，因此不使用索引。

————————————————

[索引失效的场景](https://xiaolincoding.com/mysql/index/index_lose.html)

原文链接：https://blog.csdn.net/Anna_luo/article/details/123526416

----

```mysql
unique index(a,b,c,d);
# 【等值匹配原则】
EXPLAIN SELECT * FROM `abcd` WHERE a = 1 AND b = 1 AND c = 1; # key_len = 15

# 【最左列匹配原则】
EXPLAIN SELECT * FROM `abcd` WHERE a = 1 AND b = 1; # key_len=10
EXPLAIN SELECT * FROM `abcd` WHERE b = 1; # key_len = 20 全表扫描

# 【最左前缀匹配原则】 - a varchar(255)
EXPLAIN SELECT * FROM `abcd` WHERE a LIKE '1%'; # key_len = 5
EXPLAIN SELECT * FROM `abcd` WHERE a LIKE '%1%'; # key_len = 20	全表扫描，再where过滤

# 【范围查找原则】（进行范围查找时，只有联合索引最左侧的字段才能命中索引）
EXPLAIN SELECT * FROM `abcd` WHERE a > 1; # key_len=5 （a命中，bc未命中，下同）
EXPLAIN SELECT * FROM `abcd` WHERE a > 0 AND a < 5; # key_len = 5

# 【等值查询+范围查询】
-- 虽然b没有走索引，但是这里使用了【索引下推】进行了优化，也就是在 a>0 的数据前提下，判断b的条件来决定是否砸偶索引
EXPLAIN SELECT * FROM `abcd` WHERE a > 0 AND a < 5 AND b = 1; # key_len = 5 （a命中，b不命中）

-- b范围值，断点，阻塞了c的索引，但b自身用到了索引
EXPLAIN SELECT * FROM `abcd` WHERE a = 1 AND b > 1 AND c = 1; # key_len = 10 （ab命中，c未命中）

EXPLAIN SELECT * FROM `abcd` WHERE a = 1 AND b = 1 AND c > 1; # key_len = 15 （abc都命中）

# 【覆盖索引】
-- Extra: Using where;Using index
EXPLAIN SELECT * FROM `abcd` WHERE b = '1';			# key_len=20	全表扫描，走全索引，然后再通过where过滤
EXPLAIN SELECT * FROM `abcd` WHERE a LIKE '%1%';	# key_len=20	全表扫描，走全索引，同上
EXPLAIN SELECT * FROM `abcd` WHERE b LIKE '%1%';	# key_len=20	全表扫描，走全索引，同上

1	SIMPLE	abcd		index	abcd	abcd	20		5	20.00	Using where; Using index
```

> [在MySQL中使用!=还能走索引吗？](https://blog.csdn.net/Maisule/article/details/129386447)
>
> 其实，走不走索引，只取决于一个因素，那就是**成本**。
>
> 我们知道，MySQL中有一个叫做优化器的东西，他会对每一条查询sql做成本分析，然后根据分析结果选择是否使用索引或者全表扫描。
>
> 覆盖索引一定会走的，但通过索引查找需要回表扫描时，这个时候就会根据代价来选择是否要走索引。
>
> - 范围查询：如果范围查询走了索引，范围查询条件虽然走了索引，但是**范围查询条件之后的条件**，都会失效。
>   - 因为范围的话，没法确定下一个的顺序，比如，a>1，这里面a=2可能的b=1，二a=1的b可能100，b不是有序的了。
>
> ---
>
> GPT：
>
> MySQL的>和<查询在某些情况下可以走索引，但并非在所有情况下都能使用索引。
>
> 当使用>和<进行范围查询时，MySQL可以尝试使用B树索引。如果表中存在适当的B树索引，并且查询条件涉及到该索引的列，MySQL可以选择使用索引来加速查询。
>
> 然而，是否选择使用索引还取决于多个因素，包括查询的复杂性、**表中数据的分布**以及索引的有效性等。在一些特定情况下，MySQL可能会选择不使用索引，而是执行全表扫描或者其他更优的查询计划。
>
> 总的来说，对于复杂的查询操作，包括使用>和<进行范围查询，应当根据实际情况进行测试和评估，以确定是否可以有效地使用索引来提升查询性能。

视频链接：https://www.bilibili.com/video/BV1ya41157oE

[关于mysql使用!=或者＜＞会导致索引失效问题的验证](https://feixiang.blog.csdn.net/article/details/113883206)

总结：

5.0的mysql，使用!=或者<>会造成索引失效。

8.0的mysql，使用!=或者<>会正常走索引，但是要注意，它属于范围查询，范围查询条件虽然走了索引，但是**范围查询条件之后的条件**，都会失效哦。

#### 23、MySQL的主从复制

**概述**

主从复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步。

MySQL支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制。

![image-20230218173550681](asset\MySQL主从库.png)

MySQL 复制的优点主要包含以下三个方面：

- 主库出现问题，可以快速切换到从库提供服务。

- 实现读写分离，降低主库的访问压力。

- 可以在从库中执行备份，以避免备份期间影响主库服务。

**原理**

MySQL主从复制的核心就是 二进制日志，具体的过程如下：

<img src="asset\MySQL主从复制.png" alt="image-20230218173716518" style="zoom:80%;" />

从上图来看，复制分成三步：

\1. Master 主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。

\2. 从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log 。

\3. slave重做中继日志中的事件，将改变反映它自己的数据。

**主从复制保证数据一致性**

一、保证MYSQL（MASTER端）日志和数据的统一性，处理掉电、宕机等异常情况。

1、MySQL作为一个可插拔的数据库系统，支持插件式的存储引擎，在设计上分为Server层和Storage Engine层。

2、在Server层，MySQL以events的形式记录数据库各种操作的Binlog二进制日志，其基本核心作用有：复制和备份。除此之外，我们结合多样化的业务场景需求，基于Binlog的特性构建了强大的MySQL生态，如：DTS、单元化、异构系统之间实时同步等等，Binlog早已成为MySQL生态中不可缺少的模块。

3、在Storage Engine层，InnoDB作为比较通用的存储引擎，其在高可用和高性能两方面作了较好的平衡，早已经成为使用MySQL的首选（PS：官方从MySQL 5.5.5开始，将InnoDB作为了MySQL的默认存储引擎 ）。和大多数关系型数据库一样，InnoDB采用WAL技术，即InnoDB Redo Log记录了对数据文件的物理更改，并保证总是日志先行，在持久化数据文件前，保证之前的redo日志已经写到磁盘。Binlog和InnoDB Redo Log是否落盘将直接影响实例在异常宕机后数据能恢复到什么程度。InnoDB提供了相应的参数来控制事务提交时，写日志的方式和策略。

二、保证MYSQL（SLAVE端）同步时和MASTER端保持一致。

1、异步复制

​		主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从库上，如果此时，强行将从提升为主，可能导致“数据不一致”。早期MySQL(5.5以前仅仅支持异步复制。

2、半同步复制

​		MySQL在5.5中引入了半同步复制，主库在应答客户端提交的事务前需要保证至少一个从库接收并写到relay log中，半同步复制通过rplsemi syncmaster wait point参数来控制master在哪个环节接收slave ack，master接收到ack后回状态给客户端，此参数一共有两个选项 AFTER_SYNC & AFTER_COMMIT

```sql
rpl_semi.syncmasterawaitpoint=WAIT AFTER COWMIT
```

rpl_semi sync master wait point为WAIT AFTER COMMIT时commitTrx的调用在engine层commit之后，即在等待Slave ACK时候，虽然没有返回当前客户端，但事务已经提交，其他客户端会读取到已提交事务。如果Slave端还没有读到该事务的events，同时主库发生了crash，然后切换到备库。那么之前读到的事务就不见了，出现了数据不一致的问题。如果主库永远启动不了，那么实际上在主库已经成功提交的事务，在从库上是找不到的，也就是数据丢失了。

3、全同步复制

MySQL官方针对上述问题，在5.7.2引入了Loss-less Semi-Synchronous，;在调用binlog sync之.前等待Slave ACK。这样只有在确认slave收到事务events后，事务才会提交。

```sql
rpl_semi_sync_master_wait_point=WAIT_AFTER_SYNC
```

在after sync模式下解决了after_commit模式带来的数据不一致的问题，因为主库没有提交事务。但也会有个问题，当主库在binlog flush并且binlog同步到了备库之后，binlog sync之前发生了abort，那么很明显这个事务在主库上是未提交成功的(由于abort之前binlog未sync完成，主库恢复后事务会被回滚掉)，但由于从库已经收到了这些Binlog，并且执行成功相当于在从库上多出了数据，从而可能造成“数据不一致”。

此外，MySQL半同步复制架构中，主库在等待备库ack时候，如果超时会退化为异步后，也可能导致“"数据不一致”。

三、备注&解决方案（以上解决思路可以满足99.8%公司的业务场景）

1、通过以上两点的分析和配置，我们发现MySQL自身的Repliaction已经无法满足我们爱钻牛角尖同学的欲望了（后端的程序员思维都会过于缜密），怎么办？为了保证主从的数据绝对一致性，下面我来提供两个思路（今天有点累，仅仅是思路，具体解决方案请听下回分解）。

2、阿里云自己研发的数据订正平台。

3、PXC数据强一致性解决方案并且支持多主多从哦，缺点是需要向老板申请性能差别不大的机器做集群。

链接：[MYSQL 主从复制如何保证数据一致性](https://mbd.baidu.com/newspage/data/landingsuper?sid_for_share&qq-pf-to=pcqq.c2c&isBdboxFrom=1&pageType=1&urlext=%7B%22cuid%22%3A%220a2SfYaCv8lgaHi__uSHtguISul682uEgavfigP3HiKs0qqSB%22%7D&context=%7B%22nid%22%3A%22news_9208508885793902971%22,%22sourceFrom%22%3A%22search%22%7D)

#### 24、为什么InnoDB存储引擎选择使用B+tree索引结构?

A.  相对于二叉树，层级更少，搜索效率高；

B.  对于B-tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储的键值减少，指针跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低；

C.  相对Hash索引，B+tree支持范围匹配及排序操作；

存放同样的数据，b树的高度可能比b+树要高，查询起来会增加io次数，速度会慢。非叶子节点只存储key值，故可以有更多的指针（子节点）。

#### 25、InnoDB主键索引的B+tree高度为多高呢？

<img src="asset\B+树.png" alt="image-20230219190330489" style="zoom: 67%;" />

> 假设:
>
> ​		`一个区大小为1M，一个页大小为16K，故一个区内有64个连续的页。`
>
> ​		一行数据大小为1k，一页中可以存储16行这样的数据。InnoDB的指针占用6个字节空间，主键即使为bigint，占用字节数为8。
>
> 高度为2：（即第2行为数据节点，这里一个指针对应一个节点（块/页））
>
> ​				`n * 8 + (n + 1) * 6 = 16 * 1024` , 算出 n 约为 1170									（n为第一行存储的索引个数）
>
> ​				`索引个数 * 占用字节数 + 指针个数 * 占用字节数 = 一页的总字节数`
>
> ​				----------------------------------------------------------------------------------
>
> ​				`1171 * 16 = 18736` 
>
> ​				`总叶子节点数 * 每一叶子节点（页）记录个数 = 存储总记录`
>
> ​				也就是说，如果树的高度为2，则可以存储 18000 多条记录。
>
> 高度为3：（这里第3行为叶子（索引+数据）节点）
>
> ​				`1171 * 1171 * 16 = 21939856`
>
> ​				`第二层节点数 * 每一个节点的索引个数 * 每一叶子节点（页）记录个数 = 存储总记录`
>
> ​				也就是说，如果树的高度为3，则可以存储 2200w 左右的记录。

#### 26、慢查询

**什么是慢查询？**

慢查询，顾名思义，执行很慢的查询。当执行SQL超过long_query_time参数设定的时间阈值（默认10s）时，就被认为是慢查询，这个SQL语句就是需要优化的。慢查询被记录在慢查询日志里。慢查询日志默认是不开启的。如果需要优化SQL语句，就可以开启这个功能，它可以让你很容易地知道哪些语句是需要优化的。

**慢查询配置**

以MySQL数据库为例，默认慢查询功能是关闭的，当慢查询开关打开后，并且执行的SQL语句达到参数设定的阈值后，就会触发慢查询功能打印出日志。

1、慢查询日志
查询是否开启慢查询日志：show variables like ‘slow_query_log’;

开启慢查询sql：set global slow_query_log = 1/on;
关闭慢查询sql：set global slow_query_log = 0/off;

**慢查询解决方案**

1、防止索引失效；

> 1. 索引列做运算；
> 2. 字符串不加引号；
> 3. 模糊查询；
> 4. or连接条件；
> 5. 不符合最左前缀；
> 6. 数据分布影响。

2、SQL语句优化；

> 1. 查询语句应该尽量避免全表扫描，首先应该考虑在Where子句以及OrderBy子句上建立索引，但是每一条SQL语句最多只会走一条索引，而建立过多的索引会带来插入和更新时的开销，同时对于区分度不大的字段，应该尽量避免建立索引，可以在查询语句前使用explain关键字，查看SQL语句的执行计划，判断该查询语句是否使用了索引；
> 2. 应尽量使用EXIST和NOT EXIST代替 IN和NOT IN，因为后者很有可能导致全表扫描放弃使用索引；
> 3. 应尽量避免在Where子句中对字段进行NULL判断，因为NULL判断会导致全表扫描；（数据发布）
> 4. 应尽量避免在Where子句中使用or作为连接条件，因为同样会导致全表扫描；（or连接条件）
> 5. 应尽量避免在Where子句中使用！=或者<>操作符，同样会导致全表扫描；（模糊查询）
> 6. 使用like “%abc%” 或者like “%abc” 同样也会导致全表扫描，而like “abc%”会使用索引。（模糊查询）
> 7. 在使用Union操作符时，应该考虑是否可以使用Union ALL来代替，因为Union操作符在进行结果合并时，会对产生的结果进行排序运算，删除重复记录，对于没有该需求的应用应使用Union ALL，后者仅仅只是将结果合并返回，能大幅度提高性能；
> 8. 应尽量避免在Where子句中使用表达式操作符，因为会导致全表扫描；
> 9. 应尽量避免在Where子句中对字段使用函数，因为同样会导致全表扫描
> 10. Select语句中尽量 避免使用“*”，因为在SQL语句在解析的过程中，会将“”转换成所有列的列名，而这个工作是通过查询数据字典完成的，有一定的开销；
> 11. Where子句中，表连接条件应该写在其他条件之前，因为Where子句的解析是从后向前的，所以尽量把能够过滤到多数记录的限制条件放在Where子句的末尾；
> 12. 若数据库表上存在诸如index(a,b,c)之类的联合索引，则Where子句中条件字段的出现顺序应该与索引字段的出现顺序一致，否则将无法使用该联合索引；
> 13. From子句中表的出现顺序同样会对SQL语句的执行性能造成影响，From子句在解析时是从后向前的，即写在末尾的表将被优先处理，应该选择记录较少的表作为基表放在后面，同时如果出现3个及3个以上的表连接查询时，应该将交叉表作为基表；
> 14. 尽量使用>=操作符代替>操作符，例如，如下SQL语句，select dbInstanceIdentifier from DBInstance where id > 3，该语句应该替换成 select dbInstanceIdentifier from DBInstance where id >=4 ，两个语句的执行结果是一样的，但是性能却不同，后者更加 高效，因为前者在执行时，首先会去找等于3的记录，然后向前扫描，而后者直接定位到等于4的记录。

3、表结构优化；

> 这里主要指如何正确的建立索引，因为不合理的索引会导致查询全表扫描，同时过多的索引会带来插入和更新的性能开销；
>
> 1. 首先要明确每一条SQL语句最多只可能使用一个索引，如果出现多个可以使用的索引，系统会根据执行代价，选择一个索引执行；
> 2. 对于Innodb表，虽然如果用户不指定主键，系统会自动生成一个主键列，但是自动产生的主键列有多个问题1. 性能不足，无法使用cache读取；2. 并发不足，系统所有无主键表，共用一个全局的Auto_Increment列。因此，InnoDB的所有表，在建表同时必须指定主键。
> 3. 对于区分度不大的字段，不要建立索引；
> 4. 一个字段只需建一种索引即可，无需建立了唯一索引，又建立INDEX索引。
> 5. 对于大的文本字段或者BLOB字段，不要建立索引；
> 6. 连接查询的连接字段应该建立索引；
> 7. 排序字段一般要建立索引；
> 8. 分组统计字段一般要建立索引；
> 9. 正确使用联合索引，联合索引的第一个字段是可以被单独使用的，例如有如下联合索引index(userID,dbInstanceID),一下查询语句是可以使用该索引的，select dbInstanceIdentifier from DBInstance where userID=? ，但是语句select dbInstanceIdentifier from DBInstance where dbInstanceID=?就不可以使用该索引；
> 10. 索引一般用于记录比较多的表，假如有表DBInstance，所有查询都有userID条件字段，目前已知该字段已经能够很好的区分记录，即每一个userID下记录数量不多，所以该表只需在userID上建立一个索引即可，即使有使用其他条件字段，由于每一个userID对应的记录数据不多，所以其他字段使用不用索引基本无影响，同时也可以避免建立过多的索引带来的插入和更新的性能开销；

————————————————

MySQL的慢查询是指执行时间较长的SQL查询语句，一般来说，如果一个SQL查询语句的执行时间超过了一定的阈值（比如默认为10秒），那么就会被MySQL服务器记录到慢查询日志中。慢查询会占用数据库的资源，造成性能问题，需要及时解决。

慢查询可以通过以下方法解决：

1. 优化查询语句：检查查询语句是否能够使用索引进行优化，避免全表扫描等操作。

2. 优化数据表：根据查询语句的使用情况，调整数据表的结构和索引，提高数据访问效率。

3. 减少数据量：如果查询需要返回大量数据，可以考虑分页或者限制返回结果的数量，避免影响数据库的性能。

4. 使用缓存：对于经常被查询的数据，可以使用缓存技术，减少数据库的访问次数。

5. 垂直拆分和水平拆分：当数据量过大时，可以考虑将数据拆分成多个表或者数据库，并使用分布式架构来处理查询请求，提高查询效率。

6. 升级硬件：如果以上优化措施仍然无法解决慢查询问题，可以考虑升级硬件，提高服务器的处理速度和内存容量。

总之，解决MySQL慢查询需要综合考虑多个方面，采取不同的优化措施。可以通过监测和分析慢查询日志，找到影响数据库性能的瓶颈，并实施相应的优化措施。

https://blog.csdn.net/vipshop_fin_dev/article/details/125708016

#### 27、不推荐使用JOIN的原因？

1. DB承担的业务压力大，能减少负担就减少。当表处于百万级别后，join导致性能下降；

2. 分布式的分库分表。这种时候是不建议跨库join的。目前mysql的分布式中间件，跨库join表现不良。

3. 修改表的schema，单表查询的修改比较容易，join写的sql语句要修改，不容易发现，成本比较大，当系统比较大时，不好维护。

#### 28、in 和 exist 的区别？

**exist**

exists对外表用loop逐条查询，每次查询都会查看exists的条件语句，当 exists里的条件语句能够返回记录行时(无论记录行是的多少，只要能返回)，条件就为真，返回当前loop到的这条记录，反之如果exists里的条件语句不能返回记录行，则当前loop到的这条记录被丢弃，exists的条件就像一个bool条件，当能返回结果集则为true，不能返回结果集则为 false

**in**

in查询相当于多个or条件的叠加，这个比较好理解，比如下面的查询 sql 

```select * from user where userId in (1, 2, 3);```

等效于

`select * from user where userId = 1 or userId = 2 or userId = 3;`

总的来说，in查询就是先将子查询条件的记录全都查出来，假设结果集为B，共有m条记录，然后在将子查询条件的结果集分解成m个，再进行m次查询

**结论：**

`select * from A where id in(select id from B);`

in() 适合B表比A表数据小的情况

`select a.* from A a where exists(select 1 from B b where a.id=b.id);`

exists() 适合B表比A表数据大的情况

当 A 表数据与 B 表数据一样大时,in 与 exists 效率差不多,可任选一个使用。

————————————————
原文链接：https://blog.csdn.net/weixin_43217065/article/details/108685695

#### 29、MySQL什么情况下会出现主从延迟？

MySQL主从延迟（Replication Delay）是指主库和从库之间数据同步的时间差，即从库上的数据并不是与主库实时同步的，而是有一定的延迟。

以下是可能导致MySQL主从延迟的几种情况：

1. 网络延迟：如果主库与从库之间的网络连接速度慢或者网络波动较大，就会导致主从同步过程中出现延迟。
2. 从库性能问题：如果从库的性能比主库低，例如CPU、内存、磁盘等方面，就可能导致从库同步数据的速度跟不上主库，从而产生延迟。
3. 大量读操作：如果从库上存在大量的查询操作，就会导致从库在处理查询请求的同时无法及时同步主库上的数据，从而产生延迟。
4. 主库负载过高：如果主库上存在大量的写入操作，就会导致主库的负载过高，从而影响其向从库同步数据的速度，从而产生延迟。
5. 数据库备份：当对主库进行备份时，主库会锁定某些表或行，这会影响主库向从库同步数据的速度，从而导致延迟。

为了避免MySQL主从延迟，我们可以采取以下几种措施：

1. 优化网络连接：可以通过优化网络带宽、调整TCP参数等方式来提高主从同步的效率。
2. 提升从库性能：可以通过升级硬件设备、调整配置参数等方式来提高从库的性能，从而加快数据同步的速度。
3. 控制读操作：可以限制从库上的查询操作，避免对主从同步过程造成干扰。
4. 分流写入操作：可以将主库上的写入操作分流到多个从库上进行处理，避免单一从库负载过高导致主从同步延迟。
5. 合理规划备份策略：可以采用异地备份、增量备份等方式，避免备份对主从同步产生影响。

#### 30、间隙锁&临间锁

[next-key](https://link.segmentfault.com/?enc=68lHqmaH9%2BQWe4h1tcvWxQ%3D%3D.2P5Y2Vy471KDpDjYCuV5roHo8dzNJV6qrUEVs24QStOoYVioMax5%2BhDRNDUxZb6w2o%2F55kqD8eEtKy8m33C5HMlZQ67ERi1LojSn4HryKXQg9mtsxDj08I0sEmOe%2Ft1M) 锁是索引记录上的记录锁和索引记录之前的间隙上的间隙锁的组合。

默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。

- 针对唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁。

  > 数据为 ..., 16, 25, 29, 33, ...
  >
  > 查询条件为 id = 16，给 16 加上记录锁。
  >
  > [16]

- 索引上的等值查询(唯一索引)，给不存在的记录加锁时， 优化为间隙锁。

  > 数据为 ..., 16, 25, 29, 33, ...
  >
  > 查询条件为 id = 19，此时会给 25加上间隙锁。
  >
  > (16, 25)

- 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。

  > 数据为 ..., 16, 18, 29, 33, ....
  >
  > 查询的条件为 age = 18，此时给 18加上临间锁，给29加上间隙锁，数据分为两个部分。
  >
  > (16, 18]
  >
  > (18, 29)

- 索引上的范围查询(唯一索引) --会访问到不满足条件的第一个值为止。

  > 查询的条件为 id>=19，并添加共享锁。 此时我们可以根据数据库表中现有的数据，将数据分为三个部分：
  >
  > [19]
  >
  > (19,25]
  >
  > (25,+∞]
  >
  > 所以数据库数据在加锁是，就是将19加了行锁，25的临键锁（包含25及25之前的间隙），正无穷的临键锁(正无穷及之前的间隙)。

注意：间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。

**我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug“**

1. 原则1：加锁的基本单位是next-key lock。希望你还记得，next-key lock是前开后闭区间。
2. 原则2：查找过程中访问到的对象才会加锁
3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁
4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止

#### 31、SQL的执行顺序

from > join > where > group by > 聚合函数 > having > select > order by > limit

```sql
select 
distinct user.name 
from user 
join vip on user.id=vip.id 
where user.id>10 
group by user.mobile 
having count(*)>2 
order by user.id
limit 3;
```

**执行顺序**

1. from user
2. join vip on user.id=vip.id ，join是表示要关联的表，on是连接的条件
3. where user.id>10
4. group by user.mobile 根据user.mobile分组
5. 然后先执行count(*)在执行having，查询分组之后数量大于2的分组数据
6. select 对分组聚合完的表挑选出需要查询的数据
7. distinct查询出来的数据去重
8. order by user.id 对去重后的数据排序
9. limit 3对排序后的数据选出前面3条

#### 32、Explain执行计划

MySQL的Explain语句可以查看SQL查询语句的执行计划，其中Extra字段列出了一些附加信息，主要的取值包括：

1. **Using index**：表示查询使用了覆盖索引，查询结果只需要在索引中获取，而**不需要回表**读取表数据。

2. **Using where**：表示查询使用了WHERE子句过滤条件。如果同时出现Using where和Using index，则表示使用了覆盖索引，并且还有WHERE子句过滤条件。（使用到了**条件过滤**，会出现这个字段，并不局限于where查询）

   1. 当Using where和Using index同时出现的时候，此时Using where只是用来从索引中查找数据，此数据如果不是用来过滤，那么就是用来读取，以避免回表读取数据行。https://blog.csdn.net/qq_32382173/article/details/120773022

3. **Using index condition**：表示查询优化器选择使用了索引条件下推这个特性。

   1. 注： Index Condition Pushdown ([ICP](https://so.csdn.net/so/search?q=ICP&spm=1001.2101.3001.7020))，发生在存储引擎层发生的，不是server层；`using index conditoin` 意味着**查询列**的某一部分无法直接使用索引。https://blog.csdn.net/keehom/article/details/131097206

   > 1、**Using index** : 查询的列被索引覆盖，并且where筛选条件是索引的是前导列，Extra中为Using index
   >
   > 2、**Using index ，Using where**：查询的列被索引覆盖，数据都是先通过索引查询出来的索引覆盖数据，然后经过条件过滤得到最终数据；（与第4不同的是返回值的覆盖范围）
   >
   > 3、**Using where，Using index** ：查询的列被索引覆盖，但不能直接通过索引查到条件数据；
   >
   > 4、**Using index condition**：查询的列未被索引全覆盖，意味着查询列的某一部分无法直接使用索引，二次过滤；
   >
   > 原文链接：https://blog.csdn.net/keehom/article/details/131097206

4. Using temporary：表示MySQL需要创建一个临时表来存储查询结果，在排序、分组、连接等操作中常见。

5. Using filesort：表示MySQL需要对结果进行排序，但无法使用索引完成排序，需要将结果保存到临时文件并进行排序或排序缓冲区中进行排序，**所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序。**

6. Using join buffer：表示查询使用了连接缓存区，通常出现在大表关联查询中。

7. Impossible where：表示WHERE子句的条件不符合任何数据记录，导致查询返回空结果集。

8. Select tables optimized away：表示MySQL优化了查询，直接返回了预期的结果，而没有执行任何实际的读取表数据的操作。

9. Distinct：表示查询使用了DISTINCT去重操作。

10. Range checked for each record：表示MySQL在使用索引进行范围查询时，需要检查每一条记录是否符合查询条件。

11. Full text search：表示查询使用了全文索引进行全文搜索。

总之，Extra字段提供了部分SQL查询语句的执行计划和统计信息，用于优化SQL查询性能。

链接：https://javaguide.cn/database/mysql/mysql-query-execution-plan.html

---

表 `table tb(a, b, c), index(a), index(a,b)`，sql语句 `select * from tb where a > 123; `执行过程。

- `using index conditoin` 意味着**查询列**的某一部分无法直接使用索引。

> ```mysql
> explain select * from tb where a = 123; 			// key_len=5, NULL
> 
> explain select * from tb where a > 123; 			// key_len=5, using index condition
> 
> explain select * from tb where a > 123 and c = 100; // key_len=5, using index condition, using where
> 
> explain select a from tb where a = 123;				// key_len=5, using index
> 
> explain select * from tb where c = 100;				// key_len=NULL, using where
> 
> explain select a from tb where a > 123;				// key_len=5, using where, using index（使用索引a定位到第一个满足的位置，然后再从当前位置一直往后找到所有满足的索引）
> ```

#### 33、数据库多表查询之 where & INNER JOIN

在多表查询中，一些SQL开发人员更喜欢使用WHERE来做join，比如：

```SELECT a.ID, b.Name, b.Date FROM Customers a, Sales b WHERE a.ID = b.ID;```
缺点：在上面语句中，实际上是创建了两张表的笛卡尔积，所有可能的组合都会被创建出来。在笛卡尔连接中，在上面的例子中，如果有1000顾客和1000条销售记录，这个查询会先产生1000000个结果，然后通过正确的 ID过滤出1000条记录。 这是一种低效利用数据库资源，数据库多做100倍的工作。 在大型数据库中，笛卡尔连接是一个大问题，对两个大表的笛卡尔积会创建数10亿或万亿的记录。

为了避免创建笛卡尔积，应该使用INNER JOIN ：

```SELECT a.ID, b.Name, b.Date FROM Customers a INNER JOIN Sales b ON a.ID = b.ID;```

优点：如上面语句，使用inner join 这样数据库就只产生等于ID 的1000条目标结果。增加了查询效率。

有些数据库系统会识别出 WHERE连接并自动转换为 INNER JOIN。在这些数据库系统中，WHERE 连接与INNER JOIN 就没有性能差异。但是， INNER JOIN 是所有数据库都能识别的，因此DBA会建议在你的环境中使用它。

```
INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录。
LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。
RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。
```

————————————————
原文链接：https://blog.csdn.net/u013372487/article/details/52622491

#### 34、MySQL单表数据行数

- Mysql 的表数据是以页的形式存放的，页在磁盘中不一定是连续的。
- 页的空间是 16K, 并不是所有的空间都是用来存放数据的，会有一些固定的信息，如，页头，页尾，页码，校验码等等。
- 在 B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。
- 索引结构不会影响单表最大行数，**2kw** 也只是推荐值，超过了这个值可能会导致 B + 树层级更高，影响查询性能。

链接：http://my.oschina.net/u/4090830/blog/5559454

#### 35、EXIST 和 OR 性能对比

1、IN查询在内部表和外部表上都可以使用到索引；

2、EXISTS查询仅内部表上可以使用到索引，外表会全表扫描；当子查询结果集很大，而外部表较小的时候，EXISTS的Block Nested Loop(Block 嵌套循环)的作用开始显现，查询效率会优于IN；

3、当子查询结果集较小，而外部表很大的时候，EXISTS的Block嵌套循环优化效果不明显，IN 的外表索引优势占主要作用，此时IN的查询效率会优于EXISTS。

**子查询结果集越大用EXISTS，子查询结果集越小用IN。**

链接：https://baijiahao.baidu.com/s?id=1708410912062601477&wfr=spider&for=pc

#### 36、OR 是否会走索引

OR条件的两边都是同一个索引列的情况下，如果WHERE条件是主键，则可以使用索引；

OR条件的两边都是同一个索引列的情况下，如果WHERE条件不是主键，则是否使用索引取决于MySQL查询优化器的代价估算。

OR条件的两边是不同的索引列，是否使用索引取决于MySQL查询优化器的代价估算。如果能使用索引，MySQL会使用索引，如果代价太高，仍然会走全表索引；

如果多个OR条件中有其中一个条件没有索引，则必须进行全表索引（因为查询出条件1后，并不能确定条件2，也必须全表查询条件2）。
————————————————
原文链接：https://blog.csdn.net/yfm081616/article/details/115544251

#### 37、为什么redolog无法代替double write buffer？
redolog的设计之初，是“账本的作用”，是一种操作日志，用于MySQL异常崩溃恢复使用，是InnoDB引擎特有的日志，本质上是物理日志，记录的是 “ 在某个数据页上做了什么修改 ” ，但如果数据页本身已经发生了损坏，redolog来恢复已经损坏的数据块是无效的，数据块的本身已经损坏，再次重做依然是一个坏块。

所以此时需要一个数据块的副本来还原该损坏的数据块，再利用重做日志进行其他数据块的重做操作，这就是double write buffer的原因作用。

因此，double write buffer与redolog对于容灾场景，缺一不可。
————————————————
原文链接：https://blog.csdn.net/wtopps/article/details/131123894

#### SQL语句题

##### 1、查询每个班级第一名的总成绩及学生信息

students表

```
学生id		班级id		学生姓名
sid				cid			sname
```

grades表

```
学生id		课程			分数
sid			course			score
```

答案：

```sql
# 先求出每个学生的总成绩从高到低排序
select sid, sum(score) tscore
from grades
group by sid
order by tscore desc;

# 按班级分组，求出每个班级的最高成绩及其对应学生的信息
select students.sid, cid, sname, ts.tscore
from students
         inner join (
    select sid, sum(score) tscore
    from grades
    group by sid
    order by tscore desc
) as ts on students.sid = ts.sid
group by cid;

# 与上面语句等效
# 使用联合查询
select students.sid, cid, sname, ts.tscore
from students,
     (select sid, sum(score) tscore
      from grades
      group by sid
      order by tscore desc) ts
where students.sid = ts.sid
group by cid;
```

如果多一张班级表class

```
班级id		班级名称
cid				cname				
```

则答案为：

```mysql
# 查询每个班级第一名的总成绩及学生信息
select a.sid, a.cid, a.sname, a.tscore
from (
	select students.sid, cid, sname, ts.tscore
	from students
         	inner join (
    	select sid, sum(score) tscore
    	from grades
    	group by sid
    	order by tscore desc
	) as ts on students.sid = ts.sid
	group by cid
) as a inner join class on class.cid = a.cid;
```

https://blog.csdn.net/weixin_34617955/article/details/113236257

##### 2、SQL去除重复记录

你可以使用SQL语句中的DELETE和子查询来删除表中重复的记录。具体的步骤如下：

1. 创建一个临时表，存储要删除的重复记录的主键或唯一标识。
2. 使用子查询，在临时表中插入需要删除的重复记录的主键或唯一标识。
3. 使用DELETE语句，根据临时表中的主键或唯一标识，删除原始表中的重复记录。

下面是一个示例：

```sql
-- 步骤1：创建临时表
CREATE TABLE 临时表 AS
SELECT MIN(主键) AS 主键
FROM 表名
GROUP BY 列1, 列2, ...;

-- 步骤2：向临时表中插入需要删除的重复记录的主键
INSERT INTO 临时表
SELECT 主键
FROM 表名
GROUP BY 列1, 列2, ...
HAVING COUNT(*) > 1;

-- 步骤3：删除原始表中的重复记录
DELETE FROM 表名
WHERE 主键 IN (SELECT 主键 FROM 临时表);

-- 删除完成后可以删除临时表
DROP TABLE 临时表;
```

请将上述代码中的"表名"替换为你实际要操作的表的名称，"主键"替换为你表中的主键或唯一标识列，"列1, 列2, ..."替换为用于判断重复记录的列。这样可以根据指定的列来删除重复的记录。

----

**问题描述**

表中存在重复数据，导致唯一约束添加失败。清理重复数据保留其中一条

**解决方案：**

查看重复数据

1. 查询sql

```sql
select
	a.* 
from
	a,
	( select UserId, Code, MAX ( Id ) id from a group by UserId, Code having count ( * ) > 1 ) b 
where
	a.UserId= b.UserId
	and a.Code= b.Code
	and a.id <> b.id
```

2. 删除sql

```sql
delete
	a.* 
from
	a,
	( select UserId, Code, MAX ( Id ) id from a group by UserId, Code having count ( * ) > 1 ) b 
where
	a.UserId= b.UserId
	and a.Code= b.Code
	and a.id <> b.id
```

————————————————
原文链接：https://blog.csdn.net/kan_kongzhizhen/article/details/130624133

### Mybatis

#### 1、Mybatis中nameSpace的作用

namespace : 命名空间

在大型项目中，可能存在大量的[SQL语句](https://so.csdn.net/so/search?q=SQL语句&spm=1001.2101.3001.7020)，这时候为每个SQL语句起一个唯一的标识（ID）就变得并不容易了。为了解决这个问题，在MyBatis中，可以为每个映射文件起一个唯一的命名空间，这样定义在这个映射文件中的每个SQL语句就成了定义在这个命名空间中的一个ID。只要我们能够保证每个命名空间中这个ID是唯一的，即使在不同映射文件中的语句ID相同，也不会再产生冲突了。

​      namespace作用: 

       	1. namespace + id 生成key,值就是整个sql标签, namespace区分sql命令  sql命令的ID 不能重复
    	2. 使用代理时 根据namespace就是绑定了接口,生成代理类  key就是接口名称 userDao.class
原文链接：https://blog.csdn.net/weixin_42672802/article/details/122398603

#### 2、Mybatis分页插件的原理？

首先分页参数放到ThreadLocal中，拦截执行的sql，根据数据库类型添加对应的分页语句重写sql，例如：`(select * from table where a)` 转换为 `(select count(*) from table where a)` 和 `(select * from tablewhere a limit ,)` 计算出了`total`总条数、`pageNum`当前第几页、pageSize每页大小和当前页的数据，是否为首页，是否为尾页，总页数等。

#### 3、MyBatis的ResultType和ResultMap的区别？

ResultType：指定映射类型，只要查询的字段名和类型的属性名匹配可以自动映射。

ResultMap：自定义映射规则，当查询的字段名和映射类型的属性不匹配时可以通过ResultMap自定义映射规则，也可以实现一对多、一对一映射。

[Mybatis之批量更新数据](https://blog.csdn.net/carbuser_xl/article/details/127045359)

### Redis

#### 1、Redis 5种数据结构

Redis 共有 5 种基本数据结构：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。

这 5 种数据结构是直接提供给用户使用的，是数据的保存形式，其底层实现主要依赖这 8 种数据结构：简单动态字符串（SDS）、LinkedList（双向链表）、Hash Table（哈希表）、SkipList（跳跃表）、Intset（整数集合）、ZipList（压缩列表）、QuickList（快速列表）。

Redis 基本数据结构的底层数据结构实现如下：

| String | List                         | Hash          | Set          | Zset                       |
| :----- | :--------------------------- | :------------ | :----------- | :------------------------- |
| SDS    | LinkedList/ZipList/QuickList | Dict、ZipList | Dict、Intset | ZipList、（SkipList+Dict） |

Redis 3.2 之前，List 底层实现是 LinkedList 或者 ZipList。 Redis 3.2 之后，引入了 LinkedList 和 ZipList 的结合 QuickList，List 的底层实现变为 QuickList。

---

**String：**

- **需要存储常规数据的场景**

  - 举例 ：缓存 session、token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。

  - 相关命令 ： `SET`、`GET`。

- **需要计数的场景**

  - 举例 ：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。

  - 相关命令 ：`SET`、`GET`、 `INCR`、`DECR` 。

- **分布式锁**
  - 利用 `SETNX key value` 命令可以实现一个最简易的分布式锁（存在一些缺陷，通常不建议这样实现分布式锁）。

**List：**

- **信息流展示**

  - 举例 ：最新文章、最新动态。

  - 相关命令 ： `LPUSH`、`LRANGE`。

- **消息队列**
  - Redis List 数据结构可以用来做消息队列，只是功能过于简单且存在很多缺陷，不建议这样做。

​		相对来说，Redis 5.0 新增加的一个数据结构 `Stream` 更适合做消息队列一些，只是功能依然非常简陋。和专业的消息队列相比，还是有很多欠缺的地方比如消息丢失和堆积问题不好解决。

**Hash：**

- **对象数据存储场景**

  - 举例 ：用户信息、商品信息、文章信息、购物车信息。

  - 相关命令 ：`HSET` （设置单个字段的值）、`HMSET`（设置多个字段的值）、`HGET`（获取单个字段的值）、`HMGET`（获取多个字段的值）。

**Set：**

- **需要存放的数据不能重复的场景**

  - 举例：网站 UV 统计（数据量巨大的场景还是 `HyperLogLog`更适合一些）、文章点赞、动态点赞等场景。

  - 相关命令：`SCARD`（获取集合数量） 。

- **需要获取多个数据源交集、并集和差集的场景**

  - 举例 ：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集） 、订阅号推荐（差集+交集） 等场景。

  - 相关命令：`SINTER`（交集）、`SINTERSTORE` （交集）、`SUNION` （并集）、`SUNIONSTORE`（并集）、`SDIFF`（差集）、`SDIFFSTORE` （差集）。

- **需要随机获取数据源中的元素的场景**

  - 举例 ：抽奖系统、随机。

  - 相关命令：`SPOP`（随机获取集合中的元素并移除，适合不允许重复中奖的场景）、`SRANDMEMBER`（随机获取集合中的元素，适合允许重复中奖的场景）。

**Zset：**

- **需要随机获取数据源中的元素根据某个权重进行排序的场景**

  - 举例 ：各种**排行榜**比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等，第二个用途就是用作**延时队列**，score存储时间戳。

  - 相关命令 ：`ZRANGE` (从小到大排序) 、 `ZREVRANGE` （从大到小排序）、`ZREVRANK` (指定元素排名)。

------

著作权归所有 原文链接：https://javaguide.cn/database/redis/redis-data-structures-01.html

#### 2、跳表

**定义：**

1. 跳表，又叫做跳跃表、跳跃列表，在有序链表的基础上增加了“跳跃”的功能
2. 跳表在原来的有序链表上加上了多级索引，通过索引来快速查找；可以支持快速的删除、插入和查找操作。
3. 跳表实际上是一种增加了前向指针的链表，是一种随机化的数据结构
4. Redis中 的 SortedSet、LevelDB 中的 MemTable 都用到了跳表
5. 对比平衡树, 跳表的实现和维护会更加简单, 跳表的搜索、删除、添加的平均时间复杂度是 O(logn)

**数据结构图形：**

- 对于一个单链表来讲，即使链表中存储的数据是有序的，如果我们想要在其中查找某个数据，也只能从头开到尾的遍历，查询效率低，时间复杂度是O(n)。

<img src="https://img-blog.csdnimg.cn/20210430130749617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ4MDc4NQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 67%;" />

**跳表的搜索：**

>  跳表查找任意数据的时间复杂度为O(logn)

1. 从顶层链表的首元素开始，从左往右搜索，直至找到一个大于或等于目标的元素，或者到达当前层链表的尾部
2. 如果该元素等于目标元素，则表明该元素已被找到
3. 如果该元素大于目标元素或已到达链表的尾部，则退回到当前层的前一个元素，然后转入下一层进行搜索

**跳表的插入：**

> 跳表插入的时间复杂度为：O(logn)，支持高效的动态插入。

<img src="https://img-blog.csdnimg.cn/20210430132656662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ4MDc4NQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 80%;" />

**跳表的删除：**

> 跳表的删除操作时间复杂度为：O(logn)，支持动态的删除。

- 在跳表中删除某个结点时，如果这个结点在索引中也出现了，我们除了要删除原始链表中的结点，还要删除索引中的。因为单链表中的删除操作需要拿到删除结点的前驱结点，然后再通过指针操作完成删除。所以在查找要删除的结点的时候，一定要获取前驱结点（双向链表除外）。因此跳表的删除操作时间复杂度即为O(logn)。

**跳表索引动态更新：**

- 当我们不断地往跳表中插入数据时，我们如果不更新索引，就有可能出现某2个索引节点之间的数据非常多的情况，在极端情况下，跳表还会退化成单链表

<img src="https://img-blog.csdnimg.cn/20210430132951522.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ4MDc4NQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:67%;" />

> 跳表是通过随机函数来维护“平衡性”。

- 当我们在跳表中插入数据的时候，我们通过选择同时将这个数据插入到部分索引层中，如何选择索引层，可以通过一个随机函数来决定这个节点插入到哪几级索引中，比如随机生成了k，那么就将这个索引加入到，第一级到第k级索引中。

<img src="https://img-blog.csdnimg.cn/20210430134624560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ4MDc4NQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 80%;" />

**跳表的性质：**

1. 跳表由很多层结构组成，level是通过一定的概率随机产生的；
2. 每一层都是一个有序的链表，默认是升序 ；
3. 最底层(Level 1)的链表包含所有元素；
4. 如果一个元素出现在Level i 的链表中，则它在Level i 之下的链表也都会出现；
5. 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。

实现：

```java
import java.util.Random;

// 跳表中存储的是正整数，并且存储的数据是不重复的
public class SkipList {
	
	private static final int MAX_LEVEL = 16;    // 索引的最大层数
	private int levelCount = 1;   // 索引的层级数
	private Node head = new Node();    // 头结点（不存储元素，相当于 dummy）
	private Random random = new Random();
 
	// 查找操作
	public Node find(int value) {
		Node p = head;
		for(int i = levelCount - 1; i >= 0; --i){
			while(p.next[i] != null && p.next[i].data < value) {
				p = p.next[i];
			}
		}
		
		if(p.next[0] != null && p.next[0].data == value) {
			return p.next[0];    // 找到，则返回原始链表中的结点
		}else{
			return null;
		}
	}
	
	// 插入操作
	public void insert(int value) {
		int level = randomLevel(); // 随机得到需要插入到哪几层索引中(1~level)
		Node newNode = new Node();
		newNode.data = value;
		newNode.maxLevel = level;   // 通过随机函数改变索引层的结点布置
		Node update[] = new Node[level]; // 存储每层更新节点的前驱节点，即最后一个小于value的节点位置
		for(int i = 0; i < level; ++i) { // 初始都指向头节点
			update[i] = head;
		}
		
        Node p = head;
        for(int i = level - 1; i >= 0; --i) { // 寻找每一层新节点的前驱节点
        	while(p.next[i] != null && p.next[i].data < value){
        		p = p.next[i];
        	}
        	update[i] = p;
        }
        
        for(int i = 0; i < level; ++i) { // 再每一层中插入新节点
        	newNode.next[i] = update[i].next[i];
        	update[i].next[i] = newNode;
        }
        if(levelCount < level) {
        	levelCount = level;
        }
	}
	
	// 删除操作
	public void delete(int value) {
		Node[] update = new Node[levelCount];
		Node p = head;
		for(int i = levelCount - 1; i >= 0; --i) {
			while(p.next[i] != null && p.next[i].data < value) {
				p = p.next[i];
			}
			update[i] = p;
		}
		
		if(p.next[0] != null && p.next[0].data == value) {
			for(int i = levelCount - 1; i >= 0; --i){
				if(update[i].next[i] != null && update[i].next[i].data == value) {
					update[i].next[i] = update[i].next[i].next[i];
				}
			}
		}
	}
	
	// 随机函数
	private int randomLevel() {
		int level = 1;
		for(int i = 1; i < MAX_LEVEL; ++i) {
			if(random.nextInt() % 2 == 1) {
				level++;
			}
		}
		
		return level;
	}
	
	// Node内部类
	public static class Node {
		private int data = -1; // 节点元素值
		private Node next[] = new Node[MAX_LEVEL];
		private int maxLevel = 0; // 节点的最大层数
		
		// 重写toString方法
		@Override
		public String toString() {
			StringBuilder builder = new StringBuilder();
			builder.append("{data:");
			builder.append(data);
			builder.append("; leves: ");
			builder.append(maxLevel);
			builder.append(" }");
			return builder.toString();
		}
	}
	
	// 显示跳表中的结点
	public void display() {
		Node p = head;
		while(p.next[0] != null){
			System.out.println(p.next[0] + " ");
			p = p.next[0];
		}
		System.out.println();
	}
}
```

**总结跳表：**

- 跳表使用的是空间换时间的思想，通过构建多级索引来提高查询效率，实现基于链表的“二分查找”，跳表是一种动态的数据结构，支持快速的查找、插入和删除操作，时间复杂度是 O(logn)。
- 跳表的空间复杂度是 O(n)，不过跳表可以通过改变索引策略，动态的平衡执行效率和内存消耗。
  ————————————————
  原文链接：https://blog.csdn.net/weixin_45480785/article/details/116293416

#### 3、Redis Zset的实现为什么用跳表，而不用平衡树？

- 从内存占用上来比较，跳表比平衡树更灵活一些。平衡树每个节点包含 2 个指针(分别指向左右子树)，而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。
- 在做范围查找的时候，跳表比平衡树操作要简单。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。
- 从算法实现难度上来比较，跳表比平衡树要简单得多。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。
  ————————————————
  原文链接：https://blog.csdn.net/JaJian_/article/details/127380405

#### 4、如何解决BigKey问题？

要解决Big Key问题，无非就是减小key对应的value值的大小，也就是对于String数据结构的话，减少存储的字符串的长度；对于List、Hash、Set、ZSet数据结构则是减少集合中元素的个数。

**1、对大Key进行拆分**
将一个Big Key拆分为多个key-value这样的小Key，并确保每个key的成员数量或者大小在合理范围内，然后再进行存储，通过get不同的key或者使用mget批量获取。

**2、对大Key进行清理**
对Redis中的大Key进行清理，从Redis中删除此类数据。Redis自4.0起提供了UNLINK命令，该命令能够以非阻塞的方式缓慢逐步的清理传入的Key，通过UNLINK，你可以安全的删除大Key甚至特大Key。

**3、监控Redis的内存、网络带宽、超时等指标**
通过监控系统并设置合理的Redis内存报警阈值来提醒我们此时可能有大Key正在产生，如：Redis内存使用率超过70%，Redis内存1小时内增长率超过20%等。

**4、定期清理失效数据**
如果某个Key有业务不断以增量方式写入大量的数据，并且忽略了其时效性，这样会导致大量的失效数据堆积。可以通过定时任务的方式，对失效数据进行清理。

**5、压缩value**
使用序列化、压缩算法将key的大小控制在合理范围内，但是需要注意序列化、反序列化都会带来一定的消耗。如果压缩后，value还是很大，那么可以进一步对key进行拆分。
————————————————
原文链接：https://blog.csdn.net/Weixiaohuai/article/details/125391957

#### 5、如何防止优惠券重复刷单？

对于重复请求，要考虑接口幂等和接口防重。

大家可以看下之前我写的这篇文章哈：[聊聊幂等设计](https://link.juejin.cn/?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg3NzU5NTIwNg%3D%3D%26mid%3D2247497427%26idx%3D1%26sn%3D2ed160c9917ad989eee1ac60d6122855%26chksm%3Dcf2229faf855a0ecf5eb34c7335acdf6420426490ee99fc2b602d54ff4ffcecfdab24eeab0a3%26token%3D529683793%26lang%3Dzh_CN%23rd)

防刷的话，可以限流以及加入黑名单处理。

- 为了防止某个用户请求优惠券过于频繁，我们可以对同一用户限流。
- 为了防止黄牛等模拟几个用户请求，我们可以对某个IP进行限流。

- 为了防止有人使用代理，每次请求都更换IP请求，我们可以对接口进行限流。

————————————————
原文链接：https://blog.csdn.net/m0_49496327/article/details/124062701

#### 6、缓存一致性问题？

- 看Redis原理篇*****

​	https://blog.csdn.net/lanleihhh/article/details/127683521

1、先删除缓存，再更新数据库

如果删除了缓存更新数据库的操作没有成功，此时查询数据的请求会把旧数据存储到缓存中。

2、先更新数据库，再删除缓存。

- 如果更新了数据库，删除缓存的操作失败了，此时查询数据的请求查到的数据仍然是旧数据。

- 线程A读取商品数据，刚好缓存失效了，去查询数据库数据，刚要执行放入redis缓存时，CPU发生上下文切换，线程A暂时得不到执行，此时线程B修改数据，执行update商品操作，然后删除缓存，线程A执行时，将之前查询到的旧的数据存到redis缓存中，此时就会出现redis和数据库的数据不一致的情况。

[为什么是删除缓存而不是更新缓存？](https://blog.csdn.net/oldboy1999/article/details/126180530)

3、延迟双删，先删除缓存、再更新数据库，再延迟一定的时间去删除缓存。

为什么要两次删除缓存，因为有可能第一次删除缓存后其它查询请求将旧数据存储到了缓存。

为什么要延迟一定的时间去删除缓存，为了给mysql主向从同步的时间，如果立即删除缓存很可能其它请求读到的数据还是旧数据。

延迟的时间不好确定，延迟双删仍然可能导致脏数据。

所以结论：以上方案当存在高并发时都无法解决数据库和缓存强一致性的问题。

如何做缓存一致性？

需要根据需求来定：

1、实现强一致性 需要使用分布式锁控制，修改数据和向缓存存储数据使用同一个分布式锁。（数据修改的同时更新缓存-同一个事务）

2、实现最终一致性，缓存数据要加过期时间，即使出现数据不致性当过期时间一到缓存失效又会从数据库查询最新的数据存入缓存。

3、对于实时性要求强的，要实现数据强一致性要尽量避免使用缓存，可以直接操作数据库。

使用工具对数据进行同步方案如下：

1、使用任务表加任务调度的方案进行同步。

2、使用Canal基于MySQL的binlog进行同步。

#### 7、Redis缓存预热

Redis缓存会面临冷启动问题：

**冷启动**：服务刚刚启动时，Redis中并没有缓存，如果所有商品数据都在第一次查询时添加缓存，可能会给数据库带来较大压力。

**缓存预热**：在实际开发中，我们可以利用大数据统计用户访问的热点数据，在项目启动时将这些热点数据提前查询并保存到Redis中。

#### 8、Redis内存碎片

**什么是内存碎片？**

可以将内存碎片简单地理解为那些不可用的空闲内存。

**为什么会有内存碎片？**

1、Redis 存储存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。

2、频繁修改 Redis 中的数据也会产生内存碎片。

**如何查看内存碎片？**

使用 `info memory` 命令即可查看 Redis 内存相关的信息。https://redis.io/commands/INFO

**如何清理内存碎片？**

1、Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。

直接通过 `config set` 命令将 `activedefrag` 配置项设置为 `yes` 即可。

```sh
config set activedefrag yes
```

2、重启节点可以做到内存碎片重新整理。如果你采用的是高可用架构的 Redis 集群的话，你可以将碎片率过高的主节点转换为从节点，以便进行安全重启。

#### 9、Sentinel 哨兵 - 脑裂处理方案

哨兵模式的 redis 集群，假如原来只有一个主服务，经过故障转移后，产生多个主服务，这样脑裂现象出现了。通过合理部署配置 sentinel/master，可以降低脑裂问题出现的概率。

**1. 原理**

**1.1. 概述**

哨兵模式的 redis 集群有三种角色：sentinel/master/slave，它们通过 tcp 链接，相互建立联系。

sentinel 作为高可用集群管理者，它的功能主要是：检查故障，发现故障，故障转移。

**1.2. 故障转移流程**

1. 在 redis 集群中，当 sentinel 检测到 master 出现故障，那么 sentinel 需要对集群进行故障转移。
2. 当一个 sentinel 发现 master 下线，它会将下线的 master 确认为**主观下线**。
3. 当“法定个数”（quorum）sentinel 已经发现该 master 节点下线，那么 sentinel 会将其确认为**客观下线**。
4. 多个 sentinel 根据一定的逻辑，选举出一个 sentinel 作为 leader，由它去进行故障转移，将原来连接已客观下线 master 最优的一个 slave 提升为新 master 角色。旧 master 如果重新激活，它将被降级为 slave。

**1.3. 脑裂场景**

我们看看下面的部署：两个机器，分别部署了 redis 的三个角色。

- 如果将集群部署在两个机器上（如下图）。
- sentinel 配置 `quorum = 1`，也就是一个 sentinel 发现故障，也可以选举自己为 leader，进行故障转移。

| 节点 | 描述                         |
| :--: | :--------------------------- |
|  M   | redis 主服务 master          |
|  R   | redis 副本 replication/slave |
|  S   | redis 哨兵 sentinel          |
|  C   | 链接 redis 客户端            |

```
+----+         +----+ 
| M1 |---------| R1 | 
| S1 |         | S2 | 
+----+         +----+ 
```

- 因为某种原因，两个机器断开链接，S2 将同机器的 R1 提升角色为 master，这样集群里，出现了两个 master 同时工作 —— 脑裂出现了。不同的 client 链接到不同的 redis 进行读写，那么两台机器就出现了 redis 数据不一致的现象。

```
+----+           +------+ 
| M1 |----//-----| [M1] | 
| S1 |           |  S2  | 
+----+           +------+ 
```

**2. 解决方案**

通过合理部署配置 sentinel/master，降低脑裂出现概率。

**2.1. sentienl 配置**

合理部署 sentinel 的节点个数，以及配置 sentinel 选举的法定人数。

1. sentinel 节点个数最好 >= 3。
2. sentinel 节点个数最好是基数。
3. sentinel 的选举法定人数设置为 (n/2 + 1)。

- 配置

```yaml
sentinel.conf
sentinel monitor <master-name> <ip> <redis-port> <quorum> 
```

- quorum

  <quorum> 是`法定人数`。作用：多个 sentinel 进行相互选举，有超过`法定人数`的 sentinel 选举某个 sentinel 为 leader，那么他就成为 leader， leader 负责故障转移。这个法定人数，可以配置，一般是 sentinel 个数一半以上 (n/2 + 1) 比较合理。

**2.2 Redis 的 master 配置**

通过修改 redis 配置 [redis.conf](https://github.com/antirez/redis/blob/unstable/redis.conf)，检查 master 节点与其它副本的联系。当 master 发现它的副本下线或者通信超时的总数量小于阈值时，那么禁止 master 进行写数据。

> 但是这个方案也不是完美的，`min-slaves-to-write` 依赖于副本的链接个数，如果 slave 个数设置不合理，那么集群很难故障转移成功。

**3. 小结**

- redis 脑裂主要表现为：同一个 redis 集群，原来的 master，经过故障转移后，出现多个 master。
- 解决方案主要通过 sentinel 哨兵的配置和 redis 的配置去解决问题。
- 上述方案也是有不足的地方，例如 redis 配置限制可能会受到副本个数的影响，所以具体设置，要看具体的业务场景。主要是怎么通过比较小的代价去解决问题，或者降低出现问题的概率。
- redis 虽然已经发布了 gossip 协议的无中心集群，sentinel 哨兵模式还是比较常用的，我们不建议直接使用 sentinel，可以考虑使用 codis。

链接：https://wenfh2020.com/2019/12/27/redis-split-brain/

#### 10、Redis Cluster 扩容缩容期间可以提供服务吗?

> 类似的问题:
> 如果客户端访问的 key所属的槽正在迁移怎么办?
> 如何确定给定key的应该分布到哪个哈希槽中?

**Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽**

为了保证 Redis Cluster 在扩容和缩容期间依然能够对外正常提供服务，Redis Cluster 提供了重定向机制，两种不同的类型:

- ASK 重定向

 - MOVED 重定向

从客户端的角度来看，ASK 重定向是下面这样的:

1. 客户端发送请求命令，如果请求的 key 对应的哈希槽还在当前节点的话，就直接响应客户端的请求
2. 如果客户端请求的 key 对应的哈希槽当前正在迁移至新的节点，就会返回 ASK 重定向错误，告知客户端要将请求发送到哈希槽被迁移到的目标节点。
3. 客户端收到 -ASK 重定向错误后，将会临时 (一次性)重定向，自动向目标节点发送一条 ASKING3 命令。也就是说，接收到 ASKING 命令的节点会强制执行一次请求，下次再来需要重新提前发送ASKING 命令.
4. 客户端发送真正的请求命令
5. ASK 重定向并不会同步更新客户端缓存的哈希槽分配信息，也就是说，客户端对正在迁移的相同哈希槽的请求依然会发送到原节点而不是目标节点。

<img src="asset\Redis哈希槽迁移.png" alt="image-20230218192534337" style="zoom:80%;" />

如果客户端请求的 key 对应的哈希槽应该迁移完成的话，就会返回-MOVED 重定向错误，告知客户端当前哈希槽是由哪个节点负责，客户端向目标节点发送请求并更新缓存的哈希槽分配信息。

#### 11、Redis 如何解决集群情况下分布式锁的可靠性？

为了避免单点故障，生产环境下的 Redis 服务通常是集群化部署的。

Redis 集群下，上面介绍到的分布式锁的实现会存在一些问题。由于 Redis 集群数据同步到各个节点时是异步的，如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。

![img](asset\redis-master-slave-distributed-lock.ccc5be73.png)

针对这个问题，Redis 之父 antirez 设计了 [Redlock 算法open in new window](https://redis.io/topics/distlock) 来解决。

Redlock 算法的思想是让**客户端向 Redis 集群中的多个独立的 Redis 实例依次请求申请加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。**

即使部分 Redis 节点出现问题，只要保证 Redis 集群中有半数以上的 Redis 节点可用，分布式锁服务就是正常的。

**Redlock 是直接操作 Redis 节点的**，并不是通过 Redis 集群操作的，这样才可以避免 Redis 集群主从切换导致的锁丢失问题。

Redlock 实现比较复杂，性能比较差，发生时钟变迁的情况下还存在安全性隐患。《数据密集型应用系统设计》一书的作者 Martin Kleppmann 曾经专门发文（[How to do distributed locking - Martin Kleppmann - 2016open in new window](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)）怼过 Redlock，他认为这是一个很差的分布式锁实现。感兴趣的朋友可以看看[Redis 锁从面试连环炮聊到神仙打架open in new window](https://mp.weixin.qq.com/s?__biz=Mzg3NjU3NTkwMQ==&mid=2247505097&idx=1&sn=5c03cb769c4458350f4d4a321ad51f5a&source=41#wechat_redirect)这篇文章，有详细介绍到 antirez 和 Martin Kleppmann 关于 Redlock 的激烈辩论。

实际项目中不建议使用 Redlock 算法，成本和收益不成正比。

如果不是非要实现绝对可靠的分布式锁的话，其实单机版 Redis 就完全够了，实现简单，性能也非常高。如果你必须要实现一个绝对可靠的分布式锁的话，可以基于 Zookeeper 来做，只是性能会差一些。

------

著作权归所有 原文链接：https://javaguide.cn/distributed-system/distributed-lock.html

#### 12、Redis线程模型

Redis 内部使用**文件事件处理器** file event handler ，这个文件事件处理器是**单线程的**，所以Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket ，根据 socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

1. 多个 socket 。

2. IO 多路复用程序。

3. 文件事件分派器。

4. 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）。

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

![image-20230318153007369](asset\Redis通信模型.png)

1. 客户端 Socket01 向 Redis 的 Server Socket 请求建立连接，此时 Server Socket 会产生一个AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 Socket01，并将该 Socket01 的 AE_READABLE 事件与命令请求处理器关联。

2. 假设此时客户端发送了一个 set key value 请求，此时 Redis 中的 Socket01 会产生AE_READABLE 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 Socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 Socket01 的 set key value 并在自己内存中完成 set key value 的设置。操作完成后，它会将 Socket01 的 AE_WRITABLE 事件与令回复处理器关联。

3. 如果此时客户端准备好接收返回结果了，那么 Redis 中的 Socket01 会产生一个AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 Socket01 输入本次操作的一个结果，比如 ok ，之后解除 Socket01 的AE_WRITABLE 事件与命令回复处理器的关联。

#### 13、Redis实现消息队列

**基于List结构模拟消息队列**

消息队列（Message Queue），字面意思就是存放消息的队列。而Redis的list数据结构是一个双向链表，很容易模拟出队列效果。

队列是入口和出口不在一边，因此我们可以利用：LPUSH 结合 RPOP、或者 RPUSH 结合 LPOP来实现。
不过要注意的是，当队列中没有消息时RPOP或LPOP操作会返回null，并不像JVM的阻塞队列那样会阻塞并等待消息。因此这里应该使用BRPOP或者BLPOP来实现阻塞效果。

![1653575176451](asset\list消息队列.png)

基于List的消息队列有哪些优缺点？
优点：

* 利用Redis存储，不受限于JVM内存上限
* 基于Redis的持久化机制，数据安全性有保证
* 可以满足消息有序性

缺点：

* 无法避免消息丢失
* 只支持单消费者



**基于PubSub的消息队列**

PubSub（发布订阅）是Redis2.0版本引入的消息传递模型。顾名思义，消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有订阅者都能收到相关消息。

 SUBSCRIBE channel [channel] ：订阅一个或多个频道
 PUBLISH channel msg ：向一个频道发送消息
 PSUBSCRIBE pattern[pattern] ：订阅与pattern格式匹配的所有频道

![1653575506373](asset\pubsub消息队列.png)

基于PubSub的消息队列有哪些优缺点？
优点：

* 采用发布订阅模型，支持多生产、多消费

缺点：

* 不支持数据持久化
* 无法避免消息丢失
* 消息堆积有上限，超出时数据丢失



**基于Stream的消息队列**

Stream 是 Redis 5.0 引入的一种新数据类型，可以实现一个功能非常完善的消息队列。

发送消息的命令：

![1653577301737](D:/BaiduNetdiskDownload/黑马/Redis/02-实战篇/讲义/Redis实战篇.assets/1653577301737.png)

例如：

![1653577349691](D:/BaiduNetdiskDownload/黑马/Redis/02-实战篇/讲义/Redis实战篇.assets/1653577349691.png)

读取消息的方式之一：XREAD

![1653577445413](D:/BaiduNetdiskDownload/黑马/Redis/02-实战篇/讲义/Redis实战篇.assets/1653577445413.png)

例如，使用XREAD读取第一个消息：

![1653577643629](D:/BaiduNetdiskDownload/黑马/Redis/02-实战篇/讲义/Redis实战篇.assets/1653577643629.png)

XREAD阻塞方式，读取最新的消息：

![1653577659166](D:/BaiduNetdiskDownload/黑马/Redis/02-实战篇/讲义/Redis实战篇.assets/1653577659166.png)

在业务开发中，我们可以循环的调用XREAD阻塞方式来查询最新消息，从而实现持续监听队列的效果，伪代码如下

![1653577689129](D:/BaiduNetdiskDownload/黑马/Redis/02-实战篇/讲义/Redis实战篇.assets/1653577689129.png)

注意：当我们指定起始ID为$时，代表读取最新的消息，如果我们处理一条消息的过程中，又有超过1条以上的消息到达队列，则下次获取时也只能获取到最新的一条，会出现漏读消息的问题

STREAM类型消息队列的XREAD命令特点：

* 消息可回溯
* 一个消息可以被多个消费者读取
* 可以阻塞读取
* 有消息漏读的风险

列的XREADGROUP命令特点：

* 消息可回溯
* 可以多消费者争抢消息，加快消费速度
* 可以阻塞读取
* 没有消息漏读的风险
* 有消息确认机制，保证消息至少被消费一次

最后我们来个小对比

<img src="asset\Redis实现消息队列对比图.png" alt="1653578560691" style="zoom:80%;" />

#### 14、Redis实现延迟队列

使用 `sortedset` ，拿时间戳作为 `score` ，消息内容作为 `key` 调用 `zadd` 来生产消息，消费者用 `zrangebyscore` 指令获取 `N` 秒之前的数据轮询进行处理。

#### 15、Redis Cluster下客户端如何进行访问？

客户端连接 Redis Cluster 中任意一个 master 节点即可访问 Redis Cluster 的数据，当客户端发送命令请求的时候，需要先根据 key 通过上面的计算公示找到的对应的哈希槽，然后再查询哈希槽和节点的映射关系，即可找到目标节点。

<img src="asset\Redis分片集群1.png" alt="image-20230408152205402" style="zoom:80%;" />

如果哈希槽确实是当前节点负责，那就直接响应客户端的请求返回结果，如果不由当前节点负责，就会返回 -MOVED 重定向错误，告知客户端当前哈希槽是由哪个节点负责，客户端向目标节点发送请求并更新缓存的哈希槽分配信息。

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230408152301764.png" alt="image-20230408152301764" style="zoom:80%;" />

#### 16、Redis Cluster 扩缩容

**Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽**

为了保证 Redis Cluster 在扩容和缩容期间依然能够对外正常提供服务，Redis Cluster 提供了重定向机制，两种不同的类型:

- **ASK 重定向**：可以看做是临时重定向，后续查询仍然发送到旧节点。
- **MOVED 重定向**：可以看做是永久重定向，后续查询发送到新节点。

客户端向指定节点发送请求命令，从客户端的角度来看，ASK 重定向是下面这样的:

1. 如果请求的 key 对应的哈希槽还在当前节点的话，就直接响应客户端的请求。

2. 如果请求的 key 对应的哈希槽在迁移过程中，但是请求的 key 还未迁移走的话，说明当前节点任然可以处理当前请求，同样可以直接响应客户端的请求。
3. 如果客户端请求的 key 对应的哈希槽当前正在迁移至新的节点且请求的 key 已经被迁移走的话，就会返回 -ASK 重定向错误，告知客户端要将请求发送到哈希槽被迁移到的目标节点。 -ASK 重定向错误信息中包含请求 key 迁移到的新节点的信息。
4. 客户端收到 -ASK 重定向错误后，将会临时 (一次性)重定向，自动向新节点发送一条 ASKING 命令。也就是说，接收到 ASKING 命令的节点会强制执行一次请求，下次再来需要重新提前发送ASKING 命令。
5. 新节点在收到 ASKING 命今后可能会返回重试错误(TRYAGAIN)，因为可能存在当前请求的 key 还在导入中但未导入完成的情况。
6. 客户端发送真正需要请求的命令。
7. ASK 重定向并不会同步更新客户端缓存的哈希槽分配信息，也就是说，客户端对正在迁移的相同哈希槽的请求依然会发送到旧节点而不是新节点。

<img src="asset\哈希槽迁移.png" alt="image-20230408162254052" style="zoom:80%;" />

如果客户端请求的 key 对应的哈希槽已经迁移完成的话，就会返 -MOVED 重定向错误，告知客户端当前哈希槽是由哪人节点负责，客户端向新节点发送请求并更新缓存的哈希槽分配信息，后续查询将被发送到新节点。

#### 17、布隆过滤器

链接：https://blog.csdn.net/qq_55624813/article/details/121316520

#### 18、Redis为什么采用单线程？

Redis为什么采用单线程模式，主要是因为Redis大部分操作是基于内存执行的，I/O操作时间相对较短，而Redis采用了非阻塞的I/O模型，能够充分利用操作系统提供的机制以达到高并发的目的。此外，Redis采用了单线程模式保证了所有的操作都是原子性的，并且避免了多线程并发带来的线程安全问题。虽然Redis是单线程的，但其采用的是事件轮询机制，能够同时处理多个客户端请求，实现高并发。

#### 19、Redis分布式锁

[Redis实战篇.md](D:\BaiduNetdiskDownload\黑马\Redis\02-实战篇\讲义\Redis实战篇.md)

链接：https://javaguide.cn/distributed-system/distributed-lock.html

### Elasticsearch

#### 1、ES和MySQL数据同步

我们可以将同步类型分为 全量同步和增量同步

全量同步即建好 Elasticsearch 索引后一次性导入 MySQL 所有数据。全量同步有很多现成的工具可以用比如 gomysql-elasticsearch、 Datax.

另外，除了插件之外，像我们比较熟悉的 Canal 除了支持 binlog 实时增量同步 数据库之外也支持全量同步

增量同步即对 MySQL 中新增，修改，删除的数据进行同步

- **同步双写**：修改数据时同步到 Elasticsearch。这种方式性能较差、存在丢数据风险且会耦合大量数据同步代码，一般不会使用。

- **异步双写**：修改数据时，使用 MQ 异步写入 Elasticsearch 提高效率。这种方式引入了新的组件和服务，增加了系统整体复杂性。

- **定时器**：定时同步数据到 Elasticsearch。这种方式时效性差，通常用于数据实时性不高的场景

- **binlog 同步组件Canal**(推荐)： 使用 Canal 可以做到业务代码完全解耦，API 完全解，零代码实现准实时同步,Canal 通过解析 MySQL 的 binlog 日志文件进行数据同步。

#### 2、Canal 增量数据同步 Elasticsearch 的原理了解吗?
这个在 Canal 官方文档中有详细介绍到，原理非常简单:

1. Canal 模拟 MySQL Slave 节点与 MySQL Master节点的交互协议，把自己伪装成一个 MySQL Slave 节点，向 MySQL Master 节点请求 binlog;
2. MySQL Master 节点接收到请求之后，根据偏移量将新的 binlog 发送给 MysQL Slave 节点；
3. Canal 接收到 binlog 之后，就可以对这部分日志进行解析，获取主库的结构及数据变更。

<img src="asset\Canal数据同步.png" alt="image-20230218214930948" style="zoom:80%;" />

#### 3、MongoDB和ES的区别是什么？

MongoDB和Elasticsearch（简称ES）是两种不同类型的数据库，它们在数据存储和搜索领域具有不同的特点和用途。

1. 数据存储模型：
   - MongoDB是一种面向文档的NoSQL数据库，以BSON（二进制JSON）格式存储数据。它使用集合（Collections）组织文档（Documents），每个文档是一个自包含的单元。
   - Elasticsearch是一个实时分布式搜索和分析引擎，以倒排索引为基础存储数据。它将数据划分为索引（Indexes），每个索引包含多个文档类型（Document Types），每个文档类型包含多个文档。

2. 查询和搜索功能：
   - MongoDB支持丰富的查询操作，包括精确匹配、范围查询、正则表达式、聚合等。它还提供了全文本搜索的功能，但相比于ES，在搜索和分析方面的功能较弱。
   - Elasticsearch专注于搜索和分析功能，提供了灵活的全文本搜索、模糊匹配、过滤、聚合等强大的搜索和分析工具。

3. 分布式和扩展性：
   - MongoDB可以以分片（Sharding）的方式进行水平扩展，将数据分布在多个服务器上。它提供了读写分离和副本集（Replica Set）的功能用于高可用性。
   - Elasticsearch是一个分布式系统，可以简单地通过添加节点来扩展其容量和性能。它使用主分片和副本分片的方式实现数据的分布和冗余。

4. 数据一致性：
   - MongoDB采用基于多数派（Majority-based）的一致性模型，可以在读写操作之间提供强一致性。
   - Elasticsearch采用近实时（Near Real-Time）的一致性模型，写操作会有一定的延迟，但可以提供更高的吞吐量。

5. 适用场景：
   - MongoDB适用于需要灵活数据模型和复杂查询的应用场景，如用户配置、日志存储等。
   - Elasticsearch适用于全文本搜索、日志分析、大数据分析等需要快速查询和实时分析的场景。

需要注意的是，MongoDB和Elasticsearch在某些方面也有交集，例如两者都支持复制、分片和数据冗余。选择合适的数据库取决于你的具体需求和应用场景。

这里提供了MongoDB和Elasticsearch的一些主要区别，希望对你有所帮助。如果还有其他问题，请继续提问。

---

**技术选型：**

选择合适的数据库是一个需要考虑多个因素的决策过程。下面是一个技术选型的步骤，可以帮助你在MongoDB和Elasticsearch之间进行选择：

1. 确定需求和使用场景：首先，明确你的应用需求和使用场景。考虑你需要存储的数据结构、查询和搜索功能的要求，以及预计的数据规模和处理负载。

2. 数据模型和查询功能：评估你的应用是否需要**灵活的数据模型和复杂的查询**操作。如果你的应用需要更复杂的查询能力和支持范围查询、聚合等功能，那么MongoDB可能是更好的选择。如果**全文本搜索和高级分析**是主要需求，那么Elasticsearch可能更适合。

3. 性能和扩展性：考虑你的应用对性能和扩展性的要求。如果你需要水平扩展和高吞吐量的读写操作，那么MongoDB的分片和副本集功能可以提供良好的扩展性。如果你需要快速的搜索和实时分析，并且能够通过添加节点来扩展容量和性能，那么Elasticsearch可能更适合。

4. 数据一致性和可靠性：考虑你对数据一致性和可靠性的要求。MongoDB提供基于多数派的一致性模型，可以在读写操作之间提供强一致性。Elasticsearch采用近实时的模型，写操作可能存在一定延迟，但可以提供更高的吞吐量。

5. 生态系统和社区支持：考虑数据库的生态系统和社区支持。MongoDB和Elasticsearch都有活跃的开源社区，并提供了丰富的文档、教程和示例代码。你可以评估它们的生态系统和社区资源来确定哪个数据库更适合你的需求。

6. 团队技术能力：评估你的团队的技术能力和经验。如果你的团队已经熟悉了某个数据库，那么选择该数据库可能会减少学习成本和开发时间。

最后，根据以上因素综合评估和权衡，选择最适合你需求的数据库。

请注意，在做出决策之前，你可以通过进行原型验证或进行基准测试来评估特定场景下的性能和功能。

希望这些步骤对你进行MongoDB和Elasticsearch的技术选型有所帮助。如有需要，可以继续提问。

#### 4、MySQL和MongoDB的区别？

MySQL和MongoDB是两种不同类型的数据库，它们在数据存储和查询模式、数据一致性、扩展性等方面有一些区别。以下是MySQL和MongoDB的几个主要区别：

1. 数据存储模型：
   - MySQL是一种关系型数据库（RDBMS），使用表格（Tables）和行（Rows）的结构来存储数据。它使用结构化查询语言（SQL）进行数据操作。
   - MongoDB是一种面向文档的NoSQL数据库，以BSON（二进制JSON）格式存储数据。它使用集合（Collections）和文档（Documents）的结构来存储数据。

2. 数据模式和灵活性：
   - MySQL需要事先定义表格的结构和字段类型，遵循预定的数据模式。数据插入和更新需要符合表格的结构。
   - MongoDB具有动态的数据模型，不需要预先定义字段结构。文档可以包含不同的字段，并且可以根据需要动态添加或删除字段。

3. 查询语言和功能：
   - MySQL使用结构化查询语言（SQL）进行数据查询和操作。SQL提供了强大的查询功能和对关系型数据的处理能力。
   - MongoDB使用基于文档结构的查询语言，可以使用JSON样式的查询语法。它提供了丰富的查询操作，包括精确匹配、范围查询、正则表达式、聚合等。

4. 扩展性和性能：
   - MySQL可以通过垂直扩展（Vertical Scaling）增加服务器的处理能力，例如增加内存、CPU等资源。也可以通过主从复制（Replication）实现读写分离和提高可用性。
   - MongoDB可以通过水平扩展（Horizontal Scaling）增加服务器的容量和性能，通过分片（Sharding）将数据分布在多个服务器上。它也支持副本集（Replica Set）提供高可用性和故障恢复。

5. 数据一致性：
   - MySQL采用ACID（原子性、一致性、隔离性、持久性）事务模型，可以提供强一致性和数据完整性的保证。
   - MongoDB采用BASE（基本可用、软状态、最终一致性）模型，注重可用性和性能，并在数据一致性上提供了更灵活的选择。

需要根据具体的应用需求和场景来选择适合的数据库。如果你的应用需要关系型数据模型、事务支持和强大的SQL查询功能，那么MySQL可能是更好的选择。如果你的应用对数据模式要求不确定或需要更灵活的数据模型、高性能的读写操作和复杂的查询功能，那么MongoDB可能更适合。

希望对你理解MySQL和MongoDB的区别有所帮助。如果有任何进一步的问题，请随时提问。

[MongoDB和MySQL技术选型](https://blog.csdn.net/liao0801_123/article/details/89373494)

----

**技术选型：**

进行MySQL和MongoDB的技术选型时，可以按照以下步骤进行评估和比较：

1. 明确应用需求和使用场景：首先，明确你的应用需求和使用场景。考虑数据结构和模型、查询需求、扩展性要求、性能需求、一致性要求等。

2. 数据模型和查询功能：评估你的应用对数据模型和查询功能的要求。**MySQL适用于结构化数据和复杂的关系查询**。**MongoDB适用于灵活的文档模型和面向文档的查询操作**。

3. 性能和扩展性：考虑你的应用对性能和扩展性的要求。MySQL在大规模数据处理和高并发读写操作上表现良好。MongoDB适用于大量数据的快速读写和水平扩展。

4. 事务和一致性：如果你的应用需要强一致性和事务支持，那么MySQL是更好的选择。MongoDB提供的一致性模型相对较灵活，但在某些情况下可能不适合需要严格一致性的场景。

5. 生态系统和社区支持：评估数据库的生态系统和社区支持。MySQL和MongoDB都有庞大的用户社区和丰富的文档资源，可以提供技术支持和问题解决。

6. 团队技术能力：考虑你的团队对MySQL和MongoDB的熟悉程度。如果团队已经熟悉某个数据库，那么选择该数据库可能会减少开发成本和学习曲线。

7. 安全性和可靠性：评估数据库的安全性和可靠性特性，包括访问控制、备份和恢复机制、故障转移等。确保选择的数据库符合应用的安全要求。

8. 成本因素：综合考虑MySQL和MongoDB的成本因素，包括授权费用、硬件需求、运维成本等。根据你的预算和资源来做出决策。

以上步骤可以作为参考，帮助你进行MySQL和MongoDB的技术选型。最终选择应该基于你的具体需求和场景。在决策之前，建议进行原型验证或基准测试来评估数据库在实际情况下的性能和功能表现。

如果需要进一步的帮助，请提供更多关于你的应用需求的信息，我将尽力协助你进行技术选型。

#### 5、关系型数据库和非关系型数据库的应用场景对比

关系型数据库适合存储结构化数据，如用户的帐号、地址： 

1）这些数据通常需要做结构化查询，比如join，这时候，关系型数据库就要胜出一筹 
2）这些数据的规模、增长的速度通常是可以预期的 
3）事务性、一致性 
　　 
NoSQL适合存储非结构化数据，如文章、评论： 

1）这些数据通常用于模糊处理，如全文搜索、机器学习 
2）这些数据是海量的，而且增长的速度是难以预期的， 
3）根据数据的特点，NoSQL数据库通常具有无限（至少接近）伸缩性 
4）按key获取数据效率很高，但是对join或其他结构化查询的支持就比较差

### Spring

#### 1、Spring事务失效的8种情况

1. **数据库引擎不支持事务**

​		从 MySQL 5.5.5 开始的默认存储引擎是：InnoDB，之前默认的都是：MyISAM，所以这点要值得注意，底层引擎不支持事务再怎么搞都是白搭。

2. **没有被Spring管理**

```java
// @Service
public class OrderServiceImpl implements OrderService {

    @Transactional
    public void updateOrder(Order order) {
        // update order
    } 
}
```

3. **方法不是public**

​		@[Transactional](https://so.csdn.net/so/search?q=Transactional&spm=1001.2101.3001.7020) 只能用于 public 的方法上，否则事务会失效，如果要用在非 public 方法上，可以开启 AspectJ 代理模式。

4. **自身调用问题**

```java
@Service
public class OrderServiceImpl implements OrderService {

    public void update(Order order) {
        updateOrder(order);
        
        // 需要使用Aop代理才能触发事务，否则失效
    }
    
    @Transactional
    public void updateOrder(Order order) {
        // update order
    } 
}
```

```java
@Service
public class OrderServiceImpl implements OrderService {

    @Transactional
    public void update(Order order) {
        updateOrder(order);
    }
    
    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public void updateOrder(Order order) {
        // update order
    }  
}
```

​		它们发生了自身调用，就调该类自己的方法，而没有经过 Spring 的代理类，默认只有在外部调用事务才会生效，这也是老生常谈的经典问题了。

​		这个的解决方案之一就是在的类中注入自己，用注入的对象再调用另外一个方法，这个不太优雅，另外一个可行的方案可以参考《Spring 如何在一个事务中开启另一个事务？》这篇文章

5. **数据源没有配置事务管理器**

​		当前数据源若没有配置事务管理器，那也是白搭！

```java
@Bean
public PlatformTransactionManager transactionManager(DataSource dataSource) {
    return new DataSourceTransactionManager(dataSource);
}
```

6. **不支持事务**

```java
@Service
public class OrderServiceImpl implements OrderService {

    @Transactional
    public void update(Order order) {
        updateOrder(order);
    }
    
    // Propagation.NOT_SUPPORTED： 表示不以事务运行，当前若存在事务则挂起
    @Transactional(propagation = Propagation.NOT_SUPPORTED)
    public void updateOrder(Order order) {
        // update order
    }
}
```

7. **异常被捕获**

```java
// @Service
public class OrderServiceImpl implements OrderService {

    @Transactional
    public void updateOrder(Order order) {
        try {
            // update order
        } catch (Exception e) {
            // 将异常捕获后不抛出会导致事务失效，默认执行完成（AOP只能通过异常来进行回滚）
        }
    }
}
```

8. **异常类型错误**

```java
 // @Service
public class OrderServiceImpl implements OrderService {
	
	@Transactional
	public void updateOrder(Order order) {
	    try {
	        // update order
	    } catch {
	        throw new Exception("更新错误");
	    }
	}
}
```

​	这样事务也是不生效的，因为默认回滚的是：`RuntimeException`，如果你想触发其他异常的回滚，需要在注解上配置一下，如：

```java
@Transactional(rollbackFor = Exception.class)  // 这个配置仅限于 Throwable 异常类及其子类。
```

​		https://blog.csdn.net/weixin_43564627/article/details/121354260

#### 2、Spring 中 BeanFactory 与 FactoryBean 的区别

**直接区别**

直面意思：Bean工厂、工厂Bean

1、**BeanFactory**：以 Factory 结尾，表示它是一个工厂类（接口），用于管理 Bean 的一个工厂。在 Spring 中，BeanFactory 是 [IOC](https://so.csdn.net/so/search?q=IOC&spm=1001.2101.3001.7020) 容器的核心接口，它的**职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖**。

2、**FactoryBean**：以 Bean 结尾，表示它是一个 Bean，不同于普通 Bean 的是：它是实现了 `FactoryBean<T>` 接口的 Bean，通过该 Bean 的 ID 从 BeanFactory 中获取的实际上是 **FactoryBean 的 `getObject()` 返回的对象**，而不是 FactoryBean 本身，如果要获取 FactoryBean 对象，请在 id 前面加一个 `&` 符号来获取。

**BeanFactory 是什么？**

BeanFactory，以 Factory 结尾，表示它是一个工厂类(接口)，用于管理 Bean 的一个工厂。在 Spring 中，BeanFactory 是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。

BeanFactory 是一个接口，它是 Spring 中工厂的顶层规范，是 SpringIoc 容器的核心接口，它定义了 `getBean()`、`containsBean()` 等管理 Bean 的通用方法。

Spring 的容器都是它的具体实现如：

- DefaultListableBeanFactory
- XmlBeanFactory
- ApplicationContext

这些实现类又从不同的维度分别有不同的扩展。

例如 XmlBeanFactory 类将持有此 XML 配置元数据，并用它来构建一个完全可配置的系统或应用

#### 3、MVC、Spring、SpringMVC、SpringBoot、SpringCloud的区别是什么？

1.  MVC：MVC是一种设计模式，即Model模型、View视图以及Controller控制器；

2.  Spring：Spring是一个开源框架，是在2003年兴起的一个轻量级的Java开发框架。它是为了解决企业应用开发的复杂性而创建的，框架的主要优势之一就是其分层架构，分层架构允许使用者选择使用哪一个组件，同时为 J2EE 应用程序开发提供集成的框架。Spring使用基本的JavaBean来完成以前只可能由EJB完成的事情。Spring的用途不仅限于服务器端的开发，从简单性、可测试性和松耦合的角度而言，任何Java应用都可以从Spring中受益。Spring的核心是控制反转（IoC）和面向切面（AOP），简单来说，Spring是一个分层的JavaSE/EEfull-stack(一站式) 轻量级开源框架；

3.  SpringMVC：SpringMVC是一种WEB层的MVC框架，它是spring的一个模块，属于SpringFrameWork的后续产品，拥有spring的特性。SpringMVC分离了控制器、模型对象、分派器以及处理程序对象的角色；

4.  Spring Boot：它不是一个全新的框架，也不是Spring解决方案的替代品，而是对Spring框架的一个封装。所以，以前Spring可以做的事情，现在用SpringBoot都可以做；

5.  Spring Cloud：Sping Cloud是Spring的一个顶级项目，是一个微服务框架，提供了全套的分布式应用系统的解决方案。为开发者提供了快速构建分布式系统的工具，使其可以快速的启动服务、构建应用、同时能够快速和云平台资源进行对接。

总结：

Spring MVC和Spring Boot都是基于Spring，而Spring MVC是基于Spring的一种MVC框架，而Spring boot是基于Spring的一套快速开发整合包。

  ————————————————
  版权声明：本文为CSDN博主「cloneme01」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
  原文链接：https://blog.csdn.net/goodjava2007/article/details/122859472

#### 4、AOP的优点
1. **模块化**: AOP可以将横向关注点与纵向业务逻辑分离，从而实现模块化，使代码更加清晰易懂，易于维护和扩展；

2. **可重用性**: AOP可以将横向关注点作为独立的模块，从而使这些模块可以被多个应用程序共用，提高代码的可重用性；

3. **简化代码**: AOP可以用比传统方法更少的代码来实现同样的功能，从而简化代码，提高代码的可读性和可维护性；

4. **提高程序的灵活性**: AOP可以通过将横向关注点独立出来，使得程序的各个模块之间的耦合度降低，从而提高程序的灵活性，便于进行功能扩展和修改；

5. **提高程序的安全性**: AOP可以通过将安全控制与业务逻辑分离，提高程序的安全性，减少潜在的安全漏洞。

----

可以使用@Order注解来控制切面的顺序。在同一个方法上应用多个切面时，可以为每个切面添加不同的@Order值，值越小的切面将先执行，值越大的切面将后执行。如果没有指定@Order值，则默认优先级为0。

#### 5、SpringMVC如何基于全注解开发？

Spring MVC可以通过使用注解来进行全注解开发，即不再需要使用XML文件配置。

以下是实现全注解开发的步骤：

1. 在Spring配置类上添加`@Configuration`注解，将其声明为Spring配置类。
2. 使用`@EnableWebMvc`注解开启Spring MVC支持。
3. 添加`@ComponentScan`注解，指定扫描的包路径，以便自动注册控制器、拦截器和其他组件。
4. 使用`@Bean`注解将各种组件（如视图解析器）添加到容器中。例如，可以使用`InternalResourceViewResolver`类来配置JSP视图解析器，然后将其作为bean添加到容器中。
5. 创建控制器类，并在其上使用`@Controller`注解进行标记。
6. 在控制器类的处理方法上添加相应的请求映射注解，如`@RequestMapping`，用于将请求映射到该方法。
7. 根据需要，在控制器类或处理方法上使用其他注解，如`@ResponseBody`用于返回JSON数据，`@PathVariable`用于提取URI模板变量等。

这样就可以实现完全基于注解的Spring MVC开发。

#### 6、Spring/Tomcat一个请求对应一个线程吗？

在默认情况下，Spring Boot 项目是一个请求对应一个线程，使用**线程池**来处理请求。在 Spring Boot 应用启动时，会创建一个 Servlet 容器（如Tomcat）并初始化若干个处理请求的线程，这些线程组成一个线程池。

当一个请求到达时，Servlet 容器从线程池中选择一个空闲的线程来处理该请求，并将该请求交给这个线程处理。在这个线程处理完该请求后，它会被释放回线程池中，等待下一次请求。

因此，在 Spring Boot 应用中一个线程不仅可能处理多个请求，而且多个线程也可以处理同一个请求。这种方式可以避免为每个请求都创建新的线程带来的开销，提高系统的性能和吞吐量。

但是，如果你需要在某些场景下强制让一个请求只能对应一个线程，可以使用 ThreadLocal 来实现。ThreadLocal 变量是线程本地存储，可以在一个线程内共享数据，不同线程之间互不干扰。例如，可以使用 ThreadLocal 来保存当前请求的上下文信息，确保该信息只在当前请求所在的线程中可见。

----

SpringBoot默认的内嵌容器是Tomcat，也就是我们的程序实际上是运行在Tomcat里的。所以与其说SpringBoot可以处理多少请求，到不如说Tomcat可以处理多少请求。

- **server.tomcat.threads.min-spare**：最少的工作线程数，默认大小是10。该参数相当于长期工，如果并发请求的数量达不到10，就会依次使用这几个线程去处理请求。
- **server.tomcat.threads.max**：最多的工作线程数，默认大小是200。该参数相当于临时工，如果并发请求的数量在10到200之间，就会使用这些临时工线程进行处理。
- **server.tomcat.max-connections**：最大连接数，默认大小是8192。表示Tomcat可以处理的最大请求数量，超过8192的请求就会被放入到等待队列。
- **server.tomcat.accept-count**：等待队列的长度，默认大小是100。

也就是说，SpringBoot同时所能处理的最大请求数量是`max-connections+accept-count`，超过该数量的请求直接就会被丢掉。

链接：https://www.nowcoder.com/discuss/470218626839166976?sourceSSR=search

#### 7、SpringAOP的应用场景

SpringAOP（Aspect Oriented Programming）是Spring框架的核心模块之一，它提供了一种面向切面编程的方式，可以将系统中重复出现的横切逻辑集中在一个地方进行管理和维护，从而实现系统功能的横向拓展。

下面是SpringAOP的应用场景：

1. 日志记录：通过切入点表达式，可以在需要记录日志的方法上添加切面，记录方法的执行时间、参数、返回值等信息，便于后期调试和优化。

2. 事务管理：通过织入事务增强器，可以将系统中需要进行事务管理的方法自动加入到事务中，保证数据库操作的原子性和一致性。

3. 缓存管理：通过织入缓存切面，可以将查询结果缓存起来，在下次查询时直接从缓存中获取数据，减少数据库访问，提高系统性能。

4. 安全控制：通过织入安全切面，可以对系统中敏感操作进行权限验证，保障系统安全。

5. 异常处理：通过织入异常切面，可以对系统中出现的异常进行捕获和处理，保证系统的健壮性和稳定性。

总之，SpringAOP可以应用于各个领域的开发中，通过切面编程的方式，提高系统的可维护性、可扩展性和可重用性，减少重复代码的出现。

#### 8、Spring全局异常处理

1）try...catch的弊端

①处理繁琐

编写程序的过程中，不可避免的需要在各种地方处理各种异常，所以代码中就会出现大量的try {...} catch {...} finally {...} 代码块与处理业务的代码搅合在一起，不仅有大量的冗余代码，而且还影响代码的可读性。

②解决不了一异常

try...catch捕获不了参数异常

2）异常处理的三种方式

1. 实现HandlerExceptionResolver接口

2. @ExceptionHandler

3. @ControllerAdvice+@ExceptionHandler

   > - 优点：将 Controller 层的异常和数据校验的异常进行统一处理，减少模板代码，减少编码量，提升扩展性和可维护性。
   > - 缺点：只能处理 Controller 层未捕获（往外抛）的异常，对于 Interceptor（拦截器）层的异常，Spring 框架层的异常，就无能为力了。

[原理解读：Spring MVC统一异常处理](https://cloud.tencent.com/developer/article/2183878)

————————————————
原文链接：https://blog.csdn.net/qq_45043381/article/details/119619220

link: https://www.cnblogs.com/fps2tao/p/13526773.html

---

当然，理论上，任何能够给Controller加切面的机制都能变相的进行统一异常处理。比如:

1. 在拦截器内捕获Controller的异常，做统一异常处理
2. 使用Spring的AOP机制，做统一异常处理

#### 9、拦截器和过滤器

1、拦截器(Interceptor)只对action请求起作用即对外访问路径，而过滤器(Filter)则可以对几乎所有的请求都能起作用 包括css、js等资源文件；

2、拦截器(Interceptor)是在Servlet和Controller控制器之间执行，而过滤器(Filter)是在请求进入Tomcat容器之后但是在请求进入Servlet之前执行，在请求结束返回时也是一样，是在Servlet处理完之后返回给前端之间执行。

web.xml加载顺序：context- param -> listener -> filter -> servlet

<img src="asset\拦截器过滤器.png" alt="拦截器过滤器" style="zoom:80%;" />

- 拦截器是基于java的反射机制的，而过滤器是基于函数回调。
- 拦截器不依赖与servlet容器，过滤器依赖与servlet容器。
- 拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。
- 拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。
- 在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。
- 拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。拦截器可以获取ioc中的service bean实现业务逻辑。

总结：

- 拦截器和过滤器其实都是AOP编程思想的实现,只不过过滤器是基于函数回调的，拦截器则是基于Java的反射机制（动态代理）实现的，都可以体现例如权限的检查日志的记录等功能
- 过滤器实现的是javax.servlet.Filter接口，而这个接口是在Servlet规范中定义的，也就是说过滤器Filter 的使用要依赖于Tomcat等容器，导致它只能在web程序中使用。
- 拦截器(Interceptor)它是一个Spring组件，并由Spring容器管理，并不依赖Tomcat等容器，是可以单独使用的。不仅能应用在web程序中，也可以用于Application、Swing等程序中
- 过滤器Filter执行了两次，拦截器Interceptor只执行了一次

链接：https://mp.weixin.qq.com/s/qZc-2b_d4EhJhy10Stb3bw

​			[spring拦截器机制及其使用](https://baijiahao.baidu.com/s?id=1763874267965848222&wfr=spider&for=pc)

- 拦截器

```java
@Override
public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
    // 在拦截点（Controller方法处理之前）执行拦截 若返回的是false则中断执行 反之亦然
    return false;
}

@Override
public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
    // 在处理过程中（Controller方法处理完之后  DispatcherServlet进行视图的渲染之前）执行拦截
}

@Override
public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
    // 在DispatcherServlet进行视图的渲染后 返回前进行拦截
}
```

- 过滤器

```java
public class LoginFilter implements Filter {

    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        // 过滤器初始化
    }

    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {

    }

    @Override
    public void destroy() {
        // 过滤器销毁
    }
}
```

---

过滤器（Filter）和拦截器（Interceptor）是在软件开发中常用的两种技术，用于对请求进行处理和拦截。它们具有不同的特点和应用场景：

1. 区别：
   - 运行时位置：过滤器是在 Servlet 容器中的请求处理链中运行的，位于请求到达 Servlet 之前或响应离开 Servlet 之后。拦截器是在框架或应用程序的调用链中运行的，位于请求到达控制器之前或响应离开控制器之后。
   - 范围：过滤器是基于 URL 模式进行配置，可以作用于多个 Servlet 或资源。拦截器是基于控制器或方法进行配置，作用于特定的请求处理程序或方法。
   - 控制权：过滤器可以终止请求处理链，如果过滤器不放行请求，后续的过滤器和 Servlet 将不会执行。拦截器不能终止请求处理链，但可以在请求前后执行自定义逻辑。

2. 应用场景：
   - 过滤器：常用于对请求进行全局性的预处理和后处理，例如日志记录、字符编码转换、身份验证、请求过滤等。它们对于请求和响应的处理是无状态的，对所有请求都适用，具有较高的通用性和可重用性。
   - 拦截器：常用于在请求到达控制器之前和响应离开控制器之后执行一些特定的业务逻辑，例如权限验证、日志记录、性能监控、事务管理等。它们对于请求和响应的处理是有状态的，可以获取更多的控制权和上下文信息，适用于特定的业务需求。

需要注意的是，具体的应用场景和实现方式可能会因框架、平台和开发语言的不同而有所差异。以上是一般情况下过滤器和拦截器的区别和应用场景，具体使用时应根据实际需求和技术栈的特点来选择合适的技术手段。

#### 10、Restful风格接口设计

restful风格说白了是一种软件架构风格、设计风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。

简单点说就是，使用POST、DELETE、PUT、GET，使用不同方法对资源进行操作。 分别对应 添加、 删除、修改、查询。

传统url风格：

```http
http://127.0.0.1/item/queryUser.action?id=1   	  # 查询,GET 
http://127.0.0.1/item/saveUser.action             # 新增,POST 
http://127.0.0.1/item/updateUser.action           # 更新,POST 
http://127.0.0.1/item/deleteUser.action?id=1      # 删除,GET或POST
```

使用Restful风格：

```http
【GET】 /users 					# 查询用户信息列表
【GET】 /users/1001 				# 查看某个用户信息
【POST】 /users 					# 新建用户信息
【PUT】 /users/1001 				# 更新用户信息(全部字段)
【PATCH】 /users/1001 			# 更新用户信息(部分字段)
【DELETE】 /users/1001 			# 删除用户信息
```

简单概括restful设计风格：

1. 使用名词而不是动词；
2. Get方法和查询参数不应该涉及状态改变；
3. 使用复数名词；
4. 使用子资源表达关系；
5. 使用Http头声明序列化格式；
6. 为集合提供过滤 排序 选择和分页等功能；
7. 版本化你的API；
8. 使用Http状态码处理错误；
9. 允许覆盖http方法。

————————————————
原文链接：https://blog.csdn.net/qq_37370132/article/details/107099991

### SpringBoot

#### 1、SpringBoot的自动配置原理

> 自动配置：Auto-Configuration
>
> 自动装配：Autowired
>
> ----------------
>
> 术语“配置类，英文 Configuration Class
>
> - 广义的“配置类”被注解 @Component 直接或间接修饰的某个类即我们常说的 Spring 组件，其中包括了 @Configuration 类
>
> - 狭义的“配置类"特指被注解@Configuration 所修饰的某个类又称为 @Configuration 类

<img src="https://img-blog.csdnimg.cn/20210629121733256.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzgyNjI0Mg==,size_16,color_FFFFFF,t_70" alt="Spring Boot自动装配详细流程图" style="zoom: 33%;" />

> 总结一下，面试可以这样简洁回答：
> 启动类的@SpringBootApplication注解由@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan三个注解组成，三个注解共同完成自动配置；
>
> @SpringBootConfiguration 注解标记启动类为配置类
> @ComponentScan 注解实现启动时扫描启动类所在的包以及子包下所有标记为bean的类由IOC容器注册为bean
> @EnableAutoConfiguration通过 @Import 注解导入 AutoConfigurationImportSelector类，然后通过该类的 selectImports() 方法去读取需要被自动装配的组件依赖下的META-INF/spring.factories文件配置的组件的类全名，并按照一定的规则过滤掉不符合要求的组件的类全名，将剩余读取到的各个组件的类全名集合返回给IOC容器并将这些组件注册为bean。
> ————————————————
> 原文链接：https://blog.csdn.net/qq_24078621/article/details/125216990
> 原文链接：https://blog.csdn.net/Elliot_Elliot/article/details/116609892

从一下几个方面来讲解：

<img src="asset\R[0GLDZ2AXY(1AM[MLQ1~8A.png" alt="20210629121733256" style="zoom: 50%;" />

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230102125418949.png" alt="image-20230102125418949" style="zoom: 67%;" />

> 自动装配主要依靠三个核心的关键技术：
>
> 1. 引入Starter，启动依赖组件时，这个组件里面必须要有一个包含@Configuration注解的配置类，里面通过@Bean声明了很多需要装配到IOC容器里面的Bean对象；
>
> 2. 这个配置类存放在第三方的jar包中，然后通过SpringBoot中约定优于配置的理念，将这个类的全路径放在 classpath:/META-INF/spring.factories中，让SpringBoot可以读取到第三方jar包里配置类的位置，该步骤主要用到了 SpringFactoriesLoader 来完成的；
> 3. SpringBoot拿到所有的第三方 jar 包中声明的配置类后，再通过提供的 ImportSelector 的接口来实现对这些配置类的动态加载，从而去完成自动装配的流程。
> 4. 自动装配的具体流程就是 @AutoEnableConfiguration 注解开始往下走。
>
> @SpringBootApplication ---> @EnableAutoConfiguration ---> @Import(AutoConfigurationImportSelector.class) ---> AutoConfigurationImportSelector.class
>
> selectImports() ---> getAutoConfigurationEntry() ---> getCandidateConfigurations() ---> configurations = SpringFactoriesLoader.loadFactoryNames()

https://dzzhyk.blog.csdn.net/article/details/106005176

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230102200837478.png" alt="image-20230102200837478" style="zoom:45%;" />

<img src="asset\SpringBoot启动流程.png" alt="SpringBoot启动流程" style="zoom:43%;" />

#### 2、SpringBoot是什么？

1. Spring Boot是为了简化配置进一步简化Spring应用的搭建和开发过程的轻量级框架。它的目的在于实现自动化配置，降低项目的复杂度。
2. 由于Spring-boot-starter-web模块中包含了一个内置tomcat，可以直接提供容器使用。基于Spring boot，不是原来的配置没有了，而是有一套默认的配置，可以把默认配置看作通用的约定。因此Spring boot遵守也是约定优于配置原则。
3.  SpringBoot完成了对各种框架的整合，让这些框架集成在一起变得更加简单，简化了我们在集成过程中繁琐的模板化配置；
4.  从最根本上来讲，Spring Boo是一个启动Spring项目的工具，是一些库的集合；
5.  SpringBoot不是一个全新的框架，也不是Spring解决方案的替代品，而是对Spring框架的一个封装。所以，以前Spring可以做的事情，现在用SpringBoot都可以做；
6.  一般情况下，一个SpringBoot应用 = 一个微服务 = 一个模块 = 一个有边界的上下文；
7.  SpringBoot是整合Spring技术栈的一站式框架，是简化Spring技术栈的快速开发脚手架，是一个能够快速构建生产级别的Spring应用的工具。

​	————————————————
​	原文链接：https://blog.csdn.net/goodjava2007/article/details/122859472

#### 3、如何理解SpringBoot中的Starter？

使用Spring+SpringMVC框架进行开发的时候，如果需要引入mybatis框架，那么需要在xml中定义需要的bean对象，这个过程很明显时很麻烦的，如果需要引入额外的其他组件，那么也需要进行复杂的配置，因此在springboot中引入了starter。

`Starters`可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成`Spring`及其他技术，而不需要到处找示例代码和依赖包。

本质上，`starter`就是一个`jar`包，写一个或多个`@Configuration`的配置类，将这些`bean`定义在其中，然后在`starter`包的 `META-INF/spring.factories` 中写入配置类，那么`springboot`程序在启动的时候就会按照约定来加载该配置类。

> 一般情况下，`xxx-spring-boot-starter` 只是一个空壳，不写代码，主要通过 `pom` 文件去引入项目中可能用到的其他依赖，然后通过 `xxx-spring-boot-autoconfigure` 去进行自动配置，包括具体的 `Configuration` 配置类以及定义好的 `bean`，然后将配置类写入 `spring.factories` 文件中，`springboot` 启动时便会根据约定去加载对应的配置类。

开发人员只需要将相应的 `starter` 包依赖引入应用中，进行相关的属性配置，就可以进行代码开发，而不需要单独进行 `bean` 的配置。

官方：`spring-boot-starter-xxxx` 命名，第三方：`xxxx-spring-boot-starter` 命名。

————————————————
原文链接：https://blog.csdn.net/qq_27181375/article/details/126425163

#### 4、自定义实现SpringBoot Stater的步骤

1. 写一个 `starter` 项目，一般是一个空壳，里面不写代码，主要写到依赖其他项目的作用，起名叫：`xxx-spring-boot-starter`；
2. 写一个真正实现自动装配逻辑的项目，例如：`xxx-spring-boot-autoconfigure`，在项目 `classpath` 下写一个 `META-INF/spring.factories` 文件；
3. 在 `spring.factories` 中添加配置：`org.springframework.boot.autoconfigure.EnableAutoConfiguration = com.bjpowernode.xxxConfiguration`；
4. `xxxCOnfiguration` 类需要添加注解 `@Configuration`；
5. `xxxConfiguration` 类一般也会使用 `@Conditioanl` 来适应不同的环境；
6. 在 `xxxConfiguration` 类中编写具体代码实现自动化配置，给使用者把该配的配置好，让别人可以直接使用；
7. 然后在 `xxx-spring-boot-starter` 引入 `xxx-spring-boot-autoconfigure`项目，此时就完成了一个自定义的 `starter` 的编写。

#### 5、Java SPI的概念和术语

**何谓 SPI?**

SPI 即 Service Provider lnterface，字面意思就是:"服务提供者的接口"，我的理解是: 专门提供给服务提供者或者扩展框架功能的开发者去使用的一个接口。

SPl 将服务接口和具体的服务实现分离开来，将服务调用方和服务实现者解耦，能够提升程序的扩展性、可维护性。修改或者替换服务实现并不需要修改调用方。

很多框架都使用了 Java 的 SPI 机制，比如: Spring 架、数据库加载驱动、日志接口、以及 Dubbo 的扩展实现等等。它是从Java 6开始引入的，是一种基于 classLoader 来发现并加载服务的机制。

**Service**

​		Service，是一个公开的接口或抽象类，定义了一个抽象的功能模块

**Service Provider**

​		Service Provider，则是Service 接口的一个实现类

**ServiceLoader**

​		ServiceLoader，是SPI机制中的核心组件，负责在运行时发现并加载 Service Provider.

**SPI的运行流程**

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230102184536346.png" alt="image-20230102184536346" style="zoom: 50%;" />

**Java SPI总结：**

作用：提供了一种组件发现和注册的方式，可以用于实现各种插件，或者灵活替换框架所使用的组件

优点：基于面向接口编程，优雅地实现模块之间的解耦

设计思想：面向接口 + 配置文件 + 反射技术，YYDS!!!

应用场景：JDBC·SLF4J ·Servlet容器初始化 ·等等.

缺点：Java SPI 不能单独获取某个指定的实现类；Java SPI 没有 IOC 和 AOP 机制。

**与 SpringBoot 自动装配对比：**

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230102201131199.png" alt="image-20230102201131199" style="zoom:50%;" />

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230102200951369.png" alt="image-20230102200951369" style="zoom: 43%;" />

#### 6、SpringBoot启动后/停止前立即执行的方法

**springboot启动后即执行的方法**

1）实现ApplicationRunner接口

```java
@Configuration
public class ApplicationService implements ApplicationRunner {
    @Override
    public void run(ApplicationArguments args) throws Exception {
        iForwardQueuesService.create();
    }
}
```

2）实现CommandLineRunner接口

```java
@Configuration 
public class ApplicationService implements CommandLineRunner {
    @Override
    public void run(String... args) throws Exception {
        log.info(``"执行平台登出"``);
    }
}
```

注意：如果ApplicationListener和CommandLineRunner同时存在，则ApplicationRunner接口先执行,CommandLineRunner后执行;
也可以使用执行执行顺序

```java
@Configuration
@Order(1)
public class ApplicationService implements CommandLineRunner {
    // ......
}
```

原理：
`SpringApplication` 的 `run` 方法会执行 `afterRefresh` 方法。
`afterRefresh` 方法会执行 `callRunners` 方法。
`callRunners` 方法会调用所有实现 `ApplicationRunner` 和 `CommondLineRunner` 接口的方法。

**springboot停止前执行的方法**

1）实现DisposableBean接口并实现destroy方法
springboot销毁时执行

```java
@Configuration
public class ApplicationService implements DisposableBean {
    @Override
    public void destroy() throws Exception {
        log.info("执行平台登出");
        platformService.PlatformLogout();
    }
}
```

2）使用ShutdownHook关闭钩子
JAVA虚拟机关闭钩子(Shutdown Hook)在下面场景下被调用：

- 程序正常退出;
- 使用System.exit();
- 终端使用Ctrl+C触发的中断;

- 系统关闭;
- OutOfMemory宕机;
- 使用Kill pid命令干掉进程(注：在使用kill -9 pid时，是不会被调用的);

```java
@SpringBootApplication 
@ComponentScan(value = "com.xxxxxx")
public class ForwardGbApplication {
    public static void main(String[] args) {
        ForwardGbApplication application = new ForwardGbApplication();
        Thread t = new Thread(new ShutdownHook(application), "ShutdownHook-Thread");  
        Runtime.getRuntime().addShutdownHook(t);
        SpringApplication.run(ForwardGbApplication.class, args);
    }
    
    static class ShutdownHook implements Runnable{
        private ForwardGbApplication manager;
        
        public ShutdownHook(ForwardGbApplication serverManager){
            manager = serverManager;
        }
        
        @Override
        public void run() {
            try {
                PlatformService platform = ApplicationContextHandle.getObject(PlatformService.class);
                platform.PlatformLogout();
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
}
```

`RunTime.getRunTime().addShutdownHook`的作用就是在JVM销毁前执行的一个线程.当然这个线程依然要自己写.

#### 7、RestTemplate

**RestTemplate**

RestTemplate是Spring提供的用于访问Rest服务的客户端，它提供了很多可以方便访问远程http服务的方法，这些方法可以帮助开发人员减少编写客户端代码的工作量。

**什么是REST？**

REST（Representational State Transfer）表述性状态转移。REST是一种跨平台、跨语言的架构风格。是利用HTTP的特性去设计的一种规范。

> 特性：
> 1）面向资源，以资源抽象为核心进行展开的。资源（文档，图片，一条数据）就是存在服务器上的任何信息，我们需要一个唯一的标记去操作这个资源，我们把这个标记称之为URI。
> 2）可寻址，资源在Web 服务器上都有唯一的地址。
> 3）联通性，我们在设计的不能把资源隔离开来，要考虑资源关联关系，并且通过超链接的形式将资源关联起来。
> 4）无状态，只有无状态才能够实现资源的可伸缩性。
> 5）利用GET、PUT、DELETE、POST来表示操作动作。
> 原文链接：https://blog.csdn.net/maxy_2013/article/details/122995548

### SpringCloud

#### 1、网关的作用

[5种主流API网关技术选型](https://mp.weixin.qq.com/s/iSlkUJ0CtNvoMvET7R7RPQ)

网关可以对请求进行路由，比如：可以根据请求路径路由、根据host地址路由等， 当微服务有多个实例时可以通过负载均衡算法进行路由，另外，网关还可以实现权限控制、限流等功能。

网关作为系统的唯一流量入口，封装内部系统的架构，所有请求都先经过网关，由网关将请求路由到合适的微服务，所以，使用网关的好处在于：

- 简化客户端的工作。网关将微服务封装起来后，客户端只需同网关交互，而不必调用各个不同服务；

- 降低函数间的耦合度。 一旦服务接口修改，只需修改网关的路由策略，不必修改每个调用该函数的客户端，从而减少了程序间的耦合性；

- 解放开发人员把精力专注于业务逻辑的实现。由网关统一实现**服务路由(灰度与ABTest)、负载均衡、访问控制、流量控制、熔断降级、安全认证**等非业务相关功能，而不需要每个服务 API 实现时都去考虑。

<img src="asset\网关基本功能.png" alt="img" style="zoom: 50%;" />

————————————————
原文链接：https://blog.csdn.net/a745233700/article/details/122917167

#### 2、配置文件优先级

配置文件的优先级：项目应用名配置文件 > 扩展配置文件 > 共享配置文件 > 本地配置文件。

#### 3、SpringCloud如何实现负载均衡

Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端 负载均衡的工具。简单的说，Ribbon是Netflix发布的开源项目，主要功能是提供客户端的软件负载均衡算法和服务调用。

**总结：负载均衡+RestTemplate调用**

<img src="asset\ribbon负载均衡.png" alt="image-20210904160853221" style="zoom:80%;" />

**OpenFeign自带负载均衡功能**

自定义负载均衡配置类：

```java
@Configuration
@ExcludeFromComponentScan
public class TestConfiguration1 {
    @Autowired
    private IClientConfig config;
    @Bean
    public IRule ribbonRule(IClientConfig config) { // 自定义为随机规则
        return new RandomRule();
    }
}
```

#### 4、熔断和降级

熔断和降级都是为了保护系统的稳定性和可靠性，但它们的应用场景和实现方式有所不同。

**熔断**（Circuit Breaker）是一种防止请求继续执行导致服务雪崩的机制。当系统中某个服务出现故障或者超时时，会自动切断对该服务的访问，避免其因为无法响应而引起更多的请求，最终导致服务整体不可用。熔断器通常有三个状态：关闭、开启和半开启。当熔断器处于关闭状态时，所有的请求都可以正常访问服务；当熔断器处于开启状态时，所有请求都被拒绝，直到一定时间后进入半开启状态；当熔断器处于半开启状态时，部分请求可以重新尝试访问服务，如果服务返回正常结果，则恢复正常访问，否则再次回到开启状态。

例如，在电商网站中，某一个商品详情页面涉及到多个服务调用，如用户信息、库存信息、价格信息等。如果其中一个服务出现故障或者超时，那么就可能导致整个页面无法正常加载，影响用户体验。这时通过熔断机制，我们可以针对故障服务进行限流或者降级，避免其影响整个页面的正常加载。

**降级**（Fallback）则是一种当服务出现故障或者资源不足时，损失部分质量以保证系统可用性的机制。通过预设好的备用方案来代替原有服务，提供一个较低质量的结果。当原有服务恢复后，再切换回原有服务。在降级过程中，要确保备用方案能够满足基本需求和安全性；同时也要注意监控和记录降级信息，便于后续定位问题和解决。

例如，在支付系统中，如果某一个渠道因为网络、系统等原因无法正常使用，就可以通过降级机制，将该渠道切换至备用方案，如其他支付渠道或者人工处理，保证支付系统整体的可用性。

---

熔断和降级是两个不同但相关的概念。熔断机制通常用于保护系统免受服务故障或资源不足等问题的影响，它会暂时切断对某个服务的访问并进入半开启状态进行恢复。而降级机制则是在服务不可用时提供备用方案以保证系统可用性，它可能会牺牲一定的质量来换取系统的稳定性。

在实际应用中，可以通过组合使用熔断和降级机制来提高系统的可靠性和容错能力。例如，在对某个服务进行重试时，如果连续多次失败，就触发熔断机制进行限流或者降级；同时也可以在降级方案中设置一个熔断器，当备用方案无法提供可行结果时，进入熔断状态并进行恢复尝试。

因此，熔断和降级虽然是两个不同的概念，但都是为了保护系统免受故障和资源问题的影响，并且可以互相补充和配合使用来提高系统的健壮性和稳定性。

#### 5、OpenFeign

OpenFeign是一个基于HTTP客户端的声明式Web服务客户端，它使得编写Web服务客户端变得更加容易。它是一个轻量级的库，可以与Spring Cloud和Spring Boot集成，以便于在微服务架构中使用。

OpenFeign的主要特点如下：

1. 声明式API：OpenFeign使用注解方式声明Web服务API，使得代码更加简洁易读。
2. 无需手动编写API实现：OpenFeign通过动态代理生成API实现，无需手动编写。
3. 支持多种HTTP客户端：OpenFeign支持多种HTTP客户端，包括OkHttp和Apache HttpClient。
4. 支持负载均衡：OpenFeign可以与Ribbon集成，实现负载均衡。
5. 支持断路器：OpenFeign可以与Hystrix集成，实现断路器功能。
6. 支持自定义拦截器：OpenFeign支持自定义拦截器，可以对请求和响应进行扩展。

总之，OpenFeign是一个非常方便的Web服务客户端，可以大大简化Web服务客户端的编写，提高开发效率。

使用 Jackson 序列化算法；

### 分布式

#### 1、分布式和微服务

**分布式系统**
个人觉得分布式系统面向的是Ops，更多的是考虑系统性能和部署环境之间的问题，通过分布式解决在没有大型主机的部署环境情况下，系统性能的高可用和吞吐量，是个一个很早就提出来的一个概念，是由集中式系统过渡来的，随着计算机系统向网络化和微型化的发展日趋明显，同时业务的发展，传统的集中式处理模式越来越不能适应人们的需求，学习成本高，大型主机贵、容错性差，扩容困难。

为了解决业务快速发展给IT系统带来的巨大挑战,从2009年开始,阿里集团启动了去IOE计划,其电商系统开始正式迈入分布式系统时代。

在《分布式系统概念与设计》生一书中,对分布式系统做了如下定义:

分布式系统是一个硬件或软件组件分布在不同的网络计算机上,彼此之间仅仅通过消息传递进行通信和协调的系统。 (硬件或软件组件,个人理解 ，硬件组件分布我们可以结合HarmonyOS理解，音画同步，应用跨设备流转，软总线等硬件抽象的分布式，或者可以结合RAID(独立冗余磁盘阵列）理解，可以理解为以机器为粒度的磁盘阵列，软件组件分布这里结合我们常说的微服务分布式部署，类比java Web分布式系统。)

**微服务架构**
微服务 (Microservices) 是一种软体架构风格，它是以专注於单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模组化的方式组合出复杂的大型应用程式，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的API 集相互通讯。 微服务的起源是由 Peter Rodgers 博士于 2005 年度云端运算博览会提出的微 Web 服务 (Micro-Web-Service) 开始，Juval Löwy 则是与他有类似的前导想法，将类别变成细粒服务 (granular services)，以作为 Microsoft 下一阶段的软体架构，其核心想法是让服务是由类似 Unix 管道的存取方式使用，而且复杂的服务背后是使用简单 URI 来开放介面，任何服务，任何细粒都能被开放 (exposed)。这个设计在 HP 的实验室被实现，具有改变复杂软体系统的强大力量。 2014年，Martin Fowler 与James Lewis共同提出了微服务的概念，定义了微服务是由以单一应用程式构成的小服务，自己拥有自己的行程与轻量化处理，服务依业务功能设计，以全自动的方式部署，与其他服务使用 HTTP API 通讯。同时服务会使用最小的规模的集中管理 (例如 Docker) 能力，服务可以用不同的程序语言与资料库等元件协作。

个人觉得微服务架构更多的是面向dev,更多的是考虑编码和项目业务之间的问题,根据功能把应用拆分为服务。解决的是开发问题和应用复杂性，是在对于业务的快速发展中单体应用不能满足需要的时候，提出来的一个概念，《微服务架构设计模式》一书中对微服务架构做如下定义：

把应用程序功能性分解为一组服务的架构风格。(很直白的一句话,不需要多解释，对于大型系统而言，模块化是必不可少的，相信小伙伴也做过类似的项目，微服务架可以看做是模块化的一种形式）

**比较**
从应用程序的扩展角度考虑
微服务和分布式都是对大型应用程序的扩展，只是扩展方向不同：

- 分布式系统更多是偏水平扩展，在ops方面的解决办法，利用部署系统环境的空间分布性，比如SOA架构中利用分布式集成大型、复杂的单体应用程序；比如对实例进行克隆，以副本的形式对应用的数据和服务提供一种冗余方式(数据副本和服务副本)，从而对外提供高可用，高并发的服务。分布式需要解决分布式数据一致性以及分布式环境通信异常、网络分区等问题。比如通过Zookeeper解决分布式数据一致性的问题。分布式系统可以理解为以解决硬件层面的压力从而对应用进行扩展。

- 微服务架构更多的是垂直方向的扩展，在dev方面解决问题，利用应用程序的功能性分解,，把应用拆分为一组服务，每个服务负责特定的功能。每个服务都相对较小并容易维护，使大型的复杂应用程序可以持续交付和持续部署。服务可以独立部署、可以独立扩展。同时微服务架构可以实现团队的自治。更容易实验和采纳新的技术。更好的容错性。即服务之间松耦合，但是单个服务又是高内聚的。微服务架构可以理解为解决软件层面的压力对应用进行扩展。

**微服务架构和分布式系统之间的关系**

个人认为，不属于包含关系，都是是对于应用扩展的不同解决办法。一般情况下，微服务架构的应用一般为分布式系统。但分布式系统不一定是微服务架构。
————————————————
原文链接：https://blog.csdn.net/sanhewuyang/article/details/118449828

-------------

>分布式：
>
>分布式的核心就一个字：拆。只要是将一个项目拆分成了多个模块，并将这些模块分开部署，那就算是分布式。
>
>如何拆呢？有两种方式：水平拆分，或垂直拆分（也称为“横向拆分”和“垂直拆分”），具体如下：
>
>水平拆分：根据“分层”的思想进行拆分。例如，可以将一个项目根据“三层架构”拆分成 表示层（jsp+servlet）、业务逻辑层（service）和数据访问层（dao），然后再分开部署：把表示层部署在服务器A上，把service和dao层部署在服务器B上，然后服务器A和服务器B之间通过dubbo等RPC进行进行整合。
>
>垂直拆分：根据业务进行拆分。例如，可以根据业务逻辑，将“电商项目”拆分成“订单项目”、“用户项目”和“秒杀项目”。显然这三个拆分后的项目，仍然可以作为独立的项目使用。像这种拆分的方法，就成为垂直拆分。

>微服务：
>
>微服务”就是非常微小的服务。微服务可以理解为一种非常细粒度的垂直拆分。例如，以上“订单项目”本来就是垂直拆分后的子项目，但实际上“订单项目”还能进一步拆分为“购物项目”、“结算项目”和“售后项目”，订单项目”，它完全可以作为一个分布式项目的组成元素，但就不适合作为微服务的组成元素了（因为它还能再拆，而微服务应该是不能再拆的“微小”服务，类似于“原子性”）。所以，大白话就是，微服务就是不可分割的分布式模块。

> **分布式：拆了就行。**
>
> **微服务：细粒度的垂直拆分。**
>
> https://blog.csdn.net/m0_46392035/article/details/124633411

#### 2、OPS TPS RPS

**QPS**：全名 Queries Per Second，意思是“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。

简单的说，QPS = req/sec = 请求数/秒。它代表的是服务器的机器的性能最大吞吐能力。

**TPS**： 即 Transactions Per Second 的缩写，每秒处理的事务数目。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。

客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息作出的评估分。

TPS 的过程包括：客户端请求服务端、服务端内部处理、服务端返回客户端。

**RPS**： 代表吞吐率，即 Requests Per Second 的缩写。吞吐率是服务器并发处理能力的量化描述，单位是 reqs/s，指的是某个并发用户数下单位时间内处理的请求数。

某个并发用户数下单位时间内能处理的最大的请求数，称之为最大吞吐率。

有人把 RPS 说等效于 QPS。其实可以看作同一个统计方式，只是叫法不同而已。RPS/QPS，可以使用 apche ab 工具进行测量。
————————————————
原文链接：https://blog.csdn.net/yu1xue1fei/article/details/112727927

#### 3、Raft算法

[Raft算法](https://zhuanlan.zhihu.com/p/32052223?utm_medium=social)

#### 4、幂等性保障

在高并发场景的架构里，幂等性是必须得保证的。比如说支付功能，用户发起支付，如果后台没有做幂等校验，刚好用户手抖多点了几下，于是后台就可能多次受到同一个订单请求，不做幂等很容易就让用户重复支付了，这样用户是肯定不能忍的。

**解决方案**

1，查询和删除不在幂等讨论范围，查询肯定没有幂等的说，删除：第一次删除成功后，后面来删除直接返回0，也是返回成功。

2，**数据库主键约束**或建**唯一索引**：唯一索引或唯一组合索引来防止新增数据存在脏数据 （当表存在唯一索引，并发时新增异常时，再查询一次就可以了，数据应该已经存在了，返回结果即可）。

3、**下游传递唯一序列号**，请求前生成唯一的序列号，携带序列号去请求，执行时在 redis 记录该序列号表示以该序列号的请求执行过了，如果相同的序列号再次来执行说明是重复执行。

3，**token机制**：由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交。前端在数据提交（订单）前要向后端服务的申请token，token放到 Redis 或 JVM 内存，token有效时间。提交后后台校验token，同时删除token，生成新的token返回。redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用（可以使用lua）。

4，**悲观锁**：悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用（另外还要考虑id是否为主键，如果id不是主键或者不是 InnoDB 存储引擎，那么就会出现锁全表）。

5，**乐观锁**，给数据库表增加一个version字段，可以通过这个字段来判断是否已经被修改了

6，**分布式锁**，比如 Redis 、 Zookeeper 的分布式锁。单号为key，然后给Key设置有效期（防止支付失败后，锁一直不释放），来一个请求使用订单号生成一把锁，业务代码执行完成后再释放锁。

7，**保底方案**，先查询是否存在此单，不存在进行支付，存在就直接返回支付结果。

链接：[实现接口幂等性的 4 种方案](https://www.nowcoder.com/discuss/463747212967714816?sourceSSR=users)

[如何保证业务的幂等性](https://gongfukangee.github.io/2019/03/25/Idempotence/)

[保证接口幂等性，防止重复提交](https://juejin.cn/post/7145664154186022943)

---

**总结：**

幂等性是开发当中很常见也很重要的一个需求，尤其是支付、订单等与金钱挂钩的服务，保证接口幂等性尤其重要。在实际开发中，我们需要针对不同的业务场景我们需要灵活的选择幂等性的实现方式：

- 对于下单等存在唯一主键/索引的，可以使用“唯一主键方案”的方式实现。
- 对于更新订单状态等相关的更新场景操作，使用“乐观锁方案”实现更为简单。
- 对于上下游这种，下游请求上游，上游服务可以使用“下游传递唯一序列号方案”更为合理。
- 类似于前端重复提交、重复下单、没有唯一ID号的场景，可以通过 Token 与 Redis 配合的“防重 Token 方案”实现更为快捷。

上面只是给与一些建议，再次强调一下，实现幂等性需要先理解自身业务需求，根据业务逻辑来实现这样才合理，处理好其中的每一个结点细节，完善整体的业务流程设计，才能更好的保证系统的正常运行。最后做一个简单总结

|      方式       |          使用情况          | 实现难度 |                           注意事项                           |
| :-------------: | :------------------------: | :------: | :----------------------------------------------------------: |
| 数据库唯一主键  |     插入操作 删除操作      |   简单   |       - 只能用于插入操作；- 只能用于存在唯一主键场景；       |
|  数据库乐观锁   |          更新操作          |   简单   |         - 只能用于更新操作；- 表中需要额外添加字段；         |
|   请求序列号    | 插入操作 更新操作 删除操作 |   简单   | - 需要保证下游生成唯一序列号；- 需要 Redis 第三方存储已经请求的序列号； |
| 防重 Token 令牌 | 插入操作 更新操作 删除操作 |   适中   |           - 需要 Redis 第三方存储生成的 Token 串；           |

---

GPT答案：

订单的防重复提交是一个常见的问题，以下是几种可能的方案：

1. 前端防重复提交：在用户提交订单后，禁用提交按钮或者显示一个加载中的提示，防止用户重复提交订单。这种方法简单易行，但是无法防止用户通过其他方式提交订单，比如直接发送请求。

2. 后端防重复提交：在服务器端对每个订单生成一个唯一的标识符，比如订单号或者随机字符串，并将其存储在缓存或者数据库中。当用户提交订单时，服务器端会检查该标识符是否已经存在，如果存在则说明订单已经提交过了，返回错误信息。这种方法可以有效防止重复提交，但是需要在服务器端进行额外的处理。

3. Token 防重复提交：在用户提交订单时，服务器端生成一个唯一 Token，并将其返回给前端。前端在提交订单时需要将该 Token 一并提交到服务器端，服务器端会检查该 Token 是否已经被使用过，如果已经被使用过则说明订单已经提交过了，返回错误信息。这种方法可以有效防止重复提交，而且相对于后端防重复提交来说，减轻了服务器端的负担。

4. 使用分布式锁：在多台服务器上部署同一个应用时，可以使用分布式锁来防止重复提交。当一个订单正在被处理时，其他服务器上的请求会被阻塞，直到该订单处理完成。这种方法可以有效防止重复提交，但是需要额外的技术支持。

需要根据具体的业务场景和技术架构选择合适的方案。

#### 5、分布式事务

**什么是分布式事务？**

分布式事务是指涉及到多个计算机或者应用程序之间的事务操作，这些计算机或应用程序可能分布在不同的地理位置上。在分布式环境中，一个完整的业务操作可能需要多个服务协同工作来完成，这些服务可能位于不同的节点上，并且都有各自的数据存储。

分布式事务需要满足 ACID（原子性、一致性、隔离性和持久性）特性，即：

1. 原子性（Atomicity）：分布式事务必须被视为单个操作单元，要么全部执行成功，要么全部失败回滚。
2. 一致性（Consistency）：分布式事务的执行必须使系统从一个一致状态转移到另一个一致状态，即不能破坏数据的完整性约束。
3. 隔离性（Isolation）：分布式事务在运行过程中，对其他事务必须隔离，不能相互影响。
4. 持久性（Durability）：一旦分布式事务提交，它所做的改变将永久保存在系统中。

常见的分布式事务解决方案包括两阶段提交协议（2PC）、补偿事务（TCC）、异步补偿（AT）等。其中，2PC 是最为经典的解决方案，它通过协调者和参与者之间的通信来控制事务的提交过程，在保证 ACID 特性的同时，也带来了一定的性能和可靠性方面的问题。因此，针对不同的场景和需求，需要选择合适的分布式事务解决方案。

![img](asset\arch-z-transection-1.png)

分布式事务的解决方案有很多，比如：2PC、3PC、TCC、本地消息表、MQ 事务（Kafka 和 RocketMQ 都提供了事务相关功能） 、Saga 等等。

2PC、3PC 属于业务代码无侵入方案，都是基于 XA 规范衍生出来的实现，XA 规范是 X/Open 组织定义的分布式事务处理（DTP，Distributed Transaction Processing）标准。TCC、Saga 属于业务侵入方案，MQ 事务依赖于使用消息队列的场景，本地消息表不支持回滚。

<img src="asset\XA规范角色.png" alt="image-20230322200742546" style="zoom:80%;" />

- AP（Application Program）：应用程序本身。
- RM（Resource Manager） ：资源管理器，也就是事务的参与者，绝大部分情况下就是指数据库（后文会以关系型数据库为例），一个分布式事务往往涉及到多个 RM。
- TM（Transaction Manager） ：事务管理器，负责管理全局事务，分配事务唯一标识，监控事务的执行进度，并负责事务的提交、回滚、失败恢复等。

**总结**

可以看出 2PC 和 3PC 是一种强一致性事务，不过还是有数据不一致，阻塞等风险，而且只能用在数据库层面。

而 TCC 是一种补偿性事务思想，适用的范围更广，在业务层面实现，因此对业务的侵入性较大，每一个操作都需要实现对应的三个方法。（可以实现强一致性）

本地消息、事务消息和最大努力通知其实都是最终一致性事务，因此适用于一些对时间不敏感的业务。

链接：https://zhuanlan.zhihu.com/p/183753774

#### 4、服务注册与发现 — 选择 CP 还是 AP？

对于服务发现而言，拥有可能包含虚假信息的信息要比根本不拥有任何信息更好，所以个人认为 AP 优于 CP。

在 AP 模式下，如果请求到不准确的服务实例信息，导致请求发送到一个宕机的服务端，只要做好失败重试机制和负载均衡，这次请求能够顺利的进行。

链接：https://blog.csdn.net/qq40988670/article/details/105966202

#### 5、分布式缓存的一致性？

分布式缓存的一致性指的是多个节点之间数据的同步和一致性保证。一般来说，分布式缓存可以采用以下两种方式进行一致性保证：

1. 主从复制（Master-Slave Replication）：将其中一个节点作为主节点（Master），其他节点作为从节点（Slave），主节点负责写入数据，并将数据同步到从节点，读取请求可以发送到任意一个节点上，但写入请求只能发送到主节点上。
2. 分片（Sharding）：将数据拆分成多个片段，分别保存在不同的节点上，每个节点只负责自己所保存的数据，读写请求也只会发送到相应的节点上。

#### 6、服务器节点如何扩容？

当服务器需要扩容时，可以采用以下两种方案：

1. 水平扩展（Horizontal Scaling）：添加更多的缓存节点，以支持更大的数据存储和更高的并发访问量，这种方式可以采用分片的方式进行扩容。
2. 垂直扩展（Vertical Scaling）：将单个缓存节点升级或替换成更强大的硬件，以提高单个节点的性能和处理能力，这种方式适合于数据访问量较小但需要快速响应的场景。

在扩容过程中，需要考虑新节点与现有节点之间的数据同步和一致性问题，可以采用数据迁移、数据复制等方式进行处理。同时，还需要考虑负载均衡和故障恢复等问题，可以采用HAProxy、Nginx等负载均衡软件进行实现。

#### 7、分布式锁使用场景

分布式锁是一种用于分布式系统中协调多个进程访问共享资源的机制。在分布式环境中，由于多节点同时访问同一个资源，可能会出现数据并发更新问题，因此需要使用分布式锁来保证数据的一致性和正确性。

以下是一些适合使用分布式锁的情景：

1. 秒杀系统：在高并发下，秒杀系统可能会出现超卖或重复下单等问题。使用分布式锁可以保证每个用户只能购买一次，并且库存不会超卖。

2. 订单系统：为了保证订单号的唯一性，通常会使用数据库自增主键或UUID生成器。但在分布式环境中，多个节点同时生成主键或UUID时可能会导致重复。使用分布式锁可以避免这种问题。

3. 数据库操作：在分布式系统中，多个节点同时对同一个数据源进行写操作时，容易出现数据不一致。使用分布式锁可以保证同一时间只有一个节点对该数据源进行写操作。

4. 缓存失效：在分布式缓存中，当多个节点同时请求某个缓存数据并且该数据刚好失效时，就会出现缓存穿透的问题。使用分布式锁可以避免这种问题，保证只有一个节点去加载该数据并放入缓存中。

总之，分布式锁是一种保证分布式系统数据一致性和正确性的重要机制，可以应用于各种场景中。但需要注意使用分布式锁也会带来一些额外的开销，因此需要权衡利弊并合理使用。

#### 8、分布式锁、Java锁和数据库锁的区别

分布式锁、Java中的锁、数据库锁都是用来保护共享资源的机制，但它们有以下几个共同点和区别：

共同点：
1. 保证同一时间只有一个线程(或进程)能够访问共享资源；
2. 都可以解决多线程(或进程)竞争资源导致的数据不一致问题；
3. 都需要考虑死锁和性能问题。

区别：
1. 范围：Java中的锁仅限于同一个JVM中的多个线程之间。而数据库锁和分布式锁可以跨越多个进程或者多个计算机节点之间。
2. 实现：Java中的锁一般是通过synchronized关键字或者Lock接口实现的，而数据库锁是通过数据库自身提供的锁机制实现的。分布式锁通常使用Redis或Zookeeper等分布式存储系统实现。
3. 开销：Java中的锁开销较小，因为它只需要在内存中进行加锁和解锁操作。数据库锁和分布式锁通常需要与外部资源交互，因此开销较大。
4. 适用场景：Java中的锁适用于单机多线程的场景，数据库锁适用于多个进程对同一个数据库中的数据进行操作的场景，而分布式锁适用于多个计算机节点之间共享数据或资源的场景。

总之，不同类型的锁适用于不同的场景，开发者需要根据具体情况选择合适的锁机制来保证数据的一致性和正确性。

#### 9、令牌桶如何实现平滑限流？

令牌桶算法可以通过限制令牌的生成速率和限制每次请求能够消费的令牌数量来实现平滑限流。

具体来说，令牌桶中会以固定的速率生成令牌，并将这些令牌放入到一个桶中。每当有请求到达时，系统会从桶中取出对应数量的令牌进行处理。如果桶中没有足够的令牌，则该请求需要等待直到桶中产生了足够的令牌为止。

这种方式可以有效地控制请求的处理速率，从而实现限流的效果。同时由于令牌桶算法会平稳地生成令牌，因此相比于突发性的限流方式，它可以提供更加平滑的限流效果，避免了一些不必要的浪费和延迟。

[秒杀系统-限流](https://blog.csdn.net/weixin_43519121/article/details/119736971)

https://blog.csdn.net/qq_43703196/article/details/126688590

![img](asset\秒杀流程图.png)

#### 10、分布式锁

分布式锁三种实现方式：

1、基于数据库实现分布式锁；

- 锁表
- 乐观锁
  - 缺点：不适合大量请求，会涉及大量事务回滚从而导致性能瓶颈
- 悲观锁
  - 缺点：要考虑上锁超时所导致的报错问题

2、基于缓存（Redis等）实现分布式锁；

3、基于Zookeeper实现分布式锁。

从性能角度（从高到低）来看：“缓存方式 > Zookeeper方式 >= 数据库方式”。

link: https://www.pdai.tech/md/arch/arch-z-lock.html

[分布式锁的三种实现方式](https://www.php.cn/faq/466231.html)

### MQ

#### 1、RabbitMQ的工作模式

简单模式、Work Queue模式、Pub/Sub模式、Routing模式、Topic模式。

**简单模式**

![image-20230301161515900](asset\简单模式.png)

- P：生产者，也就是要发送消息的程序
- C：消费者：消息的接收者，会一直等待消息到来
- queue：消息队列，图中红色部分。类似一个邮箱，可以缓存消息；生产者向其中投递消息，消费者从其中取出消息

**Work queues 工作队列模式**

![image-20230301161322185](asset\工作队列模式.png)

- **Work Queues：**与入门程序的简单模式相比，多了一个或一些消费端，多个消费端共同消费同一个队列中的消息。

- **应用场景**：对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。

**Pub/Sub模式**

![image-20230301161659697](asset\PubSub模式.png)

在订阅模型中，多了一个 Exchange 角色，而且过程略有变化：

- P：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机）
- C：消费者，消息的接收者，会一直等待消息到来
- Queue：消息队列，接收消息、缓存消息
- Exchange：交换机（X）。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有常见以下3种类型：
  - Fanout：广播，将消息交给所有绑定到交换机的队列
  - Direct：定向，把消息交给符合指定routing key 的队列
  - Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列

**Exchange**（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与 Exchange 绑定，或者没有符合路由规则的队列，那么消息会丢失！

**小结**

1. 交换机需要与队列进行绑定，绑定之后；一个消息可以被多个消费者都收到。

2. 发布订阅模式与工作队列模式的区别：
   - 工作队列模式不用定义交换机，而发布/订阅模式需要定义交换机；
   - 发布/订阅模式的生产方是面向交换机发送消息，工作队列模式的生产方是面向队列发送消息(底层使用默认交换机)；
   - 发布/订阅模式需要设置队列和交换机的绑定，工作队列模式不需要设置，实际上工作队列模式会将队列绑定到默认的交换机。

**Routing模式**

![image-20230301163019630](asset\Routing模式.png)

队列与交换机的绑定，不能是任意绑定了，而是要指定一个 RoutingKey（路由key）；

消息的发送方在向 Exchange 发送消息时，也必须指定消息的 RoutingKey；

Exchange 不再把消息交给每一个绑定的队列，而是根据消息的 Routing Key 进行判断，只有队列的 Routingkey 与消息的 Routing key 完全一致，才会接收到消息。

- P：生产者，向 Exchange 发送消息，发送消息时，会指定一个routing key
- X：Exchange（交换机），接收生产者的消息，然后把消息递交给与 routing key 完全匹配的队列
- C1：消费者，其所在队列指定了需要 routing key 为 error 的消息
- C2：消费者，其所在队列指定了需要 routing key 为 info、error、warning 的消息

**Routing** 模式要求队列在绑定交换机时要指定 **routing key**，消息会转发到符合 routing key 的队列。

**Topic模式**

![image-20230301163745654](asset\Topic模式.png)

Topic 类型与 Direct 相比，都是可以根据 RoutingKey 把消息路由到不同的队列。只不过 Topic 类型 Exchange 可以让队列在绑定 Routing key 的时候使用**通配符**！

Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 

通配符规则：# 匹配一个或多个词，* 匹配不多不少恰好1个词，例如：item.# 能够匹配 item.insert.abc 或者 item.insert，item.* 只能匹配 item.insert。

Topic 主题模式可以实现 Pub/Sub 发布与订阅模式和 Routing 路由模式的功能，只是 Topic 在配置routing key 的时候可以使用通配符，显得更加灵活。

#### 2、消息可靠传递

1. 持久化
   - exchange要持久化
   - queue要持久化
   - message要持久化

2. 生产方确认Confirm

3. 消费方确认Ack

4. Broker高可用

#### 3、死信交换机/队列

1. 死信交换机和死信队列和普通的没有区别

2. 当消息成为死信后，如果该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队列

3. 消息成为死信的三种情况：

   1. 队列消息长度到达限制；

   2. 消费者拒接消费消息，并且不重回队列；

   3. 原队列存在消息过期设置，消息到达超时时间未被消费；

**延迟队列** 指消息进入队列后，可以被延迟一定时间，再进行消费。

在RabbitMQ中并未提供延迟队列功能。但是可以使用：**TTL+死信队列** 组合实现延迟队列的效果。

<img src="asset\rabbit延迟队列.png" alt="image-20230925182727120" style="zoom:80%;" />

#### 4、消息幂等性保证

幂等性指一次和多次请求某一个资源，对于资源本身应该具有同样的结果。也就是说，其任意多次执行对资源本身所产生的影响均与一次执行的影响相同。

在MQ中指，消费多条相同的消息，得到与消费该消息一次相同的结果。

<img src="asset\消息幂等性保障.png" alt="image-20230301113647845" style="zoom:80%;" />

#### 5、Kafka为什么这么快？

kafka的快是从底层设计,到充分利用硬件,系统,压缩等等特性,综合产生的结果。

1. partition 并行处理，写入数据的时候由于单个Partion是末尾添加所以速度最优。
2. 顺序写入，磁盘顺序读写速度超过内存随机读写，充分利用磁盘特性。
3. 批量压缩文件，利用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率。
4. 通过mmap实现顺序的快速写入，提高I/O速度。
5. 读取数据时采用 sendfile，减少 CPU 消耗。

**mmap** 和 **sendfile**

- **Memory Mapped Files** 简称 `mmap`，简单描述其作用就是：`将磁盘文件映射到内存，用户通过修改内存就能修改磁盘文件`。
- Linux 内核提供、实现零拷贝的 API。
- mmap 将磁盘文件映射到内存，支持读和写，对内存的操作会反映在磁盘文件上。
- sendfile 是将读到内核空间的数据，转到 socket buffer，进行网络发送。
- RocketMQ 在消费消息时，使用了 mmap；Kafka 使用了 sendfile。

链接：https://baijiahao.baidu.com/s?id=1710624455165799096&wfr=spider&for=pc

#### 6、延时队列

**什么是延时队列**

[延时队列](https://so.csdn.net/so/search?q=延时队列&spm=1001.2101.3001.7020)相比于普通队列最大的区别就体现在其延时的属性上，普通队列的元素是先进先出，按入队顺序进行处理，而延时队列中的元素在入队时会指定一个延迟时间，表示其希望能够在经过该指定时间后处理。从某种意义上来讲，延迟队列的结构并不像一个队列，而更像是一种以时间为权重的有序堆结构。

**延时队列的应用**

延时队列在项目中的应用还是比较多的，尤其像电商类平台：

- 12306 下单成功后，在半个小时内没有支付，自动取消订单。
- 如果订单一直处于某一个未完结状态时，及时处理关单，并退还库存。
- 淘宝新建商户一个月内还没上传商品信息，将冻结商铺等。
- 会议预定系统，在预定会议开始前半小时通知所有预定该会议的用户。
- 安全工单超过 24 小时未处理，则自动拉企业群提醒相关责任人。
- 用户下单外卖以后，距离超时时间还有 10 分钟时提醒外卖小哥即将超时。
- 外卖平台发送订餐通知，下单成功后 60s 给用户推送短信。

————————————————
原文链接：https://blog.csdn.net/ChineseSoftware/article/details/123330873

#### 7、Kafka如何保证数据的一致性？

Kafka通过以下两种方式来保证数据的一致性：

1. **分区复制**：Kafka将每个主题分成多个分区，每个分区可以有多个副本。当写入数据时，数据首先写入主分区，然后通过Kafka的复制机制将数据复制到所有副本分区。这样可以确保副本中的数据与主分区中的数据一致。

2. **ISR机制**：ISR（In-Sync Replicas）机制是Kafka中用于保证副本分区中的数据与主分区中的数据保持一致的机制。在ISR机制下，只有那些已经与主分区同步的副本才能被认为是有效的副本，而未同步完成的副本则处于不可用状态。只有当所有的ISR副本都成功同步了主分区的数据之后，才会认为该条数据已经被正确提交。[Kafa ISR](https://blog.csdn.net/kiritobryant/article/details/128786174)

综上所述，Kafka通过分区复制和ISR机制来保证数据的一致性，从而保证了数据的可靠性和安全性。同时，Kafka还支持多种配置选项，例如acks参数、min.insync.replicas参数等，可以帮助用户更加精细地控制数据的一致性和可用性。

[Kafka ISR 机制](https://baijiahao.baidu.com/s?id=1766648149810311028&wfr=spider&for=pc)

#### 8、Kafka如何保证数据不丢失？

Kafka通过以下两种方式来保证数据不丢失：

1. 写入数据时的**持久化**：Kafka能够将写入的数据持久化到磁盘上。当写入数据时，Kafka会将数据先写入操作系统的缓存中，然后再异步地将数据持久化到磁盘上。这样即使系统崩溃或者宕机，之前写入的数据也能从磁盘上恢复。

2. **副本机制**：Kafka的分区副本机制可以保证数据不丢失。每个分区可以设置多个副本，当写入数据时，数据会被同时复制到多个副本中。如果某个副本故障，其他副本仍然可以继续提供服务。一旦故障的副本恢复正常，Kafka会自动将其同步回来。

除此之外，Kafka还支持各种配置选项，例如acks参数、replication.factor参数等，可以帮助用户更加精细地控制数据的可靠性和容错能力。总之，Kafka通过强大的持久化和副本机制，确保了数据不丢失的能力。

#### 9、Kafka和RabbitMQ的区别？

Kafka和RabbitMQ是两种不同的消息队列系统，它们有以下几个区别：

1. 架构设计：Kafka采用分治设计，将数据和元数据分开存储，broker只存储数据，而Zookeeper则存储元数据；RabbitMQ则采用集中式架构，将数据和元数据都存储在单个broker上。

2. 消息传递方式：Kafka采用的是pull-based model，即消费者需要从broker中主动拉取数据；RabbitMQ则采用的是push-based model，即当有新消息需要发送时，RabbitMQ会立即将其推送给订阅该队列的消费者。

3. 数据可靠性：Kafka具备高可靠性，能够保证数据不丢失；而RabbitMQ则能够提供数据的可靠性，并支持消息确认和重试等机制。

4. 性能表现：Kafka能够处理大量的消息流，适合实时处理、实时分析等场景。而RabbitMQ则更适合处理少量但更加复杂的消息，适合在企业应用中使用。

5. 编程接口：RabbitMQ提供了各种编程语言的客户端接口，如Java、C#、Python等；而Kafka则主要以Java为主要编程语言，其他语言的客户端接口相对较少。

总体来说，Kafka更加适合在数据流处理、日志收集、实时分析等场景中使用，而RabbitMQ则更适合在企业应用中使用。

**kafka和rabbitmq全面对比分析**

| 对比项                         | kafka                                                        | rabbitmq                                     |
| ------------------------------ | ------------------------------------------------------------ | -------------------------------------------- |
| 开发语言                       | scala,Java                                                   | erlang                                       |
| 是否支持多租户                 | 2.x.x支持多租户                                              | 支持多租户                                   |
| 是否支持topic优先级            | 不支持                                                       | 支持                                         |
| 是否支持消息全局有序           | 不支持                                                       | 支持                                         |
| 是否支持消息分区有序           | 支持                                                         | 支持                                         |
| 是否内置监控                   | 无内置监控                                                   | 内置监控                                     |
| 是否支持多个生产者             | 一个topic支持多个生产者                                      |                                              |
| 是否支持多个消费者             | 一个topic支持多个消费者(一个消费者可消费多个分区，一个分区可被多个消费组消费，但同一消费组内仅能有一个消费者同时消费1个分区) |                                              |
| **是否支持一个分区多个消费者** | 不支持                                                       | 不支持                                       |
| 是否支持JMX                    | 支持                                                         | 不支持(非java语言编写)                       |
| 是否支持加密                   | 支持                                                         | 支持                                         |
| 消息队列协议支持               | 仅支持自定义协议                                             | 支持AMQP、MQTT、STOMP协议                    |
| 客户端语言支持                 | 支持多语言客户端                                             | 支持多语言客户端                             |
| 是否支持消息追踪               | 不支持消息追踪                                               | 支持消息追踪                                 |
| 是否支持消费者推模式           | 不支持消费者推模式                                           | 支持消费者推模式                             |
| 是否支持消费者拉模式           | 支持消费者拉模式                                             | 支持消费者拉模式                             |
| 是否支持广播消息               | 支持广播消息                                                 | 支持广播消息                                 |
| 是否支持消息回溯               | 支持消息回溯，因为消息持久化，消息被消费后会记录offset和timstamp | 不支持，消息确认被消费后，会被删除           |
| 是否支持消息数据持久化         | 支持消息数据持久                                             | 支持消息数据持久                             |
| 是否支持消息堆积               | 支持消息堆积，并批量持久化到磁盘                             | 支持阈值内的消息对接，无法支持较大的消息堆积 |
| 是否支持流量控制               | 支持控制用户和客户端流量                                     | 支持生产者的流量控制                         |
| 是否支持事务性消息             | 支持                                                         | 不支持                                       |
| 元数据管理                     | 通过zookeeper进行管理                                        | 支持消息数据持久                             |
| 默认服务端口                   | 9092                                                         | 5672                                         |
| 默认监控端口                   | kafka web console 9000;kafka manager 9000;                   | 15672                                        |
| 网络开销                       | 相对较小                                                     | 相对较大                                     |
| 内存消耗                       | 相对较小                                                     | 相对较大                                     |
| cpu消耗                        | 相对较大                                                     | 相对较小                                     |

实际场景选择

在实际生产应用中，通常会使用kafka作为消息传输的数据管道，rabbitmq作为交易数据作为数据传输管道，主要的取舍因素则是是否存在丢数据的可能；rabbitmq在金融场景中经常使用，具有较高的严谨性，数据丢失的可能性更小，同事具备更高的实时性；而kafka优势主要体现在吞吐量上，虽然可以通过策略实现数据不丢失，但从严谨性角度来讲，大不如rabbitmq；而且由于kafka保证每条消息最少送达一次，有较小的概率会出现数据重复发送的情况；

> 消息队列中的推拉模式是指消息的消费方式。在推模式中，消息生产者将消息推送到消息队列中，然后消息消费者从队列拉取消息进行消费。在拉模式中，消息消费者主动从消息队列中拉取消息进行消费。
>
> 推模式的优点是实时性好，消息生产者可以立即将消息推送到队列中，消费者可以立即消费。同时，推模式可以减少消息消费者的轮询次数，降低系统的负载。缺点是如果消息生产者生产的消息过多，消费者可能无法及时消费，导致消息积压。
>
> 拉模式的优点是可以根据消费者的实际需求进行消费，避免了消息积压的问题。同时，拉模式可以据消费者的消费能力进行消费，避免了消费者无法及时消费的问题。缺点是消费者需要不断地轮询消息队列，增加了系统的负载。
>
> 综合来看，推模式适用于实时性要求高的场景，例如在线聊天实时监控等。拉模式适用于消费者消费能力不确定的场景，例如批量处理、离线计算等。
>
> 在实际应用中，可以根据具体的业务需求选择合适的消息消费方式。同时，也可以结合推拉模式，例如在消息生产者将消息推送到队列中后，消费者可以使用长轮询的方式进行拉取，以实现更好的实时性和消费能力。

————————————————

原文链接：https://blog.csdn.net/myhes/article/details/83247108

---

Kafka是一种分布式流式数据处理平台，其体现在以下几个方面：

1. 数据持久化与发布订阅模型：Kafka提供可持久化的消息存储，并且以发布-订阅模型进行数据传输。它使得数据可以被持久化保存，并能够被多个消费者组订阅和并行处理。

2. 实时流式数据处理：Kafka支持高吞吐量和低延迟的消息传递，可以实现实时的流式数据处理。生产者可以将数据实时写入Kafka，而消费者可以立即接收、处理和分析这些数据。这种实时性使得Kafka非常适合构建实时数据流处理应用。

3. 消息流式处理：Kafka的设计理念是将数据流看作是连续的消息流。数据以多个分区的形式进行分片存储，每个分区都有一个顺序的消息日志。消费者可以以流的方式从分区中读取并处理消息，实现了对大规模消息流的高效处理。

4. 可水平扩展性：Kafka采用分布式架构，可以通过增加更多的Broker节点来实现水平扩展。这使得Kafka能够处理大规模的数据流，并且具有高容错性和高可用性。

5. 丰富的流处理生态系统：Kafka不仅仅是一个消息队列系统，还与流处理框架（如Apache Flink、Apache Samza等）和批处理框架（如Apache Spark）等集成，提供了完整的流式数据处理生态系统。

综上所述，Kafka作为一种流式数据处理平台，通过持久化数据、发布订阅模型、实时性、消息流式处理、可扩展性和丰富的生态系统等特点，使得它成为处理大规模实时数据流的理想选择。

#### 10、RabbitMQ防止消息重复消费

重复投递的原因：等待超时后需要重试

避免重复投递:：消息生产时，生产者发送的消息携带一个 Message ID(全局唯一 ID)作为去重和幂等的依据，避免重复的消息进入队列

重复消费的原因：消费者接收消息后，在确认之前断开了连接或者取消订阅消息会被重新分发给下一个订阅的消费者

避免重复消费：消息消费时，要求消息体中必须要有一个全局唯一 ID，作为去重和幂等的依据，避免同一条消息被重复消费。

---

**实现：**

在 RabbitMQ 中，可以通过设置消息的属性来携带唯一 ID。具体实现方法如下：

1. 在发送消息时，为消息设置一个唯一的 ID。可以使用 UUID 作为 ID，确保唯一性。

```java
String messageId = UUID.randomUUID().toString();
Message message = MessageBuilder
        .withBody(message.getBytes())
        .setHeader("messageId", messageId)
        .build();
rabbitTemplate.convertAndSend(exchange, routingKey, message);
```

2. 在消费者端，判断是否处理过相同 ID 的消息。可以借助 Redis 等缓存数据库记录已处理过的消息 ID，每次接收到新消息时，先查询缓存中是否存在相同 ID 的消息。

```java
@RabbitListener(queues = "myQueue")
public void handleMessage(Message message) {
    String messageId = message.getMessageProperties().getHeaders().get("messageId").toString();
    if (redisTemplate.opsForValue().setIfAbsent(messageId, "1")) {
        // 处理消息
    } else {
        // 已经处理过相同 ID 的消息，不再重复处理
    }
}
```

以上代码使用了 Spring Boot 和 Spring AMQP 提供的相关 API，需要在项目中引入相应的依赖。同时，还需要配置 RabbitMQ 连接信息、Redis 连接信息等相关参数。

#### 11、消息队列对比和技术选型

- 日志处理、大数据处理等场景，高吞吐量、低延迟的特性考虑，Kafka依旧是一个较好的选型。
- 针对业务交易数据，有延迟消息、队列模式消费、异地容灾，多消息主题等场景，可以选用TDMQ/Pulsar。
- 其他一些业务自定义的使用场景，由于后台技术栈是Golang，可以考虑采用NSQ进行定制开发或研究学习。
- 消息中间件性能跟服务端、客户端参数、使用场景等方面上有很大关系，在系统上线前，还需要根据实际应用场景进行压测调优。

<img src="asset\主流MQ对比.png" alt="image-20230925182212899" style="zoom:80%;" />

![img](asset\消息队列对比.png)

[消息队列选型全方位对比](https://zhuanlan.zhihu.com/p/508717798)

### Zookeeper

#### 1、Zookeeper特点

1. **顺序一致性**： 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。
2. **原子性**： 一次数据更新要么成功（标志：半数以上节点成功），要么失败，不存在中间状态。
3. **可靠性**： 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖（服务器保存了消息，那么它就一直都存在）。
4. **最终一致性：**客户端看到的数据最终是一致的。

---

**顺序写**

集群中一写多读。所有写请求都会分配一个 zk 集群全局的唯一递增编号，zxid。Zxid是64位:高 32位是leader 届数，低32位是请求的自增长编号。保证各种客户端发起的写请求都是有顺序的。

**数据一致性**

任何一台 zk 机器收到了写请求之后都会同步给其他机器，保证数据的一致性。使用 Zab 协议作节点之问数据同步，2PC 过半写机制。“

**高性能**

纯内存的数据结构 znode，2PC 中的过半写机制。所以 zk 集群绝对是高并发高性能的，如果你让 zk 部署在高配置物理机上，一个 3 台机器的 zk 集群抗下每秒几万请求没有问题。

**高可用**
只要集群中挂掉不超过一半的机器，都能保证可用，数据不会丢失。“

follower 宕机没影响，leader 宕机有数据不一致问题，新选举的 leader 会自动处理，正常运行。但是在恢复模式期间，可能有一小段时间是没法写入 zk 的。

**高并发**

高性能决定的，基于纯内存数据结构来处理，并发能力是很高的。

写，只有 leader 进行写，但是高配置的物理机，比如 16核 32G，写入几万QPS。

读，所有机器都可以读，3 台机器的话，起码可以支撑十几万 QPS。bserver可以线性扩展。

#### 2、Zab协议

**Zab一致性协议**

ZK专门设计了ZAB协议(Zookeeper Atomic Broadcast)来保证主从节点数据的一致性。下面分别从client向Leader和Follower写数据场景展开陈述。

**写 Leader场景数据一致性**

![img](https://pic2.zhimg.com/80/v2-d53d50a73915168c2204622817f19809_720w.webp)

1. 客户端向 Leader 发起写请求 ；
2. Leader 将写请求以 Proposal 的形式发给所有 Follower 并等待 ACK ；
3. Follower 收到 Leader 的 Proposal 后返回 ACK ；
4. Leader 得到过半数的 ACK（Leader 对自己默认有一个 ACK）后向所有的 Follower 和 Observer 发送 Commmit ；
5. Leader 将处理结果返回给客户端。

**注意**：Leader不需要得到所有Follower的ACK，只要收到过半的ACK即可，同时Leader本身对自己有一个ACK。上图中有4个Follower，只需其中两个返回ACK即可，因为(2+1) / (4+1) > 1/2 - Observer虽然无投票权，但仍须同步Leader的数据从而在处理读请求时可以返回尽可能新的数据。

> 在ZooKeeper的两阶段提交中，第一阶段是提案阶段，主要目的是将提案发送给所有的follower节点。在这个阶段，发送的提案除了zxid之外，还包括数据。具体来说提案中包含了要进行的操作类型（例如创建、更新或删除节点）、节点路径以及节点数据等信息。
>
> 在接收到提案后，follower节点会将提案中的数据写入到本地的内存中，但是并不会将数据写入到磁盘中。这是因为在第一阶段中，follower节点并没有对提案进行投票，因此还不能确定这个提案是否会被最终提交。只有在第二阶段中，当follower节点收到了大多数节点的投票，并且确定要提交这个提案时，才会将数据写入到磁盘中。
>
> 总之，在zookeeper的两阶段提交中，第一阶段的提案阶段中，follower节点会将提案中的数据写入到内存中，但是并不会将数据写入到磁盘中。只有在第二阶段中，当follower节点确定要提交这个提案时，才会将数据写入到磁盘中。

**写 Follower场景数据一致性**

![img](https://pic4.zhimg.com/80/v2-1970ace30458f97795f7e10adac924d3_720w.webp)

1. 客户端向 Follower 发起写请求， Follower将写请求转发给 Leader 处理； 
2. 其它流程与直接写 Leader 无任何区别。

**注意**：Observer 与 Follower 写流程相同

**最终一致性**

Zab 协议消息广播使用两阶段提交的方式，达到主从数据的最终一致性。为什么是最终一致性呢？从上文可知数据写入过程核心分成下面两阶段： 

- 第一阶段：Leader 数据写入事件作为提案广播给所有 Follower 结点；可以写入的Follower结点返回确认信息 ACK。 
- 第二阶段：Leader 收到一半以上的 ACK 信息后确认写入可以生效，向所有结点广播 COMMIT 将提案生效。

根据写入过程的两阶段的描述，可以知道 ZooKeeper 保证的是最终一致性，即 Leader 向客户端返回写入成功后，可能有部分 Follower 还没有写入最新的数据，所以是最终一致性。

ZooKeeper 保证的最终一致性也叫顺序一致性，即每个结点的数据都是严格按事务的发起顺序生效的。ZooKeeper 集群的写入是由 Leader 结点协调的，真实场景下写入会有一定的并发量，那 Zab 协议的两阶段提交是如何保证事务严格按顺序生效的呢？ZK事物的顺序性是借助上文中的Zxid实现的。Leader 在收到半数以上 ACK 后会将提案生效并广播给所有 Follower 结点，Leader 为了保证提案按 ZXID 顺序生效，使用了一个 ConcurrentHashMap，记录所有未提交的提案，命名为 outstandingProposals，key 为 ZXID，Value 为提案的信息。对 outstandingProposals 的访问逻辑如下： 

1. Leader 每发起一个提案，会将提案的 ZXID 和内容放到 outstandingProposals 中，作为待提交的提案； 
2. Leader 收到 Follower 的 ACK 信息后，根据 ACK 中的 ZXID 从 outstandingProposals 中找到对应的提案，对 ACK 计数; 
3. 执行 tryToCommit 尝试将提案提交：判断流程是，先判断当前 ZXID 之前是否还有未提交提案，如果有，当前提案暂时不能提交；再判断提案是否收到半数以上 ACK，如果达到半数则可以提交；如果可以提交，将当前 ZXID 从 outstandingProposals 中清除并向 Followers 广播提交当前提案；

Leader 是如何判断当前 ZXID 之前是否还有未提交提案的呢？由于前提是保证顺序提交的，所以 Leader 只需判断 outstandingProposals 里，当前 ZXID 的前一个 ZXID 是否存在。代码如下：

<img src="https://pic1.zhimg.com/80/v2-a56ae3abe1d2f8332f7d2f7525c92bd0_720w.webp" alt="img" style="zoom:80%;" />

所以 ZooKeeper 是**通过两阶段提交保证数据的最终一致性，并且通过严格按照 ZXID 的顺序生效提案保证其顺序一致性的**。

#### 3、Zookeeper如何保证数据不丢失（持久化）？

zookeeper的数据在内存中是以树形结构的datatree形式存在的，采用了两种方式进行数据的持久化，一种是定期的snapshot；一种是增量事务日志txnlog；

<img src="asset\zookeeper日志持久化.png" alt="img" style="zoom:80%;" />

**snapshot**：记录了整个内存中的数据，即datatree的序列化；

**txnlog**：实时记录了所有访问zookeeper的事务请求，包括create、setdata、setacl、delete等等操作；

**如何保证数据不丢失？**

在zookeeper客户端请求zookeeper服务中，zookeeper的服务端首先是判断这个请求是否是事务请求，如果是事务请求，那么zookeeper服务端首先将这个请求记录在增量事务日志中，保证了其持久化，然后再进行更新内存数据datatree；在这个过程中，它也会去判断是否生成snapshot，如果要生成snapshot，那么就创建一个新的线程去干snapshot的事情；

**如何快速的加载数据，恢复应用服务？**

由于snapshot是定期生成的，所以它的数据可能不是最新的数据，如果我们只加载这个数据，难免会有漏数据，所以在zookeeper重启后，它会先去找到最新且合法的snapshot，这里有一个合法，其实就是校验其文件的完整性；加载完了之后，其实就是加载了zookeeper的一大部分数据，这时候会返回当前处理的最新的zxid，然后去增量事务日志中，找到大于等于zxid+1的事务记录，这样从这个记录开始，直至读取到文件结束，其实就完成了快速的加载数据。

**如何保证单节点故障，不影响数据丢失呢？**

zookeeper服务会在事务请求的时候，将事务请求转发给每一个参与决议的节点，即leader和follower，然后收到半数以上的返回后，才会更新自己的数据，紧接着才会返回给客户端响应；也就是在这个过程中一定有半数以上的节点完成了数据的持久化，这样解决了单节点故障，不丢失数据；

**[总结](https://link.zhihu.com/?target=https%3A//coding.imooc.com/class/361.html%3Fmc_marking%3D4f1d92ae1ae1cda712217fef16823dbd%26mc_channel%3Dshouji)**

其实[zookeeper的这种持久化方案](https://link.zhihu.com/?target=https%3A//coding.imooc.com/class/361.html%3Fmc_marking%3D4f1d92ae1ae1cda712217fef16823dbd%26mc_channel%3Dshouji)，在很多基础组件中都是如此的，比如很多数据库的持久化方案等等；所以知晓这种方案，也可以举一反三，希望这些知识对大家后续的工作中有所帮助！

#### 4、Zookeeper是最终一致性还是强一致性？

最终一致性:写入一条数据，方法返回，告诉你写入成功了，此时你立马去其他 zk 机器上查有可能是查不到的，短暂时间是不一致的。

但是过一会儿，最终一定会让其他机器同步这条数据，最终是可以查到的。

研究了 ZooKeeper 的 ZAB 协议之后，你会发现，其实过半 follower 对事务proposal 返回 ack，就会发送 commit 给所有 follower，只要 follower 或者 leader 进行了 commit，这个数据就会被客户端读取到了。

那么有没有可能，此时有的 follower 已经 commit 了，但是有的 follower还没有 commit？绝对会的，所以有可能某个客户端连接到 follower01，可以读取到刚 commit的数据，但是有的客户端连接到 follower02 在这个时间还没法读取到。

所以 zk 不是强一致的，不是说 leader 必须保证一条数据被全部 follower都 commit 了才会让你读取到数据，而是过程中可能你会在不同的 follower上读取到不一致的数据，但是最终一定会全部 commit 后一致，让你读到一致的数据的。

zk官方给自己的定义：**顺序一致性**

虽然 zk 本质上是最终一致性，但是他比最终一致性更好一点，所以面试的时候要说是 顺序一致性，因为 leader 一定会保证所有的 proposal 同步到follower 上 都是按照顺序来走的，起码顺序不会乱。

如果要求强一致性，可以手动调用 zk 的 **sync()** 操作。

#### 5、Zookeeper数据不一致问题

还是会存在的，我们可以分成3个场景来描述这个问题。

**查询不一致**

因为Zookeeper是过半成功即代表成功，假设我们有5个节点，如果123节点写入成功，如果这时候请求访问到4或者5节点，那么有可能读取不到数据，因为可能数据还没有同步到4、5节点中，也可以认为这算是数据不一致的问题。

解决方案可以在读取前使用 sync 命令。

**leader未发送proposal宕机**

这也就是数据同步说过的问题。

leader刚生成一个proposal，还没有来得及发送出去，此时leader宕机，重新选举之后作为follower，但是新的leader没有这个proposal。

这种场景下的日志将会被丢弃。

**leader发送proposal成功，发送commit前宕机**

如果发送proposal成功了，但是在将要发送commit命令前宕机了，如果重新进行选举，还是会选择zxid最大的节点作为leader，因此，这个日志并不会被丢弃，会在选举出leader之后重新同步到其他节点当中。
————————————————
原文链接：https://blog.csdn.net/weixin_44295960/article/details/114694446

### Netty

Netty经典32连问：https://mp.weixin.qq.com/s/iMEgT4GPtl12gAcUN16-Yw

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230605162450251.png" alt="image-20230605162450251" style="zoom: 80%;" />

#### 1、IO分类

应用程序想要去读取数据，他是无法直接去读取磁盘数据的，他需要先到内核里边去等待内核操作硬件拿到数据，这个过程就是1;

等到内核从磁盘上把数据加载出来之后，再把这个数据写给用户的缓存区，这个过程是2。

<img src="asset\IO.png" alt="1653897115346" style="zoom:80%;" />

**阻塞IO（Blocking IO）**

同步阻塞IO模式，数据的读取和写入必须阻塞在一个线程内等待其完成。

<img src="asset\BIO.png" alt="1653897270074" style="zoom:80%;" />

**非阻塞IO（Nonblocking IO）**

NIO是一种同步非阻塞的IO模型，应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询(polling)。

由于 CPU 要处理更多的系统调用，因此这种模型是比较低效的。

<img src="asset\NIO.png" alt="1653897490116" style="zoom:80%;" />

**IO多路复用（IO Multiplexing）**

无论是阻塞IO还是非阻塞IO，用户应用在一阶段都需要调用recvfrom来获取数据，差别在于无数据时的处理方案：

- 如果调用recvfrom时，恰好没有数据，阻塞IO会使CPU阻塞，非阻塞IO使CPU空转，都不能充分发挥CPU的作用。
- 如果调用recvfrom时，恰好有数据，则用户进程可以直接进入第二阶段，读取并处理数据

当用户去读取数据的时候，不再去直接调用recvfrom了，而是调用select的函数，select函数会将需要监听的数据交给内核，由内核去检查这些数据是否就绪了，如果说这个数据就绪了，就会通知应用程序数据就绪，然后来读取数据，再从内核中把数据拷贝给用户态，完成数据处理，如果N多个FD一个都没处理完，此时就进行等待。

它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。

<img src="asset\IO多路复用.png" alt="1653898691736" style="zoom:80%;" />

IO多路复用是利用单个线程来同时监听多个FD，并在某个FD可读、可写时得到通知，从而避免无效的等待，充分利用CPU资源。

**信号驱动IO（Signal Driven IO）**

应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。

相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。

<img src="asset\信号驱动IO.png" alt="1653911776583" style="zoom:80%;" />

当有大量IO操作时，信号较多，SIGIO处理函数不能及时处理可能导致信号队列溢出，而且内核空间与用户空间的频繁信号交互性能也较低。

**异步IO（Asynchronous IO）**

异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。

进行 aio_read 系统调用会立即返回，应用进程继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。

这种方式，不仅仅是用户态在试图读取数据后，不阻塞，而且当内核的数据准备完成后，也不会阻塞。

他会由内核将所有数据处理完成后，由内核将数据写入到用户态中，然后才算完成，所以性能极高，不会有任何阻塞，全部都由内核完成，可以看到，异步IO模型中，用户进程在两个阶段都是非阻塞状态。

异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。

<img src="asset\异步IO.png" alt="1653911877542" style="zoom:80%;" />

**总结：**

- 同步 I/O: 应用进程在调用 recvfrom 操作时会阻塞。
- 异步 I/O: 不会阻塞。

阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，虽然非阻塞式 I/O 和信号驱动 I/O 在等待数据阶段不会阻塞，但是在之后的将数据从内核复制到应用进程这个操作会阻塞。

前四种 I/O 模型的主要区别在于第一个阶段，而第二个阶段是一样的: 将数据从内核复制到应用进程过程中，应用进程会被阻塞。

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/java/io/java-io-model.html

#### 2、Netty的优点

- 比直接使用 JDK 自带的 NIO 相关的 API 来说更加易用。
- 统一的 API，支持多种传输类型，阻塞和非阻塞的。
- 简单而强大的线程模型。
- 自带编解码器解决 TCP 粘包/拆包问题。
- 自带各种协议栈。
- 真正的无连接数据包套接字支持。
- 比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。
- 安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。
- 社区活跃
- 成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。
- ......

#### 3、Netty的应用场景

理论上来说，NIO 可以做的事情 ，使用 Netty 都可以做并且更好。Netty 主要用来做网络通信 :

1. **作为 RPC 框架的网络通信工具** ： 我们在分布式系统中，不同服务节点之间经常需要相互调用，这个时候就需要 RPC 框架了。不同服务节点的通信是如何做的呢？可以使用 Netty 来做。比如我调用另外一个节点的方法的话，至少是要让对方知道我调用的是哪个类中的哪个方法以及相关参数吧！
2. **实现一个自己的 HTTP 服务器** ：通过 Netty 我们可以自己实现一个简单的 HTTP 服务器，这个大家应该不陌生。说到 HTTP 服务器的话，作为 Java 后端开发，我们一般使用 Tomcat 比较多。一个最基本的 HTTP 服务器可以处理常见的 HTTP Method 的请求，比如 POST 请求、GET 请求等等。
3. **实现一个即时通讯系统** ： 使用 Netty 我们可以实现一个可以聊天类似微信的即时通讯系统，这方面的开源项目还蛮多的，可以自行去 Github 找一找。
4. **实现消息推送系统** ：市面上有很多消息推送系统都是基于 Netty 来做的。
5. ......

#### 4、那些开源框架用到了Netty？

我们平常经常接触的 Dubbo、RocketMQ、Elasticsearch、gRPC 等等都用到了 Netty。

可以说大量的开源项目都用到了 Netty，所以掌握 Netty 有助于你更好的使用这些开源项目并且让你有能力对其进行二次开发。

#### 5、连接假死如何处理？

**出现原因：**

连接假死是如何出现的呢？可能存在以下几种情况：

1）网络设备出现故障。例如网卡，机房等，底层的 TCP 连接已经断开了，但应用程序没有感知到，仍然占用着资源。

2）公网网络不稳定，出现丢包。如果连续出现丢包，这时现象就是客户端数据发不出去，服务端也一直收不到数据，进程一直占据资源，耗在这儿。

3）应用程序线程阻塞，无法进行数据读写。

连接假死会产生以下问题：

1）假死的连接占用的资源不能自动释放。

2）向假死的连接发送数据，得到的反馈是发送超时。

**如何解决：**

Netty提供了一个叫做IdleStateHandler的处理器，用来进行空闲检测。

其实现方式是：

> 当Channel有一段时间没有执行读、写或两者操作时触发IdleStateEvent。

有三个主要参数：

- readerIdleTime：一个IdleStateEvent，其状态是IdleState.READER_IDLE时的指定时间段内，没有执行读操作将被触发。 指定0以禁用。
- writerIdleTime：一个IdleStateEvent，其状态是IdleState.WRITER_IDLE时的指定时间段内，没有执行写操作将被触发。 指定0以禁用。
- allIdleTime：一个IdleStateEvent，其状态是IdleState.ALL_IDLE时的指定时间段内，没有进行读取和写入都将被触发。 指定0以禁用

比较好的处理方式，需要结合业务区考虑，没有消息读取并不代表连接存在问题，可以使用下面的方式，**心跳检测**：

客户端：当检测到没有数据写入时，可以定时向服务端发送心跳，比如每5秒就向服务端写入一次数据。这个时间要小于服务器设置的检测时间。

服务端：设置一个定时读取的检测时间，比如8秒，这样在8秒内，一定会受到客户端的心跳，如果超过8秒没有心跳，则可以认为连接出现问题，可以关闭channel。

链接：https://www.jianshu.com/p/86bac0c9da5a

#### 6、Netty中的时间轮

TimeWheel 算法稍微有点抽象，是一种实现延迟队列的巧妙且高效的算法，被应用在 Netty，Zookeeper，Kafka 等各种框架中。下边主要实践 Netty 的延时队列讲一下时间轮是什么原理。

![img](asset\时间轮.png)

wheel ：时间轮，图中的圆盘可以看作是钟表的刻度。比如一圈 round 长度为 24 秒，刻度数为 8，那么每一个刻度表示 3 秒。那么时间精度就是 3 秒。时间长度/刻度数值越大，精度越大。

当添加一个定时、延时任务 A，假如会延迟 25 秒后才会执行，可时间轮一圈 round 的长度才 24 秒，那么此时会根据时间轮长度和刻度得到一个圈数 round 和对应的指针位置 index，也是就任务 A 会绕一圈指向 0 格子上，此时时间轮会记录该任务的 round 和 index 信息。当 round=0，index=0 ，指针指向 0 格子任务 A 并不会执行，因为 round=0 不满足要求。

所以每一个格子代表的是一些时间，比如 1 秒和 25 秒都会指向 0 格子上，而任务则放在每个格子对应的链表中，这点和HashMap的数据有些类似。

Netty 构建延时队列主要用 HashedWheelTimer，HashedWheelTimer 底层数据结构依然是使用 DelayedQueue，只是采用时间轮的算法来实现。
————————————————
原文链接：https://blog.csdn.net/ChineseSoftware/article/details/123330873

#### 7、NIO

NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。

NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。

通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。

因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件具有更好的性能。

应该注意的是，只有套接字 Channel 才能配置为非阻塞，而 FileChannel 不能，为 FileChannel 配置非阻塞也没有意义。

<img src="asset\selector" alt="image" style="zoom:80%;" />

I/O 与 NIO 最重要的区别是数据打包和传输的方式，I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。

面向流的 I/O 一次处理一个字节数据: 一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 I/O 通常相当慢。

面向块的 I/O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。

I/O 包和 NIO 已经很好地集成了，java.io.* 已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。例如，java.io.* 包中的一些类包含以块的形式读写数据的方法，这使得即使在面向流的系统中，处理速度也会更快。

------

**NIO如何提升效率？**

NIO（New I/O）与传统的I/O（旧的I/O）相比，其主要提升了效率和可扩展性。下面是NIO如何实现这些功能的一些主要特点：

1. 非阻塞I/O：NIO使用非阻塞I/O模型，它允许一个线程来处理多个通道，而不需要为每个连接创建一个新的线程。因此，NIO可以更有效地使用系统资源。

2. 缓存I/O：缓存I/O提高了I/O操作的效率，因为数据可以在内存中缓存，避免了频繁的磁盘I/O操作。NIO通过使用缓存区来实现缓冲I/O操作。

3. 选择器：NIO提供了选择器（Selector），可以用来管理多个通道。选择器在单个线程中处理多个通道的I/O操作，从而使得线程可以同时监听多个通道上的事件，进一步提升了I/O操作的效率。

4. 内存映射文件：NIO还支持内存映射文件，将文件映射到内存中，以便快速读取文件数据，避免了频繁的磁盘I/O操作。

总之，NIO通过非阻塞I/O、缓存I/O、选择器和内存映射文件等机制，优化了I/O操作的效率和可扩展性，使得程序可以更加高效地处理大量的并发连接。

著作权归@pdai所有 原文链接：https://pdai.tech/md/java/io/java-io-nio.html

#### 8、Reactor线程模型

常见的 Reactor 实现方案有三种。

第一种方案单 Reactor 单进程 / 线程，不用考虑进程间通信以及数据同步的问题，因此实现起来比较简单，这种方案的缺陷在于无法充分利用多核 CPU，而且处理业务逻辑的时间不能太长，否则会延迟响应，所以不适用于计算机密集型的场景，适用于业务处理快速的场景，比如 Redis（6.0之前 ） 采用的是单 Reactor 单进程的方案。

第二种方案单 Reactor 多线程，通过多线程的方式解决了方案一的缺陷，但它离高并发还差一点距离，差在只有一个 Reactor 对象来承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。

第三种方案多 Reactor 多进程 / 线程，通过多个 Reactor 来解决了方案二的缺陷，主 Reactor 只负责监听事件，响应事件的工作交给了从 Reactor，Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案，Nginx 则采用了类似于 「多 Reactor 多进程」的方案。

Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」。

因此，真正的大杀器还是 Proactor，它是采用异步 I/O 实现的异步网络模型，感知的是已完成的读写事件，而不需要像 Reactor 感知到事件后，还需要调用 read 来从内核中获取数据。

不过，无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 Reactor 模式是基于「待完成」的 I/O 事件，而 Proactor 模式则是基于「已完成」的 I/O 事件。

链接：https://xiaolincoding.com/os/8_network_system/reactor.html

链接：https://blog.csdn.net/zhumengguang/article/details/125022723

#### 9、Netty的零拷贝

维基百科是这样介绍零拷贝的:

`零复制(英语: Zero-copy;也译零拷贝)技术是指计算机执行操作时，CPU 不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省 CPU 周期和内存带宽`

在OS 层面上的 Zero-copy 通常指避免在 用户态(User-space) 与 内核态(Kernel-space) 之间来回拷贝数据。而在 Netty 层面，零拷贝主要体现在对于数据操作的优化.

Netty 中的零拷贝体现在以下几个方面：

1、堆外内存，避免JVM 堆内存到堆外内存的数据拷贝

2、使用Netty 提供的 ompositeByteBuf 类可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了冬个 ByteBuf 之间的拷贝。

3、通过 Unpooled.wrappedBuffer 可以将 byte 数组包装成 ByteBuf 对象，包装过程中不会产生内存拷贝。

4、ByteBuf 支持 slice 操作,因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf,避免了内存的拷贝。

5、通过 FileRegion 包装的 FileChannel#tranferTo() 实现文件传输,可以直接将文件缓冲区的数据发送到目标 channel，避免了传统通过循环 write 方式导致的内存拷贝问题。

[Netty 中的零拷贝机制](https://baijiahao.baidu.com/s?id=1750269996376465605&wfr=spider&for=pc)

### RPC

#### 1、评价一个RPC框架的好坏标准有哪些？

评价一个RPC框架好坏的标准有以下几个：

1. 性能：RPC框架本身需要具备高性能、低延迟、高吞吐量等特点，能够满足实际业务需求。

2. 可靠性：RPC框架需要支持服务发现、容错机制、数据一致性、故障恢复等功能，保证系统的可用性和稳定性。

3. 扩展性：RPC框架应该具备良好的扩展性，能够方便地扩展新协议、新序列化方式、新负载均衡算法等。

4. 易用性：RPC框架需要提供简洁易用的API和文档，让开发者能够快速上手并使用。

5. 兼容性：RPC框架需要兼容不同的编程语言和平台，使得不同技术栈的系统可以互相调用。

6. 安全性：RPC框架需要提供安全认证、加密传输等安全措施，防止数据泄漏和攻击。

7. 社区活跃度：RPC框架需要有活跃的社区支持，及时修复bug、提供新功能和文档，保持框架的长期维护和发展。

#### 2、HTTP和RPC

HTTP和RPC都是在分布式系统中进行网络通信的协议，但它们之间存在一些区别。

1. 设计目的不同：HTTP是为了支持Web应用程序而设计的，它采用文本格式传输数据，主要用于信息交互和资源访问。RPC则是为了解决跨进程或跨网络调用的问题而设计的，主要用于服务调用和远程过程执行。

2. 传输数据格式不同：HTTP使用文本格式（如JSON、XML等）传输数据，RPC则使用二进制格式（如Protobuf、Thrift等）传输数据，二进制格式具有更高的效率和可扩展性。

3. 通信方式不同：HTTP采用请求响应模式，客户端向服务器发送请求，服务器返回响应；RPC可以采用请求响应模式，也可以采用双向通信模式，支持异步调用和流式传输等特性。

4. 应用场景不同：HTTP适用于面向用户的Web应用程序，RPC适用于面向服务的分布式系统，例如微服务架构。

5. 部署方式不同：因为HTTP是基于Web的协议，所以它天然地支持通过Web服务器进行负载均衡和反向代理；而RPC需要使用专门的框架和组件来支持负载均衡和服务发现，例如Nacos、Consul等。

总之，HTTP和RPC都是分布式系统中常用的协议，它们各有优缺点，需要根据具体应用场景进行选择。

更多：https://www.nowcoder.com/discuss/477533661760397312?sourceSSR=users

​		[为什么有了http，还需要rpc？](https://xiaolincoding.com/network/2_http/http_rpc.html)

#### 3、一致性哈希

不同的负载均衡算法适用的业务场景也不同的。

轮询这类的策略只能适用与每个节点的数据都是相同的场景，访问任意节点都能请求到数据。但是不适用分布式系统，因为分布式系统意味着数据水平切分到了不同的节点上，访问数据的时候，一定要寻址存储该数据的节点。

哈希算法虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。

为了减少迁移的数据量，就出现了一致性哈希算法。

一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。

但是一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应。

为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。

引入虚拟节点后，可以会提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。

---

一致性哈希算法和普通的哈希算法有以下区别：

1. 哈希算法：
   - 普通的哈希算法将输入数据通过哈希函数映射到一个固定的哈希空间，通常用于散列函数或数据摘要计算。哈希算法的结果是不可预测的，且不保证分布均匀。

2. 一致性哈希算法：
   - 一致性哈希算法将哈希空间组织成一个哈希环，并将数据和节点都映射到该环上。数据被映射到环上的一个位置，然后顺时针寻找第一个遇到的节点作为数据的存储节点。**一致性哈希算法保证在节点数量变动时，大部分数据仍能映射到同一节点。**

应用场景方面，两者也有一些区别：

1. 普通哈希算法适用于：
   - 数据分片：当需要将数据分散到多个存储节点时，可以使用普通哈希算法进行哈希分片，确保数据在各节点之间均匀分布。

2. 一致性哈希算法适用于：
   - 缓存和负载均衡：一致性哈希算法在构建缓存系统或负载均衡器时非常有用。它可以确保在节点增加或减少时，只有部分数据需要迁移，降低了系统的维护成本。
   - 分布式存储：一致性哈希算法可以用于分布式存储系统中，通过将数据映射到节点来实现数据的平衡和可扩展性。

总之，普通的哈希算法主要用于数据分片，而一致性哈希算法更适用于缓存、负载均衡和分布式存储等场景，可以提供更好的可扩展性和容错性。根据具体的需求和应用场景，选择适当的哈希算法可以提高系统的效率和性能。

#### 4、序列化算法对比

<img src="asset\序列化反序列化.png" alt="image-20220702131833644" style="zoom:80%;" />

**判断一个序列化算法好坏的标准：**

1. 是否支持跨语言，支持语种是否丰富 

2. 编码后的码流 

3. 编解码的**性能** 
   1. 序列化后的二进制序列大小。
   2. 序列化，反序列化的速率。

4. 类库是否小巧，API使用是否方便 

5. 使用者开发的工作量和难度。

**JDK、JSON、HESSIAN、KRYO 、PROTOSTUFF**，其中JSON使用的是Gson实现，此外还可以使用FastJson、Jackson等实现JSON序列化。

五种序列化算法的比较如下：

| 序列化算法     | **优点**                 | **缺点**         |
| -------------- | ------------------------ | ---------------- |
| **Kryo**       | 速度快，序列化后体积小   | 跨语言支持较复杂 |
| **Hessian**    | 默认支持跨语言           | 较慢             |
| **Protostuff** | 速度快，基于protobuf     | 需静态编译       |
| **Json**       | 使用方便                 | 性能一般         |
| **Jdk**        | 使用方便，可序列化所有类 | 速度慢，占空间   |

性能对比图，单位为 nanos：

![序列化性能比较图](asset\序列化性能比较.png)

项目测试：

> /*
>  \* JDK          369B
>  \* JSON         156B
>  \* HESSIAN      226B
>  \* KRYO         99B
>  \* PROTOSTUFF   144B
>  */
>
> RpcMessage(MessageHeader, Object)

**其他比较**

1. Hessian使用固定长度存储int和long，而kryo使用变长的int和long保证这种基本数据类型序列化后尽量小，实际应用中，很大的数据不会经常出现。

2. Kryo进行序列化的时候，需要传入完整类名或者利用 register() 提前将类注册到Kryo上，其类与一个int型的ID相关联，序列中只存放这个ID，因此序列体积就更小，而Hessian则是将所有类字段信息都放入序列化字节数组中，直接利用字节数组进行反序列化，不需要其他参与，因为存的东西多处理速度就会慢点。

3. Kryo使用不需要实现Serializable接口，Hessian则需实现。

4. Kryo数据类的字段增、减，序列化和反序列化时无法兼容，而Hessian则兼容，Protostuff是只能在末尾添加新字段才兼容。

5. Kryo和Hessian使用涉及到的数据类中必须拥有无参构造函数。

6. Hessian会把复杂对象的所有属性存储在一个Map中进行序列化。所以在父类、子类存在同名成员变量的情况下，Hessian序列化时，先序列化子类，然后序列化父类，因此反序列化结果会导致子类同名成员变量被父类的值覆盖。

7. Kryo不是线程安全的，要通过ThreadLocal或者创建Kryo线程池来保证线程安全，而Protostuff则是线程安全的。

8. Protostuff和Kryo序列化的格式有相似之处，都是利用一个标记来记录字段类型，因此序列化出来体积都比较小。

————————————————
原文链接：https://blog.csdn.net/apple_52109766/article/details/125571873

----

**优缺点：**

以下是Kryo、Protostuff、Hessian、JSON和JDK序列化算法的优缺点：

**Kryo:**
优点：

1. 高性能：Kryo在序列化和反序列化过程中具有很高的性能，尤其在处理复杂对象和大数据量时表现出色。
2. 体积小：Kryo生成的序列化数据通常比其他算法更紧凑，占用较小的存储空间。
3. 兼容性：Kryo可以处理添加、删除或修改类定义的情况，并能与旧版本的数据进行兼容。

缺点：
1. 不跨语言：Kryo是一种Java特定的序列化框架，不支持跨语言序列化。
2. 可读性差：Kryo使用二进制格式，无法以人类可读的形式展示序列化数据。

**Protostuff:**
优点：

1. 高性能：Protostuff基于Google Protocol Buffers协议，通过动态代码生成实现高效的序列化和反序列化。
2. 跨语言支持：Protostuff支持多种编程语言，并且在不同语言之间的序列化和反序列化效果相同。
3. 数据压缩：Protostuff提供了数据压缩的功能，能够减少传输和存储的数据量。

缺点：
1. 类型定义依赖：Protostuff需要通过类的显式定义和注解来进行序列化，与某些动态结构或运行时生成的类不兼容。

**Hessian:**
优点：

1. 跨语言支持：Hessian可以在多种编程语言之间进行序列化和反序列化，方便实现跨平台的通信。
2. 简单易用：Hessian提供了简单的API和配置方式，易于上手和使用。

缺点：
1. 性能相对较低：与Kryo和Protostuff相比，Hessian的性能稍差一些，尤其是在处理复杂对象和大数据量时。

**JSON:**
优点：

1. 人类可读性好：JSON使用**文本格式**，以键值对的形式表示对象和数据，易于阅读和调试。
2. 广泛支持：几乎所有编程语言都有JSON的解析和生成库，方便各种应用之间的数据交换。

缺点：
1. 性能较低：相对于二进制格式的序列化算法，JSON的序列化和反序列化速度较慢。
2. 存储空间相对较大：相比其他算法，JSON产生的序列化数据通常比较冗余，占用较大的存储空间。

**JDK序列化算法:**
优点：

1. 简单易用：JDK内置的序列化机制可以通过实现`java.io.Serializable`接口简单地实现对象的序列化和反序列化。
2. 兼容性好：JDK序列化机制对类的修改比较宽容，在某些场景下可以实现向后和向前兼容。

缺点：
1. 性能较低：JDK序列化算法通常在性能方面表现较差，尤其在处理复杂对象和大数据量时效率低下。
2. 不跨语言：JDK序列化算法是Java特定的，不支持与其他编程语言之间的跨语言序列化。
3. 安全性问题：JDK序列化机制存在一些安全风险，可能受到恶意攻击。

综上所述，选择合适的序列化算法应根据具体的需求和优先考虑的因素，如性能要求、跨语言支持、存储空间和人类可读性等。

----

**Kryo**对各种数据类型的序列化机制，其再降低序列化大小方面做了如下优化：-

1. Kryo序列化的“对象”是数据以及少量元信息，这和JAVA默认的序列化的本质区别，java默认的序列化的目的是语言层次的，将类，对象的所有信息都序列化了，也就是就算是不加载类的定义，也可以根据序列化后的信息动态生成类的所有信息。而Kryo反序列化时，必须能加载类的定义，这样Kryo可以节省大量的字节空间。
2. Kryo为了提供性能和减小序列化结果体积，提供注册的序列化对象类的方式。在注册时，会为该序列化类生成int ID，后续在序列化时使用int ID唯一标识该类型。
3. 使用变长int(1~5字节)，变长long(1~9字节) 存储int，long类型，大大节省空间。
4. 元数据（字符串类型）使用缓存机制，重复出现的字符串使用int来存储，节省存储空间。
5. 字符串类型使用UTF-8存储，但会使用ascii码进一步优化空间。

[Kryo序列化编码机制](https://zhuanlan.zhihu.com/p/272816835?utm_id=0)

[序列化-Kryo的使用详解](https://blog.csdn.net/w727655308/article/details/121879000?spm=1001.2014.3001.5506)

### Linux

#### 1、top命令

top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。

**1．命令格式：**

```bash
top [参数]
```

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20221201111655803.png" alt="image-20221201111655803" style="zoom:80%;" />

```bash
PID — 进程id
USER — 进程所有者
PR — 进程优先级
NI — nice值。负值表示高优先级，正值表示低优先级
VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES
RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA
SHR — 共享内存大小，单位kb
S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程
%CPU — 上次更新到现在的CPU时间占用百分比
%MEM — 进程使用的物理内存百分比
TIME+ — 进程使用的CPU时间总计，单位1/100秒
COMMAND — 进程名称（命令名/命令行）
```

**2．命令功能：**

显示当前系统正在执行的进程的相关信息，包括进程ID、[内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)占用率、CPU占用率等（默认按照CPU占用率排序）。

**3．命令参数**

```bash
-b 批处理
-c 显示完整的治命令
-I 忽略失效过程
-s 保密模式
-S 累积模式
-i <时间> 设置间隔时间
-u <用户名> 指定用户名
-p <进程号> 指定进程
-n <次数> 循环显示的次数
```

​	https://blog.csdn.net/m0_51627713/article/details/118091336

#### 2、Linux中的管道符的作用？

在linux中，管道符是“|”，主要用于**将两个或者多个命令连接到一起，把一个命令的输出作为下一个命令的输入**；语法“command1 | command2 [ | commandN... ]”，“|”符左边命令的输出会作为“|”符右边命令的输入。管道符是可以连续使用的，第一个命令的输出会作为第二个命令的输入，第二个命令的输出又会作为第三个命令的输入，依此类推。

cat、sort、uniq、grep等命令均支持管道符，是因为这些命令均可从标准输入中读取要处理的文本（即从标准输入中读取参数）；而对于部分命令，例如rm、kill等命令则不支持从标准输入中读取参数，只支持从命令行中读取参数（即rm命令后面必须指定删除的文件或者目录，kill命令后面必须要指定杀死的进程号等）

**那什么样的命令支持管道，什么样的命令不支持管道呢？**

一般情况下，处理文本的命令，例如sort、uniq、grep、awk、sed等命令均支持管道；像rm、ls这类的不是处理文本的命令均不支持管道。

#### 3、cat命令

1、显示整个文件内容

```shell
cat my.log
```

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230322212604690.png" alt="image-20230322212604690" style="zoom:80%;" />

2、查找搜索目标所在行数，举例我要查询所有带 ”ext” 的

```shell
cat my.log | grep -n ext
```

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230322212528066.png" alt="image-20230322212528066" style="zoom: 80%;" />

3、查看搜索目标后2行数据，举例我要查询ext1 的后两行数据

```shell
cat my.log | grep -A 2 ext1
```

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230322212720501.png" alt="image-20230322212720501" style="zoom:80%;" />

4、查看搜索目标前2行数据,举例我要查询ext1 的前两行数据

```shell
cat my.log | grep -B 2 ext1
```

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230322212822107.png" alt="image-20230322212822107" style="zoom:80%;" />

5、同时查看搜索目标 前2行和 后2行数据，举例我要查询ext1 前后2行的数据

```shell
cat my.log | grep -C 2 ext1
```

<img src="C:\Users\Wuxy\AppData\Roaming\Typora\typora-user-images\image-20230322212910650.png" alt="image-20230322212910650" style="zoom:80%;" />

6、如果文件过大，我们可以输出到新的文件里，举例我要把所有ext 的结果输入到out.log

```shell
cat my.log | grep -n ext > out.log
```

#### 4、history命令

history命令说明：用于显示历史记录和执行过的指令命令, history命令是被保存在内存中的，当退出或者登录shell时，会自动保存或读取。在内存中，历史命令仅能够存储1000条历史命令，该数量是由[环境变量](https://so.csdn.net/so/search?q=环境变量&spm=1001.2101.3001.7020) HISTSIZE进行控制。

```shell
exort HISTSIZE=5 #设置只记录5条历史命令
```

如想查询某个用户在系统上执行了什么命令，可以使用root用户身份登录系统，检查Home目录下的用户主目录下的“**.bash_history”**文件，该文件记录了用户所使用的命令和历史信息。

命令用法：直接输入history查看

| 参数 | 参数说明                                     | 备注 |
| ---- | -------------------------------------------- | ---- |
| n    | 显示历史记录中最近的N个记录,例如 history 5   |      |
| -c   | 清空当前历史命令                             |      |
| -a   | 将历史命令缓冲区中命令写入历史命令文件中     |      |
| -r   | 将历史命令文件中的命令读入当前历史命令缓冲区 |      |
| -w   | 将当前历史命令缓冲区命令写入历史命令文件中   |      |
| -d   | 删除历史记录中第offset个命令                 |      |
| -n   | 读取指定文件                                 |      |

原文链接：https://blog.csdn.net/qq_42623156/article/details/110184465

#### 5、chmod命令

**chmod命令**是linux上用于改变权限的命令，使用格式：

```bash
chmod [options] mode files
```

options:

```bash
-c，–changes
只输出被改变文件的信息

-f，–silent，–quiet
当chmod不能改变文件模式时，不通知文件的用户

–help
输出帮助信息。

-R，–recursive
可递归遍历子目录，把修改应到目录下所有文件和子目录

–reference=filename
参照filename的权限来设置权限

-v，–verbose
无论修改是否成功，输出每个文件的信息

–version
输出版本信息。
```

who:

```bash
u 用户
g 组
o 其它
a 所有用户(默认)
```

opcode:

```bash
+ 增加权限
- 删除权限
= 重新分配权限
```

permission:

```bash
r 读
w 写
x 执行
s 设置用户(或组)的ID号
t 设置粘着位(sticky bit)，防止文件或目录被非属主删除
u 用户的当前权限
g 组的当前权限
o 其他用户的当前权限
```

作为选择，我们多数用三位八进制数字的形式来表示权限，第一位指定属主的权限，第二位指定组权限，第三位指定其他用户的权限，每位通过4(读)、2(写)、1(执行)三种数值的和来确定权限。如6(4+2)代表有读写权，7(4+2+1)有读、写和执行的权限。

还可设置第四位，它位于三位权限序列的前面，第四位数字取值是4，2，1，代表意思如下：

- 4，执行时设置用户ID，用于授权给基于文件属主的进程，而不是给创建此进程的用户。
- 2，执行时设置用户组ID，用于授权给基于文件所在组的进程，而不是基于创建此进程的用户。
- 1，设置粘着位。

```bash
$ chmod -R 777 file
$ chmod u+x file 　　　 给file的属主增加执行权限
$ chmod 751 file 　　　 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限
$ chmod u=rwx,g=rx,o=x file 上例的另一种形式
$ chmod =r file 　　　　为所有用户分配读权限
$ chmod 444 file 　　　　 同上例
$ chmod a-wx,a+r file 　　 　 同上例
$ chmod -R u+r directory 　 递归地给directory目录下所有文件和子目录的属主分配读的权限
$ chmod 4755 　　设置用ID，给属主分配读、写和执行权限，给组和其他用户分配读、执行的权限
```

### 操作系统

#### 1、孤儿进程和僵尸进程

**一、产生的原因**

1) 一般进程

​		正常情况下：子进程由父进程创建，子进程再创建新的进程。父子进程是一个异步过程，父进程永远无法预测子进程的结束，所以，当子进程结束后，它的父进程会调用wait()或waitpid()取得子进程的终止状态，回收掉子进程的资源。

2) 孤儿进程

​		孤儿进程：父进程结束了，而它的一个或多个子进程还在运行，那么这些子进程就成为孤儿进程(father died)。子进程的资源由init进程(进程号PID = 1)回收。

3) 僵尸进程

​		僵尸进程：子进程退出了，但是父进程没有用wait或waitpid去获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中，这种进程称为僵死进程。

**二、问题危害**

注意：unix提供了一种机制保证父进程知道子进程结束时的状态信息。

这种机制是：在每个进程退出的时候，内核会释放所有的资源，包括打开的文件，占用的内存等。但是仍保留一部分信息(进程号PID，退出状态，运行时间等)。直到父进程通过wait或waitpid来取时才释放。

但是这样就会产生问题：如果父进程不调用wait或waitpid的话，那么保留的信息就不会被释放，其进程号就会被一直占用，但是系统所能使用的进程号是有限的，如果大量产生僵死进程，将因没有可用的进程号而导致系统无法产生新的进程，这就是僵尸进程的危害

孤儿进程是没有父进程的进程，它由init进程循环的wait()回收资源，init进程充当父进程。因此孤儿进程并没有什么危害。

补充：任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程的数据结构，等待父进程去处理。如果父进程在子进程exit()之后，没有及时处理，出现僵尸进程，并可以用ps命令去查看，它的状态是“Z”。

**三、解决方案**

1) kill杀死元凶父进程(一般不用)

​		严格的说，僵尸进程并不是问题的根源，罪魁祸首是产生大量僵死进程的父进程。因此，我们可以直接除掉元凶，通过kill发送SIGTERM或者SIGKILL信号。元凶死后，僵尸进程进程变成孤儿进程，由init充当父进程，并回收资源。

或者运行：kill -9 父进程的pid值、

2) 父进程用wait或waitpid去回收资源(方案不好)

​		父进程通过wait或waitpid等函数去等待子进程结束，但是不好，会导致父进程一直等待被挂起，相当于一个进程在干活，没有起到多进程的作用。

3) 通过信号机制，在处理函数中调用wait，回收资源

​		通过信号机制，子进程退出时向父进程发送SIGCHLD信号，父进程调用signal(SIGCHLD,sig_child)去处理SIGCHLD信号，在信号处理函数sig_child()中调用wait进行处理僵尸进程。什么时候得到子进程信号，什么时候进行信号处理，父进程可以继续干其他活，不用去阻塞等待。

*注意：僵尸进程无法用kill直接杀死*

————————————————
原文链接：https://blog.csdn.net/a13568hki/article/details/103851388

#### 2、为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？

第一：历史原因， c 语言设计者用 0 开始计数数组下标，之后 Java、JavaScript等高级语言都效仿 C 语言，因此继续沿用从 0 开始计数的习惯。部分语言数组不是从 0 开始计数的，比如 Matlab，还有部分语言支持负数下标，如 Python。

第二：从数组存储的内存模型上来看，“下标”最确切的定义应该是 “**偏移**（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：

`a[k]_address = base_address + k * type_size`
但是，如果数组从1 开始计数，那我们计算数组元素 a[k] 的内存地址就会变为：
`a[k]_address = base_address + （k-1）* type_size`

对比两个公式，不难发现，从 1 开始编号，每次随机访问数组元素都多来一次减法运算，对于 CPU 来说，就多来一次减法指令。

数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致，所以为来减少一次减法操作，数组选择来从 0 开始编号，而不是 1 开始。
————————————————
原文链接：https://blog.csdn.net/org_hjh/article/details/107286675

#### 3、进程的调度算法

👨‍💻**面试官** ：**你知道操作系统中进程的调度算法有哪些吗?**

🙋 **我** ：嗯嗯！这个我们大学的时候学过，是一个很重要的知识点！

为了确定首先执行哪个进程以及最后执行哪个进程以实现最大 CPU 利用率，计算机科学家已经定义了一些算法，它们是：

- **先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
- **时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。
- **优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。
- **多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法**既能使高优先级的作业得到响应又能使短作业（进程）迅速完成**。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。

---

原文链接：https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html

**多级反馈队列调度算法：**

**1、**设有N个队列（Q1,Q2....QN），其中各个队列对于[处理机](https://baike.baidu.com/item/处理机?fromModule=lemma_inlink)的[优先级](https://baike.baidu.com/item/优先级/5643121?fromModule=lemma_inlink)是不一样的，也就是说位于各个队列中的作业(进程)的优先级也是不一样的。一般来说，优先级Priority(Q1) > Priority(Q2) > ... > Priority(QN)。怎么讲，位于Q1中的任何一个作业(进程)都要比Q2中的任何一个作业(进程)相对于CPU的优先级要高（也就是说，Q1中的作业一定要比Q2中的作业先被[处理机调度](https://baike.baidu.com/item/处理机调度/6944303?fromModule=lemma_inlink)），依次类推其它的队列。

**2、**对于优先级最低的队列来说，里面是遵循[时间片轮转](https://baike.baidu.com/item/时间片轮转?fromModule=lemma_inlink)法。也就是说，位于队列QN中有M个作业，它们的[运行时间](https://baike.baidu.com/item/运行时间/5215646?fromModule=lemma_inlink)是通过QN这个队列所设定的[时间片](https://baike.baidu.com/item/时间片/6525414?fromModule=lemma_inlink)来确定的；对于其他队列，遵循的是先来先服务算法，每一进程分配一定的时间片，若时间片运行完时进程未结束，则进入下一优先级队列的末尾。

**3、**各个队列的时间片是一样的吗？不一样，这就是该算法设计的精妙之处。各个队列的时间片是随着优先级的增加而减少的，也就是说，优先级越高的队列中它的时间片就越短。同时，为了便于那些超大作业的完成，最后一个队列QN(优先级最低的队列)的时间片一般很大(不需要考虑这个问题)。

<img src="asset\多级反馈队列调度算法.png" alt="多级反馈队列调度算法" style="zoom:80%;" />

------

原文链接：https://baike.baidu.com/item/%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/449587?fr=aladdin

#### 4、页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。

> **缺页中断** 就是要访问的**页**不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

**OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。

**FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。

**LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU 算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。

**LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。

------

原文链接：https://javaguide.cn/cs-basics/operating-system/operating-system-basic-questions-01.html

#### 5、磁盘扫描算法

**先来先服务**（*First-Come，First-Served，FCFS*），顾名思义，先到来的请求，先被服务。

**最短寻道时间优先**（*Shortest Seek First，SSF*）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求

**扫描（Scan）算法**磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。这种算法也叫做电梯算法，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。

**循环扫描**（*Circular Scan, CSCAN* ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。

**LOOK 算法**，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。

**C-LOOK算法**，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。

链接：https://xiaolincoding.com/os/5_schedule/schedule.html

#### 6、Java里面的线程和操作系统的线程一样吗？

**不同**

在[多核](https://so.csdn.net/so/search?q=多核&spm=1001.2101.3001.7020)操作系统中，jvm也会允许在一个进程内同时并发执行多个线程。java中的线程和操作系统中的线程分别存在于虚拟机和操作系统中，他们虽然不同，但却是一一对应，息息相关的。

**阐述关系**

首先，日常开发中都是会使用线程池来获取或者创建线程的，而线程在创建时，其实是先创建一个java线程，等到本地存储、程序计数器、缓冲区等都分配好以后，JVM会调用操作系统的方法，创建一个与java线程绑定的原生线程。

线程的调度是由操作系统负责的。

当操作系统为线程分配好时间片以后，就会调用java线程的run方法执行该线程。

当线程结束后，会释放java线程和原生线程所占用的资源。
————————————————
原文链接：https://blog.csdn.net/qq_51234063/article/details/124920208

#### 7、函数调用和系统调用的区别？

<img src="asset\虚拟文件系统.png" alt="img" style="zoom: 50%;" />

**什么是系统调用**

百度百科的解释是：

由操作系统实现提供的所有系统调用所构成的集合即程序接口（用户可以直接使用的接口）或应用编程接口(Application Programming Interface，API)用户通过程序间接使用的接口）。是应用程序同系统之间的接口。

系统调用执行过程：

1.传递系统调用参数

2.执行陷入指令（访管指令），用用户态切换到核心态，这是因为系统调用一般都需要再核心态下执行

3.执行系统调用程序

4.返回用户态

**什么函数调用**

计算机编译或运行时，使用某个函数来完成相关命令。对无参函数调用时则无实际参数表。实际参数表中的参数可以是常数、变量或其它构造类型数据及表达式。各实参之间用逗号分隔。

**函数调用和系统调用的区别**

函数调用是调用函数库中的一个程序，而系统调用是调用系统内核的服务。

函数调用是与用户程序相联系，而系统调用是操作系统的一个进入点

函数调用是在用户地址空间执行，而系统调用是在内核地址空间执行

函数调用的运行时间属于「用户」时间，而系统调用的运行时间属于「系统」时间

函数调用属于过程调用，开销较小，而系统调用需要切换到内核上下文环境然后切换回来，开销较大

————————————————
原文链接：https://blog.csdn.net/a284365/article/details/114483681

#### 8、什么是虚拟内存？

虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虑拟内存。

**虚拟内存有什么作用？**

- 第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
- 第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
- 第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

#### 9、虚拟内存的实现方式

虚拟内存中，允许将一个作业分多次调入内存。采用连续分配方式时，会使相当一部分内存空间都处于暂时或 永久 的空闲状态，造成内存资源的严重浪费。而且也无法从逻辑上扩大内存容量。因此，虑拟内存的实需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式:

- 请求分页存储管理。
- 请求分段存储管理
- 请求段页式存储管理

不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面:

- 一定容量的内存和外存。
- 页表机制(或段表机制)，作为主要的数据结构。
- 中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。
- 地址变换机构，逻辑地址到物理地址的变换。

#### 10、中断分为哪几类？

中断是指，CPU正常运行期间，由于有内/外部事件，或者由程序预先安排的事件，引起CPU暂停当前工作，转而去处理该事件，当处理完该事件后再返回继续运行被中断(暂停)的程序。通常，操作系统将中断分为两类：外部中断(硬件中断)和内部中断(异常中断，即软件引起的)。

操作系统收到了中断请求，会打断其他进程的运行，所以**中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。**

而且，中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说中断有可能会丢失，所以中断处理程序要短且快。

(1) 硬件故障中断。它是由于机器故障造成的，例如，电源故障、主存出错等。

(2) 程序中断。这是由于程序执行到某条机器指令时可能出现的各种问题而引起的中断，例如，发现定点操作数溢出、除数为“0”、地址越界、使用非法指令码、目态下的用户使用了特权指令等。 

(3) 外部中断。这是由各种外部事件引起的中断，例如，按压了控制板上的一个中断键、设置的定时时钟的时间周期到。 

(4) 输入输出中断。输入输出控制系统发现外围设备完成了输入输出操作或在执行输入输出操作时通道或外围设备产生错误而引起的中断。 

(5) 访管中断。它是正在运行的进程为了请求调用操作系统的某个功能而执行一条“访管指令”所引起的中断。例如，用户要求分配一台外围设备、要求分配一些主存区域。要求启动外围设备读一批数据等。

链接：https://xiaolincoding.com/os/1_hardware/soft_interrupt.html

#### 11、一台机器最多开几个进程，多少ip、多少端口？

1. 进程数：一台机器最多可以开多少个进程是取决于操作系统的限制。不同的操作系统对进程数的限制是不同的。通常，操作系统会为每个进程分配一些系统资源，如内存、文件描述符、线程等。当进程数量过多时，系统资源可能会耗尽，这样会导致系统性能下降或者崩溃。因此，操作系统会有一个限制来控制最大进程数。例如，**Linux默认的最大进程数为32768个**，但可以通过修改配置文件来增加这个限制。而**Windows 10家庭版默认的最大进程数为2048个**。总之，具体的最大进程数取决于操作系统和所使用的硬件条件。
2. IP地址：IPv4协议中，IP地址数量有限，总共只有 **2^32** = 4294967296个。在实际应用中，通常只能使用本地网络内的IP地址来进行通信，而不能跨越不同的网络。
3. 端口号：每个应用程序都会分配一个唯一的端口号以便与其他应用程序区分。在TCP/IP协议中，端口号的范围是0到 **2^16** = 65535 之间，其中0到1023之间的端口号被预留给特定的系统服务，普通应用程序应使用大于1023的端口号。

   > 65536.因为TCP的报文头部中源端口号和目的端口号的长度是16位，也就是可以表示2^16=65536个不同端口号，因此TCP可供识别的端口号最多只有65536个。但是由于0到1023是知名服务端口，所以实际上还要少1024个端口号。
   >
   > 而对于服务器来说，可以开的端口号与65536无关，其实是受限于Linux可以打开的文件数量，并且可以通过MaxUserPort来进行配置。

**一个进程最多可以创建多少个线程？**

- 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。
- 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。

#### 12、CPU缓存一致性

CPU 在读写数据的时候，都是在 CPU Cache 读写数据的，原因是 Cache 离 CPU 很近，读写性能相比内存高出很多。对于 Cache 里没有缓存 CPU 所需要读取的数据的这种情况，CPU 则会从内存读取数据，并将数据缓存到 Cache 里面，最后 CPU 再从 Cache 读取数据。

而对于数据的写入，CPU 都会先写入到 Cache 里面，然后再在找个合适的时机写入到内存，那就有「写直达」和「写回」这两种策略来保证 Cache 与内存的数据一致性：

- **写直达**，只要有数据写入，都会直接把数据写入到内存里面，这种方式简单直观，但是性能就会受限于内存的访问速度；
- **写回**，对于已经缓存在 Cache 的数据的写入，只需要更新其数据就可以，不用写入到内存，只有在需要把缓存里面的脏数据交换出去的时候，才把数据同步到内存里，这种方式在缓存命中率高的情况，性能会更好；

当今 CPU 都是多核的，每个核心都有各自独立的 L1/L2 Cache，只有 L3 Cache 是多个核心之间共享的。所以，我们要确保多核缓存是一致性的，否则会出现错误的结果。

要想实现缓存一致性，关键是要满足 2 点：

- 第一点是**写传播**，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；
- 第二点是**事物的串行化**，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；

基于**总线嗅探机制**的 **MESI 协议**，就满足上面了这两点，因此它是保障缓存一致性的协议。

MESI 协议，是已修改、独占、共享、已失效这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。

链接：https://xiaolincoding.com/os/1_hardware/cpu_mesi.html

#### 13、冯诺依曼模型

最重要的是定义计算机基本结构为 5 个部分，分别是**运算器、控制器、存储器、输入设备、输出设备**，这 5 个部分也被称为**冯诺依曼模型**。

<img src="asset\Von_Neumann_architecture.svg" alt="img" style="zoom:80%;" />

运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。

<img src="asset\CPU执行程序.png" alt="img" style="zoom:80%;" />

链接：https://xiaolincoding.com/os/1_hardware/how_cpu_run.html

#### 14、中央处理器

中央处理器也就是我们常说的 CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据：

- 32 位 CPU 一次可以计算 4 个字节；
- 64 位 CPU 一次可以计算 8 个字节；

这里的 32 位和 64 位，通常称为 CPU 的位宽，代表的是 CPU 一次可以计算（运算）的数据量。

之所以 CPU 要这样设计，是为了能计算更大的数值，如果是 8 位的 CPU，那么一次只能计算 1 个字节 `0~255` 范围内的数值，这样就无法一次完成计算 `10000 * 500` ，于是为了能一次计算大数的运算，CPU 需要支持多个 byte 一起计算，所以 CPU 位宽越大，可以计算的数值就越大，比如说 32 位 CPU 能计算的最大整数是 `4294967295`。

CPU 内部还有一些组件，常见的有**寄存器、控制单元和逻辑运算单元**等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而寄存器可以分为多种类，每种寄存器的功能又不尽相同。

CPU 中的[寄存器](https://blog.csdn.net/weixin_27015733/article/details/119164499)主要作用是存储计算时的数据，你可能好奇为什么有了内存还需要寄存器？原因很简单，因为内存离 CPU 太远了，而寄存器就在 CPU 里，还紧挨着控制单元和逻辑运算单元，自然计算时速度会很快。

常见的寄存器种类：

- *通用寄存器*，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。
- *程序计数器*，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。
- *指令寄存器*，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。

#### 15、如何让程序跑的更快？

<img src="asset\程序的CPU执行时间公式2.png" alt="img" style="zoom:80%;" />

要想程序跑的更快，优化这三者即可：

- *指令数*，表示执行程序所需要多少条指令，以及哪些指令。这个层面是基本靠编译器来优化，毕竟同样的代码，在不同的编译器，编译出来的计算机指令会有各种不同的表示方式。
- *每条指令的平均时钟周期数 CPI*，表示一条指令需要多少个时钟周期数，现代大多数 CPU 通过流水线技术（Pipeline），让一条指令需要的 CPU 时钟周期数尽可能的少；
- *时钟周期时间*，表示计算机主频，取决于计算机硬件。有的 CPU 支持超频技术，打开了超频意味着把 CPU 内部的时钟给调快了，于是 CPU 工作速度就变快了，但是也是有代价的，CPU 跑的越快，散热的压力就会越大，CPU 会很容易奔溃。

很多厂商为了跑分而跑分，基本都是在这三个方面入手的哦，特别是超频这一块。

#### 16、32位和64位CPU

> 64 位相比 32 位 CPU 的优势在哪吗？64 位 CPU 的计算性能一定比 32 位 CPU 高很多吗？

64 位相比 32 位 CPU 的优势主要体现在两个方面：

- 64 位 CPU 可以一次计算超过 32 位的数字，而 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进行计算，效率就没那么高，但是大部分应用程序很少会计算那么大的数字，所以**只有运算大数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不大**。
- 通常来说 64 位 CPU 的地址总线是 48 位，而 32 位 CPU 的地址总线是 32 位，所以 64 位 CPU 可以**寻址更大的物理内存空间**。如果一个 32 位 CPU 的地址总线是 32 位，那么该 CPU 最大寻址能力是 4G，即使你加了 8G 大小的物理内存，也还是只能寻址到 4G 大小的地址，而如果一个 64 位 CPU 的地址总线是 48 位，那么该 CPU 最大寻址能力是 `2^48`，远超于 32 位 CPU 最大寻址能力。

> 你知道软件的 32 位和 64 位之间的区别吗？再来 32 位的操作系统可以运行在 64 位的电脑上吗？64 位的操作系统可以运行在 32 位的电脑上吗？如果不行，原因是什么？

64 位和 32 位软件，实际上代表指令是 64 位还是 32 位的：

- 如果 32 位指令在 64 位机器上执行，需要一套兼容机制，就可以做到兼容运行了。但是**如果 64 位指令在 32 位机器上执行，就比较困难了，因为 32 位的寄存器存不下 64 位的指令**；
- 操作系统其实也是一种程序，我们也会看到操作系统会分成 32 位操作系统、64 位操作系统，其代表意义就是操作系统中程序的指令是多少位，比如 64 位操作系统，指令也就是 64 位，因此不能装在 32 位机器上。

总之，**硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽。**

#### 17、寄存器、CPU高速缓存、内存、SSD/HDD的速度和容量对比

<img src="asset\存储器的层次关系图.png" alt="img" style="zoom:80%;" />

各种存储器之间的关系，可以用我们在图书馆学习这个场景来理解。

CPU 可以比喻成我们的大脑，我们当前正在思考和处理的知识的过程，就好比 CPU 中的**寄存器**处理数据的过程，速度极快，但是容量很小。而 CPU 中的 **L1-L3 Cache** 好比我们大脑中的短期记忆和长期记忆，需要小小花费点时间来调取数据并处理。

我们面前的桌子就相当于**内存**，能放下更多的书（数据），但是找起来和看起来就要花费一些时间，相比 CPU Cache 慢不少。而图书馆的书架相当于**硬盘**，能放下比内存更多的数据，但找起来就更费时间了，可以说是最慢的存储器设备了。

从 寄存器、CPU Cache，到内存、硬盘，这样一层层下来的存储器，访问速度越来越慢，存储容量越来越大，价格也越来越便宜，而且每个存储器只和相邻的一层存储器设备打交道，于是这样就形成了存储器的层次结构。

再来回答，开头的问题：那机械硬盘、固态硬盘、内存这三个存储器，到底和 `CPU L1 Cache` 相比速度差多少倍呢？

CPU L1 Cache 随机访问延时是 1 纳秒，内存则是 100 纳秒，所以 **CPU L1 Cache 比内存快 `100` 倍左右**。

SSD 随机访问延时是 150 微秒，所以 **CPU L1 Cache 比 SSD 快 `150000` 倍左右**。

最慢的机械硬盘随机访问延时已经高达 10 毫秒，我们来看看机械硬盘到底有多「龟速」：

- **SSD 比机械硬盘快 70 倍左右；**
- **内存比机械硬盘快 100000 倍左右；**
- **CPU L1 Cache 比机械硬盘快 10000000 倍左右；**

我们把上述的时间比例差异放大后，就能非常直观感受到它们的性能差异了。如果 CPU 访问 L1 Cache 的缓存时间是 1 秒，那访问内存则需要大约 2 分钟，随机访问 SSD 里的数据则需要 1.7 天，访问机械硬盘那更久，长达近 4 个月。

可以发现，不同的存储器之间性能差距很大，构造存储器分级很有意义，分级的目的是要构造**缓存**体系。

#### 18、Linux 和 Windows 内核

**内核**

<img src="asset\Kernel_Layout.png" alt="内核" style="zoom: 33%;" />

**Monolithic Kernel**

![分别为宏内核、微内核、混合内核的操作系统结构](asset\OS-structure2.png)

对于内核的架构一般有这三种类型：

- 宏内核，包含多个模块，整个内核像一个完整的程序；
- 微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；
- 混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；

Linux 的内核设计是采用了宏内核，Window 的内核设计则是采用了混合内核。

这两个操作系统的可执行文件格式也不一样， Linux 可执行文件格式叫作 ELF，Windows 可执行文件格式叫作 PE。

链接：https://xiaolincoding.com/os/2_os_structure/linux_vs_windows.html

#### 19、虚拟地址

**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**

如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。

于是，这里就引出了两种地址的概念：

- 我们程序所使用的内存地址叫做**虚拟内存地址**（*Virtual Memory Address*）
- 实际存在硬件里面的空间地址叫**物理内存地址**（*Physical Memory Address*）。

操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：

<img src="asset\虚拟地址映射逻辑地址.png" alt="img" style="zoom: 67%;" />

#### 20、4GB物理内存的机器上申请8G内存会怎样？

- 在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
- 在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
  - 如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
  - 如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

#### 21、线程奔溃了，进程也会崩溃吗？

<img src="asset\线程崩溃的缺点.png" alt="img" style="zoom: 67%;" />

正常情况下，操作系统为了保证系统安全，所以针对非法内存访问会发送一个 SIGSEGV 信号，而操作系统一般会调用默认的信号处理函数（一般会让相关的进程崩溃）。

但如果进程觉得"罪不致死"，那么它也可以选择自定义一个信号处理函数，这样的话它就可以做一些自定义的逻辑，比如记录 crash 信息等有意义的事。

回过头来看为什么虚拟机会针对 StackoverflowError 和 NullPointerException 做额外处理让线程恢复呢，针对 stackoverflow 其实它采用了一种栈回溯的方法保证线程可以一直执行下去，而捕获空指针错误主要是这个错误实在太普遍了。

为了这一个很常见的错误而让 JVM 崩溃那线上的 JVM 要宕机多少次，所以出于工程健壮性的考虑，与其直接让 JVM 崩溃倒不如让线程起死回生，并且将这两个错误/异常抛给用户来处理。

**原因其实就是虚拟机内部定义了信号处理函数，而在信号处理函数中对这两者做了额外的处理以让 JVM 不崩溃，另一方面也可以看出如果 JVM 不对信号做额外的处理，最后会自己退出并产生 crash 文件 hs_err_pid_xxx.log（可以通过 -XX:ErrorFile=/var/\*log\*/hs_err.log 这样的方式指定），这个文件记录了虚拟机崩溃的重要原因**。

所以也可以说，虚拟机是否崩溃只要看它是否会产生此崩溃日志文件

#### 22、怎么给一个程序指定他运行的最大最小内存？

在Linux中，可以使用`ulimit`命令来为一个程序指定它运行的最大和最小内存。

- 要设置程序运行的最小内存，可以使用以下命令：

```shell
ulimit -v <min_memory>
```

其中，`<min_memory>`是以KB为单位的最小内存限制。这将影响到程序可以使用的虚拟内存大小。例如，要将最小内存设置为256MB，则可以使用以下命令：

```sh
ulimit -v 262144
```

- 要设置程序运行的最大内存，可以使用以下命令：

```sh
ulimit -m <max_memory>
```

其中，`<max_memory>`是以KB为单位的最大内存限制。这将影响到程序可以使用的物理内存大小。例如，要将最大内存设置为1GB，则可以使用以下命令：

```bash
ulimit -m 1048576
```

注意：`ulimit`命令只会对当前会话中的程序生效，并不会永久性地修改系统设置。如果需要永久性地修改系统设置，请参考相关文档进行配置。

#### 23、操作系统的进程和JVM的线程有什么区别？

操作系统的进程和JVM的线程也有一些重要的区别：

1. 资源分配：操作系统中的进程是资源分配和调度的基本单位，每个进程拥有独立的地址空间、堆栈、程序计数器等资源。而JVM中的线程则是在进程内部创建的，共享进程的堆和方法区。因此，操作系统中的进程需要更多的资源来维护，而JVM中的线程相对轻量级。

2. 状态切换：在操作系统中，当CPU时间片用完或者发生阻塞时，需要进行进程的切换，保存和恢复进程的状态。而在JVM中，线程的切换是由Java虚拟机控制的，不需要像操作系统那样保存和恢复全部进程的状态，所以线程切换的开销比进程切换小得多。

3. 安全性：JVM的线程是由Java虚拟机管理的，它们运行在受到Java安全管理器保护的沙箱中，可以限制线程对系统的访问和操作。而操作系统的进程可以直接访问系统资源并进行操作，需要更多的注意和安全保护。

4. 编程模型：操作系统中的进程可以通过共享内存或IPC（进程间通信）等方式进行通信和数据交换，需要更加复杂的编程模型。而在JVM中，线程可以通过共享对象、锁和变量等方式进行通信和数据交换，更加方便和简单。

总之，在操作系统和JVM中，进程和线程都是非常重要的概念，但它们有不同的实现和特点，需要根据具体情况选择合适的方式来管理和使用。

---

Java 线程和操作系统线程是一一对应的，每个 Java 线程都会被映射到一个操作系统线程上。Java 中的线程实际上是通过调用底层操作系统提供的线程 API 进行创建、启动和管理的。

在 Java 中，可以使用 `Thread` 类的 `getId()` 方法获取当前线程的唯一标识符，该标识符与底层操作系统线程 ID 是一一对应的。而在操作系统中，可以使用相应的工具（如 `ps` 命令）来查看当前进程运行时所启动的所有线程以及它们的 ID。

因此，如果需要找到某个 Java 线程对应的操作系统线程，可以先获取该线程的 ID，然后使用操作系统提供的工具进行查询即可。不过需要注意的是，Java 线程与操作系统线程并不是完全独立的，它们之间存在一定的映射关系和依赖关系，因此不能直接对操作系统线程进行任意的修改和操作，否则可能会导致程序出现异常或崩溃。

#### 24、操作系统创建一个进程的过程

操作系统创建进程的过程通常包括以下步骤：

1. 分配进程控制块（PCB）：操作系统首先会为新进程分配一个独立的进程控制块（PCB），用于记录进程的状态、标识符、程序计数器等关键信息。

2. 分配空间和加载程序：接下来，操作系统为进程分配地址空间，并将进程需要执行的程序从磁盘中读入到内存中。这个过程可能涉及到页表的更新等操作。

3. 初始化进程上下文：在分配好地址空间和加载好程序之后，操作系统会初始化进程的上下文环境，包括栈、堆、全局变量和文件描述符等资源。

4. 启动进程：完成所有初始化工作后，操作系统会将进程的控制权转交给进程本身，使其开始运行。

需要注意的是，不同操作系统的具体实现可能会有所不同，但以上提到的几个步骤是比较通用的。此外，在创建进程的过程中，还可能需要进行一些权限检查、资源分配等操作，以确保新进程能够正常运行并不会对系统造成不良影响。

#### 25、操作系统进程状态

**操作系统中的五种状态**

1. 新建：创建新的进程
2. 就绪：进程已经获得除CPU时间片以外的任何资 源，一旦获得cpu时间片就能立马执行。
3. 执行：处于就绪队列中的进程获得了时间片运行进程。
4. 阻塞：进程时间片用完进入阻塞队列中等待唤醒。
5. 终止：进程执行完毕。

<img src="asset\操作系统进程状态.png" alt="在这里插入图片描述" style="zoom: 50%;" />

#### 26、键盘敲入字母时，期间发生了什么？

<img src="asset\CPU 硬件总线图.png" alt="CPU 的硬件架构图" style="zoom: 67%;" />

CPU 里面的内存接口，直接和系统总线通信，然后系统总线再接入一个 I/O 桥接器，这个 I/O 桥接器，另一边接入了内存总线，使得 CPU 和内存通信。再另一边，又接入了一个 I/O 总线，用来连接 I/O 设备，比如键盘、显示器等。

那当用户输入了键盘字符，**键盘控制器**就会产生扫描码数据，并将其缓冲在键盘控制器的寄存器中，紧接着键盘控制器通过总线给 CPU 发送**中断请求**。

CPU 收到中断请求后，操作系统会**保存被中断进程的 CPU 上下文**，然后调用键盘的**中断处理程序**。

键盘的中断处理程序是在**键盘驱动程序**初始化时注册的，那键盘**中断处理函数**的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。

得到了显示字符的 ASCII 码后，就会把 ASCII 码放到「读缓冲区队列」，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区，最后将这些数据显示在屏幕里。

显示出结果后，**恢复被中断进程的上下文**。

链接：https://xiaolincoding.com/os/7_device/device.html

#### 27、零拷贝技术

早期 I/O 操作，内存与磁盘的数据传输的工作都是由 CPU 完成的，而此时 CPU 不能执行其他任务，会特别浪费 CPU 资源。

于是，为了解决这一问题，DMA 技术就出现了，每个 I/O 设备都有自己的 DMA 控制器，通过这个 DMA 控制器，CPU 只需要告诉 DMA 控制器，我们要传输什么数据，从哪里来，到哪里去，就可以放心离开了。后续的实际数据传输工作，都会由 DMA 控制器来完成，CPU 不需要参与数据传输的工作。

传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。

零拷贝两种实现方式：1、mmap+write；2、sendfile。

为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（`sendfile` 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。

Kafka 和 Nginx 都有实现零拷贝技术，这将大大提高文件传输的性能。

零拷贝技术是基于 PageCache 的，PageCache 会缓存最近访问的数据，提升了访问缓存数据的性能，同时，为了解决机械硬盘寻址慢的问题，它还协助 I/O 调度算法实现了 IO 合并与预读，这也是顺序读比随机读性能好的原因。这些优势，进一步提升了零拷贝的性能。

需要注意的是，零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发送。

另外，当传输大文件时，不能使用零拷贝，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，并且大文件的缓存命中率不高，这时就需要使用「异步 IO + 直接 IO 」的方式。

在 Nginx 里，可以通过配置，设定一个文件大小阈值，针对大文件使用异步 IO 和直接 IO，而对小文件使用零拷贝。

链接：https://xiaolincoding.com/os/8_network_system/zero_copy.html

#### 28、用户态和内核态

在操作系统中，有两种不同的执行模式：内核态和用户态。

<img src="asset\内核架构.png" alt="内核" style="zoom:50%;" />

1. 用户态

用户态是指程序执行时所处的一种状态，此时程序只能访问自己的数据和代码，不能直接访问操作系统提供的资源。在用户态下，程序执行的指令会被 CPU 直接执行，但是如果要访问操作系统提供的某些资源（如文件、网络等），则需要通过系统调用进入内核态。

2. 内核态

内核态是指操作系统运行时所处的一种状态，此时操作系统可以直接访问计算机的所有硬件资源，且可以管理和调度所有正在运行的程序。在内核态下，CPU 可以执行任意指令，包括访问 I/O 设备、修改内存等操作。因为内核态具有最高权限，所以在内核态下运行的程序必须非常小心谨慎，否则可能会导致整个系统崩溃。

在操作系统中，内核态与用户态之间的切换是由操作系统负责控制的，一般情况下，程序只在用户态下执行，当需要访问操作系统提供的资源时，就会触发系统调用，并进入内核态。当系统调用完成后，又会返回到用户态，继续执行程序。这种切换过程需要一定的时间和资源开销，所以在设计程序时，应该尽量减少系统调用的次数和耗时。

用户态和内核态主要是为了保证计算机系统的安全性、稳定性和性能。

link: https://xiaolincoding.com/os/2_os_structure/linux_vs_windows.html

#### 29、多进程和多线程的应该场景

多进程和多线程都是并发编程的方式，但它们适用于不同的场景。

多进程适用于以下场景：

1. 需要在不同的操作系统进程之间进行通信和资源共享。
2. 需要隔离应用程序中的各个模块，从而提高应用程序的稳定性和安全性。
3. 需要利用多核处理器的优势来提高程序的性能和并发度。

多线程适用于以下场景：

1. 需要在同一个进程内部实现并发操作，例如 GUI 应用程序中的界面响应和数据处理。

2. 需要实现大量的计算密集型任务，例如图像处理和加密解密等。

3. 需要同时进行多个网络连接或 IO 操作，例如 Web 服务器和数据库连接池等。

总之，多进程适合需要在不同的进程之间进行通信和资源共享的场景，并提供更好的隔离和安全性；而多线程适合在单个进程内部实现并发操作，并提供更好的性能和效率。

#### 30、一个Tomcat启动，从操作系统角度分析，它干了什么？

当操作系统启动Tomcat时，它会首先为Tomcat进程分配一块内存空间。这个空间通常是虚拟内存，即尚未映射到物理内存中的内存区域。

接下来，操作系统会从磁盘上加载Tomcat的二进制文件，包括可执行文件、配置文件等，并将这些文件加载到Tomcat进程的虚拟地址空间中。此时Tomcat还没有开始运行，只是被加载到了内存中。

随后，Tomcat进程会调用JVM来启动Java虚拟机。JVM会在进程的内存空间中分配一块堆内存，用于存储Java对象和类信息。同时，JVM还会加载Tomcat所需的Java类和库，并进行初始化工作。

在JVM启动完成之后，Tomcat进程会创建多个线程，用于处理HTTP请求和响应。同时，Tomcat还会加载Web应用程序，并将它们部署到Servlet容器中。每个Web应用程序都有自己的ClassLoader，用于加载其所依赖的类和库。

最后，Tomcat进程会监听一个或多个网络端口，等待客户端连接。当客户端请求到达时，Tomcat会接受连接，并将请求交给相应的线程处理。同时，Tomcat还会记录日志，以便管理员随时查看系统状态和调试问题。

总的来说，Tomcat启动的过程涉及到进程的创建、内存的分配、二进制文件和Java类的加载、线程的创建、Web应用程序的部署等多个步骤。这些步骤相互关联，共同组成了Tomcat的启动过程。

#### 31、x64和x84

**含义：**

1. x64是一种64位架构，也就是说，它可以处理64位数据，这种架构可以处理更大的数据，比如更多的内存，更多的输入输出，这有利于电脑的运行，更好地处理更多的数据。

2. x84是一种32位架构，也就是说，它只能处理32位数据，这种架构只能处理有限的数据，比如较少的内存，较少的输入输出，因此，它的运行效率比不上64位架构。

**区别：**

1. x64和x84在处理数据的能力上有很大的区别，x64能处理更多的数据，而x84只能处理有限的数据，但x64架构的电脑成本要比x84架构的电脑成本高。

2. 由于x64架构的电脑能够处理更多的数据，因此，它适用于进行复杂的计算，例如游戏，图像处理等，而x84架构的电脑处理能力较弱，因此，它适用于浏览网页，写文档等轻量级的任务。

3. x64和x84的架构是完全不同的，因此，x64架构的程序无法在x84架构的电脑上运行，反之亦然，所以，我们在购买电脑时，要根据自己的需求来选择合适的架构。

---

**32位和64位的区别如下：**

1、处理数据的能力不同。

32位计算机的CPU一次最多能处理32位数据，例如它的EAX寄存器就是32位的，当然32位计算机通常也可以处理16位和8位数据。64为计算机一次处理数据要比32位大得多，一次运行64位的数据。

2、支持的内存不同。

32位 的系统许多支持4G的内存，而64位则可以支持上百G的内存。

3、架构不同。

从 32位到 64 位架构的改变是一个根本的改变，因为大多数操作系统必须进行全面性修改，以取得新架构的优点。其它软件也必须进行移植，以使用新的性能;较旧的软件一般可借由硬件兼容模式(新的处理器支持较旧的 32 位版本指令集)或软件模拟进行支持。

或者直接在 64 位处理器里面实作 32 位处理器内核(如同 Intel 的 Itanium 处理器，其内含有 x86 处理器内核，用来执行 32 位 x86 应用程序)。支持 64 位架构的操作系统，一般同时支持 32 位和 64 位的应用程序。

4、对配置的要求不同。

64位操作系统只能安装在64位电脑上(CPU必须是64位的)。同时需要安装64位常用软件以发挥64位(x64)的最佳性能。32位操作系统则可以安装在32位(32位CPU)或64位(64位CPU)电脑上。

#### 32、大小端

在计算机中，字节序指的是在存储器中，多字节数据的字节存放顺序。大小端是计算机体系结构中的一个概念，用于表示在多字节数据类型中，字节的顺序。在不同的计算机体系结构中，字节顺序可能不同。一些处理器将最高位字节存储在地址最低的位置，这被称为“**大端**字节序”（高位字节排放在内存的低地址端，低位字节排放在内存的高地址端），而另一些处理器将最低位字节存储在地址最低的位置，这被称为“**小端**字节序”（低位字节排放在内存的低地址端，高位字节排放在内存的高地址端）。

　　例如，假设我们要存储十六进制数0x12345678（十进制数为305419896），在大端字节序下，它的存储顺序为：

```
12 34 56 78
```

　　而在小端字节下，则为：

```
78 56 34 12
```

　　　以上从左到右=》 低地址（高位）到高地址（低位）。偷个图：

<img src="asset\大小端.png" alt="img" style="zoom:50%;" />

链接：https://www.cnblogs.com/wj-1314/p/12133422.html

#### 33、用户级线程和内核级线程

[用户级线程和内核级线程](https://blog.csdn.net/qq_53144843/article/details/120461625)

用户线程和内核线程是两种不同类型的线程，它们的主要区别在于操作系统对它们的支持和管理方式。

用户线程是由应用程序自己创建和调度的线程。它们完全在用户空间运行，不需要操作系统的干预。用户线程的创建、调度、同步和销毁都由应用程序自己实现，操作系统并不了解这些细节。由于用户线程不涉及内核态的切换，因此用户线程的切换速度非常快，可以在应用程序中实现轻量级的并发控制。

相比之下，内核线程是由操作系统内核直接创建和管理的线程。内核线程在内核态运行，需要操作系统的干预才能进行调度和同步。内核线程的创建、调度、同步和销毁都由操作系统负责实现。由于内核线程涉及内核态的切换，因此内核线程的切换速度比用户线程慢，同时也需要更多的系统资源。

虽然内核线程比用户线程更加复杂和重量级，但其具有更好的可靠性和稳定性，因为操作系统可以更好地控制和保护它们。同时，内核线程通常可以利用多核处理器的所有核心，并且可以与其他进程和线程共享系统资源，实现更高效的并发控制。

----

用户线程进行上下文切换时，通常会涉及到运行态的切换。

当一个用户线程需要让出 CPU（如等待 I/O 完成或者时间片耗尽），操作系统需要对其进行上下文切换，将当前线程的上下文保存起来，并从调度队列中选择下一个要执行的线程。这个过程涉及到将当前线程的寄存器状态、程序计数器值以及其他相关信息保存到内存中，同时从下一个线程的上下文中恢复相应的寄存器状态和程序计数器值，使其可以继续执行。

在用户线程的上下文切换过程中，操作系统仅负责保存和恢复寄存器状态及程序计数器值等与线程相关的上下文信息，而不会涉及到线程的用户态数据和栈的切换。这使得用户线程的上下文切换相对轻量级，速度较快。但是，由于操作系统无法感知用户线程的具体执行情况和堆栈状态，因此在用户线程的上下文切换后，其堆栈信息可能已经失效，需要重新建立。

需要注意的是，**用户线程的上下文切换完全由应用程序自己实现，而不是由操作系统负责。操作系统仅在特定的时机（如系统调用、信号处理等）下介入用户线程并进行上下文切换**。

---

1 .内核级线程:切换由内核控制，当线程进行切换的时候，由用户态转化为内核态。切换完毕要从内核态返回用户态；可以很好的利用smp，即利用多核cpu。windows线程就是这样的。

 \2. 用户级线程内核的切换由用户态程序自己控制内核切换,不需要内核干涉，少了进出内核态的消耗，但不能很好的利用多核Cpu,目前[Linux](https://so.csdn.net/so/search?q=Linux&spm=1001.2101.3001.7020) pthread大体是这么做的。

线程的实现可以分为两类：用户级线程(User-Level Thread)和内核线线程(Kernel-Level Thread)，后者又称为内核支持的线程或轻量级进程。在多线程操作系统中，各个系统的实现方式并不相同，在有的系统中实现了用户级线程，有的系统中实现了内核级线程。

**用户线程**指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，应用进程利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。不需要用户态/核心态切换，速度快，操作系统内核不知道多线程的存在，因此一个线程阻塞将使得整个进程（包括它的所有线程）阻塞。由于这里的处理器时间片分配是以进程为基本单位，所以每个线程执行的时间相对减少。

**内核线程**：由操作系统内核创建和撤销。内核维护进程及线程的上下文信息以及线程切换。一个内核线程由于I/O操作而阻塞，不会影响其它线程的运行。Windows NT和2000/XP支持内核线程。

**用户线程运行在一个中间系统上面。**目前中间系统实现的方式有两种，即运行时系统（Runtime System）和内核控制线程。“运行时系统”实质上是用于管理和控制线程的函数集合，包括创建、撤销、线程的同步和通信的函数以及调度的函数。这些函数都驻留在用户空间作为用户线程和内核之间的接口。用户线程不能使用系统调用，而是当线程需要系统资源时，将请求传送给运行时，由后者通过相应的系统调用来获取系统资源。内核控制线程：系统在分给进程几个轻型进程（LWP），LWP可以通过系统调用来获得内核提供的服务，而进程中的用户线程可通过复用来关联到LWP，从而得到内核的服务。

**以下是用户级线程和内核级线程的区别：**

**（1）**内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。

**（2）**用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。

**（3）**用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。

**（4）**在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。

**（5）**用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。

**内核线程的优点：**

（1）当有多个处理机时，一个进程的多个线程可以同时执行。

**缺点：**

（1）由内核进行调度。

**用户进程的优点：**

（1） 线程的调度不需要内核直接参与，控制简单。

（2） 可以在不支持线程的操作系统中实现。

（3） 创建和销毁线程、线程切换代价等线程管理的代价比内核线程少得多。

（4） 允许每个进程定制自己的调度算法，线程管理比较灵活。这就是必须自己写管理程序，与内核线程的区别

（5） 线程能够利用的表空间和堆栈空间比内核级线程多。

（6） 同一进程中只能同时有一个线程在运行，如果有一个线程使用了系统调用而阻塞，那么整个进程都会被挂起。另外，页面失效也会产生同样的问题。

**缺点：**

（1）资源调度按照进程进行，多个处理机下，同一个进程中的线程只能在同一个处理机下分时复用

### 设计模式

#### 1、设计模式的六大原则

设计模式的六大原则：

1、**单一职责原则**，其核心就是控制类的粒度大小、将对象解耦、提高其内聚性；

2、**开闭原则**，可以通过“抽象约束、封装变化”来实现；

3、**里氏替换原则**，主要阐述了有关继承的一些原则；

4、**依赖倒置原则**，降低了客户与实现模块之间的耦合；

5、**接口隔离原则**，是为了约束接口、降低类对接口的依赖性；

6、**迪米特法则**，要求限制软件实体之间通信的宽度和深度。

---

1、单一职责（Single-Responsibility-Principle）

​		就一个类而言，应该仅有一个引起它变化的原因。

​		如果一个类承担的职责过多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者抑制这个类完成其他职责的能力。这种耦合会导致脆弱他的设计，当变化发生时，设计会遭受到意想不到的破坏；软件设计真正要做的许多内容就是发现职责并把那些职责相互分离。

​		遵循单一职责的优点：

- 降低类的复杂度，一个类只负责一项职责。
- 提高类的可读性，可维护性
- 降低变更引起的风险。

2、开闭原则（Open Close Principle）

​		开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。

3、里氏代换原则（Liskov Substitution Principle）

​        子类型必须能够替换掉它们的父类型。由于子类型的可替换性才使得使用父类类型的模块在无需修改的情况下就可以扩展。

​		里氏代换原则是面向对象设计的基本原则之一。里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。

4、依赖倒转原则（Dependence Inversion Principle）

​		这个原则是开闭原则的基础，具体内容：**针对接口编程，依赖于抽象而不依赖于具体。**

>  **高层模块不应该依赖低层模块，两个都应该依赖抽象；抽象不应该依赖细节，细节应该依赖抽象。**
>
> 要针对接口编程，不要针对实现编程。该原则可以说是面向对象设计的标志，编写时考虑的是如何对抽象编程而不是针对细节编程，即程序中所有的依赖关系都是终止于抽象类或者接口。

> 依赖倒置原则（DIP）是面向对象设计中的一项重要原则，其核心思想是高层模块不应该依赖于低层模块，二者都应该依赖于抽象。下面列举一些常见的框架和库，它们都遵循了依赖倒置原则：
>
> 1. Spring框架：Spring是一个轻量级的Java开发框架，其核心是IoC容器和AOP框架。Spring IoC容器使用了依赖注入（DI）机制实现组件之间解耦，而且通过接口编程、依赖抽象等方式强调了依赖倒置原则。
>
> 2. Hibernate ORM框架：Hibernate是一个优秀的ORM框架，它采用了依赖倒置原则来解决数据层与业务逻辑层之间的耦合问题。Hibernate提供了一系列的接口，在使用时只需要面向这些接口编程，而具体的实现则由Hibernate框架来完成。
>
> 3. JUnit单元测试框架：JUnit是一个常用的Java单元测试框架，它通过依赖倒置原则来解决测试代码与被测试代码之间的耦合问题。在JUnit中，测试代码不应该依赖于被测试代码的具体实现，而是应该通过接口或抽象类来与被测试代码进行交互。
>
> 4. Guice依赖注入框架：Guice是一个轻量级的依赖注入框架，它使用了依赖倒置原则来实现组件之间的解耦。通过Guice提供的注解和绑定机制，可以很方便地完成依赖注入，从而实现松耦合的程序结构。
>
> 总之，依赖倒置原则在很多框架和库中都得到了广泛应用，这些框架和库都采用了面向接口编程、依赖注入等技术手段来实现高内聚、低耦合的程序设计。

5、接口隔离原则（Interface Segregation Principle）

​		这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。

6、迪米特法则，又称最少知道原则（Demeter Principle）

​		最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。

> 如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用；如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。
>
> 该原则其根本思想，是强调了类之间的松耦合；类之间的耦合越弱，越利于复用，一个处在弱耦合的类被修改，不会对有关系的类造成波及。在类的结构设计上，每一个类都应当尽量降低成员的访问权限。

7、合成复用原则（Composite Reuse Principle）

​		合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承

#### 2、外观（门面）模式

门面模式（Facade Pattern）是一种结构型设计模式，它提供了一个统一的接口，用来访问一个子系统中的一群接口，使得子系统更易于使用。

门面模式的具体体现在如下几个方面：

1. 封装子系统

门面模式把子系统中的多个接口封装在一个门面类中，对外只暴露一个简单、易用的接口。这样，客户端只需要与门面类交互，而不必直接与子系统中的多个接口交互，从而降低了客户端和子系统之间的耦合度。

2. 提供统一接口

门面模式提供了统一、简单的接口，方便客户端使用。这个接口其实就是门面类中封装的多个接口的组合，可以简化客户端的代码。

3. 隐藏复杂实现细节

门面模式隐藏了子系统的复杂实现细节，客户端对于子系统的具体实现不需要了解，只需要通过门面类来调用子系统的接口即可。这样使得客户端更加专注于自己的业务，不必关注子系统的复杂实现。

总之，门面模式能够帮助我们简化代码、封装复杂逻辑，使得代码更易于维护，同时也能够降低系统的耦合度，提高系统的设计灵活性和扩展性。

### Maven

#### 1、maven的依赖

**① 依赖的目的**

当 A jar 包用到了 B jar 包中的某些类时，A 就对 B 产生了依赖，这是概念上的描述。那么如何在项目中以依赖的方式引入一个我们需要的 jar 包呢？ 答案非常简单，就是使用 `dependency` 标签指定被依赖 jar 包的坐标就可以了。

```pom
<dependency>
    <groupId>net.lazyegg.maven</groupId>
    <artifactId>Hello</artifactId>
    <version>0.0.1-SNAPSHOT</version>
    <scope>compile</scope>            
</dependency>
```



**② 依赖的范围**

**classpath** 用于指定 `.class` 文件存放的位置，类加载器会从该路径中加载所需的 `.class` 文件到内存中。

Maven 在编译、执行测试、实际运行有着三套不同的 classpath：

- **编译 classpath** ：编译主代码有效
- **测试 classpath** ：编译、运行测试代码有效
- **运行 classpath** ：项目运行时有效

Maven 的依赖范围如下：

- **compile**：编译依赖范围（默认），使用此依赖范围对于编译、测试、运行三种都有效，即在编译、测试和运行的时候都要使用该依赖 Jar 包。
- **test**：测试依赖范围，从字面意思就可以知道此依赖范围只能用于测试，而在编译和运行项目时无法使用此类依赖，典型的是 JUnit，它只用于编译测试代码和运行测试代码的时候才需要。
- **provided** ：此依赖范围，对于编译和测试有效，而对运行时无效。比如 `servlet-api.jar` 在 Tomcat 中已经提供了，我们只需要的是编译期提供而已。
- **runtime**：运行时依赖范围，对于测试和运行有效，但是在编译主代码时无效，典型的就是 JDBC 驱动实现。
- **system**：系统依赖范围，只在编译和测试时有效，使用 system 范围的依赖时必须通过 systemPath 元素显示地指定依赖文件的路径，不依赖 Maven 仓库解析，所以可能会造成建构的不可移植。
- 常用依赖范围有效性总结

|          | compile | test | provided |
| -------- | ------- | ---- | -------- |
| 主程序   | √       | ×    | √        |
| 测试程序 | √       | √    | √        |
| 参与部署 | √       | ×    | ×        |



**③ 依赖的传递性**

A 依赖 B，B 依赖 C，A 能否使用 C 呢？那要看 B 依赖 C 的范围是不是 compile，如果是则可用，否则不可用。



**④ 依赖的排除**

如果我们在当前工程中引入了一个依赖是 A，而 A 又依赖了 B，那么 Maven 会自动将 A 依赖的 B 引入当 前工程，但是个别情况下 B 有可能是一个不稳定版，或对当前工程有不良影响。这时我们可以在引入 A 的时候将 B 排除。

```pom
<dependency>
	<groupId>net.lazyegg.maven</groupId>
	<artifactId>Hello</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<scope>compile</scope>
	<exclusions>
		<exclusion>
			<groupId>commons-logging</groupId>
			<artifactId>commons-logging</artifactId>
			</exclusion>
	</exclusions>
</dependency>
```



**⑤ 统一管理所依赖 jar 包的版本**

对同一个框架的一组 jar 包最好使用相同的版本。为了方便升级框架，可以将 jar 包的版本信息统一提取出来

- 统一声明版本号

```pom
<properties>
	<starfish.spring.version>4.1.1.RELEASE</starfish.spring.version>
	<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
</properties>
```

- 引用前面声明的版本号

```pom
<dependency>
	<groupId>org.springframework</groupId>
	<artifactId>spring-core</artifactId>
	<version>${starfish.spring.version}</version>
	<scope>compile</scope>
</dependency>
```


**⑥ 依赖的原则：解决 jar 包冲突**

- 路径最短者优先

- 路径相同时先声明者优先

————————————————
原文链接：https://blog.csdn.net/u011870547/article/details/104020790

原文链接：https://javaguide.cn/tools/maven/maven-core-concepts.html

#### 2、构建项目的几个主要环节：
清理（clean）：删除以前的编译结果，为重新编译做好准备
编译（compile）：将Java 源程序编译为字节码文件
测试（test）：针对项目中的关键点进行测试，确保项目在迭代开发过程中关键点的正确性
报告（）：在每一次测试后以标准的格式记录和展示测试结果
打包（package）：将一个包含诸多文件的工程封装为一个压缩文件用于安装或部署。Java 工程对应 jar 包，Web工程对应 war 包。
安装（install）：在 Maven 环境下特指将打包的结果——jar 包或 war 包安装到本地仓库中。
部署（deploy）：将打包的结果部署到远程仓库或将 war 包部署到服务器上运行。
————————————————
原文链接：https://blog.csdn.net/u011870547/article/details/104020790

#### 3、maven的依赖原则

1、最短路径原则（依赖传递的路径越短越优先）

2、pom文件申明顺序优先（路径长度一样，则先申明的优先）

3、覆写原则（当前pom文件里申明的直接覆盖父工程传过来的）

### Nginx

#### 1、Nginx的负载均衡策略有哪些？

nginx 的负载均衡策略主要有以下几种：

1. 轮询（Round Robin）：nginx默认的负载均衡方式，每次将请求发送到下一台服务器，循环往复。
2. IP哈希（IP Hash）：将客户端的IP地址进行哈希运算，根据哈希值决定将请求发送到哪一台服务器。
3. 最少连接（Least Connections）：将请求发送到当前连接数最少的服务器上，以平衡服务器的负载。
4. 泛洪（Least Time）：将请求发送到处理时间最短的服务器上，可以提高整个系统的响应速度。
5. 加权轮询（Weighted Round Robin）：给不同的服务器设置不同的权重，每次按照权重比例将请求发送到相应服务器。
6. 加权IP哈希（Weighted IP Hash）：将加权后的服务器的IP地址进行哈希运算，将请求发送到哈希值相应的服务器上。

使用哪种负载均衡策略取决于具体的场景和需求，需要根据实际情况进行选择。

### Git

#### 1、git rebase 和 git merge 的区别？

1. 采用merge和rebase后，git log的区别，**merge命令不会保留merge的分支的commit，rebase会保留所有的commit**：

<img src="asset\gitrebase.png" alt="img" style="zoom: 80%;" />

**rebase** 会把你当前分支的 commit 放到公共分支的最后面，所以叫**变基**。就好像你从公共分支又重新拉出来这个分支一样。

举例：如果你从 master 拉了个feature分支出来,然后你提交了几个 commit,这个时候刚好有人把他开发的东西合并到 master 了,这个时候 master 就比你拉分支的时候多了几个 commit,如果这个时候你 rebase master 的话，就会把你当前的几个 commit，放到那个人 commit 的后面。

![img](asset\rebase.png)

**merge** 会把公共分支和你当前的commit 合并在一起，形成一个新的 commit 提交

<img src="asset\merge.png" alt="img" style="zoom:50%;" />

2. 处理冲突的方式：
   1. （一股脑）使用merge命令合并分支，解决完冲突，执行git add .和git commit -m'fix conflict'。这个时候会产生一个commit
   2. （交互式）使用rebase命令合并分支，解决完冲突，执行git add .和git rebase --continue，不会产生额外的commit。这样的好处是，‘干净’，分支上不会有无意义的解决分支的commit；坏处，如果合并的分支中存在多个commit，需要重复处理多次冲突。

3. git pull和git pull --rebase区别：git pull做了两个操作分别是‘获取’和合并。所以加了rebase就是以rebase的方式进行合并分支得到一条干净的分支流。

```git
git pull = git fetch + git merge FETCH_HEAD 
git pull --rebase =  git fetch + git rebase FETCH_HEAD  
```

```git
git rebase --continue; 让 rebase 过程继续执行。
git rebase --abort; 发生代码冲突后，放弃合并，回到操作前的样子。
```

————————————————
原文链接：https://blog.csdn.net/muzidigbig/article/details/122519949

#### 2、git的回滚

**查看提交记录**

命令形式：git log [option]

- options
  - --all 显示所有分支
  - --pretty=oneline 将提交信息显示为一行
  - --abbrev-commit 使得输出的commitId更简短
  - --graph 以图的形式显示

**版本回退**

命令形式：git reset --hard commitID

- commitID 可以使用 git-log 或 git log 指令查看

如何查看已经删除的记录？

- git reflog

- 这个指令可以看到已经删除的提交记录

### Docker

#### 1、Docker和虚拟机的区别

[Docker](https://link.jianshu.com/?t=http://lib.csdn.net/base/docker)是近年来新兴的[虚拟化](https://so.csdn.net/so/search?q=虚拟化&spm=1001.2101.3001.7020)工具，它可以和虚拟机一样实现资源和系统环境的隔离。

下图分别是虚拟机与docker的实现框架：

<img src="asset\虚拟机.png" alt="image-20230324164417877" style="zoom:80%;" />

<img src="asset\docker.png" alt="image-20230324164457360" style="zoom:80%;" />

不同点：

**1.携带内容不同**

虚拟机是携带操作系统，本身很小的应用程序却因为携带了操作系统而变得非常大很笨重.Docker是不携带操作系统的，所以Docker的应用就非常的轻巧。

**2.启动速度不同**

docker 启动快速属于秒级别，虚拟机通常需要几分钟去启动。

**3.性损耗不同**

docker 需要的资源更少，docker 在操作系统级别进行虚拟化，docker 容器和内核交互，几乎没有性能损耗。

**4.系统利用不同**

Docker对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器；容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小.专统虚拟机方式运行 10个不同的应用就要起10个虚拟机，而Docker 只需要启动10个隔离的应用即可。

**5.管理部署不同**

使用 Docker只需要小小的修改，就可以替代以往大量的更新工作，所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。

比较两图的差异，左图虚拟机的Guest OS层和Hypervisor层在docker中被Docker Engine层所替代。虚拟机的Guest OS即为虚拟机安装的[操作系统](https://link.jianshu.com/?t=http://lib.csdn.net/base/operatingsystem)，它是一个完整操作系统内核；虚拟机的Hypervisor层可以简单理解为一个硬件虚拟化平台，它在Host OS是以内核态的驱动存在的。

**首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。**

尽管你可以在容器里通过 Mount Namespace 单独挂载其他不同版本的操作系统文件，比如 CentOS 或者 Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在**低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。而在高版本的Linux宿主机上运行低版本的Linux容器是可以的**。

**docker：**

> （1）docker有着比虚拟机更少的抽象层。由于docker不需要Hypervisor实现硬件资源虚拟化，运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有优势，具体的效率对比在下几个小节里给出。在IO设备虚拟化上，docker的镜像管理有多种方案，比如利用Aufs文件系统或者Device Mapper实现docker的文件管理，各种实现方案的效率略有不同。
>
> （2）docker利用的是宿主机的内核，而不需要Guest OS。因此，当新建一个容器时，docker不需要和虚拟机一样重新加载一个操作系统内核。我们知道，引导、加载操作系统内核是一个比较费时费资源的过程，当新建一个虚拟机时，虚拟机软件需要加载Guest OS，这个新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统，则省略了这个过程，因此新建一个docker容器只需要几秒钟。另外，现代操作系统是复杂的系统，在一台物理机上新增加一个操作系统的资源开销是比较大的，因此，docker对比虚拟机在资源消耗上也占有比较大的优势。事实上，在一台物理机上我们可以很容易建立成百上千的容器，而只能建立几个虚拟机。

链接：https://zhuanlan.zhihu.com/p/487824422

链接：https://blog.csdn.net/weixin_40391011/article/details/118545349

#### 2、Docker如何访问系统资源？

对边缘设备而言，在支持容器化运行的条件下，需要在容器内获取宿主机的硬件资源，完成与宿主机硬件资源的交互。通常在宿主机提供驱动的情况下，容器内需要通过SPI、I2C、[UART](https://so.csdn.net/so/search?q=UART&spm=1001.2101.3001.7020)、USB等协议完成数据的交互。

linux下以host模式启动 

**--net=host 很关键，加入此参数即可访问宿主机资源**，如mysql数据库

如：docker run --net=host -d test_app:test_tap

挂载目录

**-v /opt/demo/test:/opt/demo/test 将宿主主机的/opt/demo/test目录挂载到容器的/opt/demo/test目录**

如：docker run --net=host -v /opt/demo/test:/opt/demo/test -it demo:test

链接：http://events.jianshu.io/p/1a9d9a381bb6

### Nacos

`Nacos`配置中心的几个核心概念：`dataId`、`group`、`namespace`，它们的层级关系如下图：

<img src="asset\Nacos配置中心.png" alt="图片" style="zoom: 50%;" />

`dataId`：是配置中心里最基础的单元，它是一种`key-value`结构，`key`通常是我们的配置文件名称，比如：`application.yml`、`mybatis.xml`，而`value`是整个文件下的内容。目前支持`JSON`、`XML`、`YAML`等多种配置格式。

`group`：dataId配置的分组管理，比如同在dev环境下开发，但同环境不同分支需要不同的配置数据，这时就可以用分组隔离，默认分组`DEFAULT_GROUP`。

`namespace`：项目开发过程中肯定会有`dev`、`test`、`pro`等多个不同环境，`namespace`则是对不同环境进行隔离，默认所有配置都在`public`里。

#### 1、Nacos的配置更新策略

`nacos`采用的是客户端主动拉`pull`模型，应用长轮询（`Long Polling`）的方式来获取配置数据。

**长轮询**

长轮询可不是什么新技术，它不过是由服务端控制响应客户端请求的返回时间，来减少客户端无效请求的一种优化手段，其实对于客户端来说与短轮询的使用并没有本质上的区别。

客户端发起请求后，服务端不会立即返回请求结果，而是将请求挂起等待一段时间，如果此段时间内服务端数据变更，立即响应客户端请求，若是一直无变化则等到指定的超时时间后响应请求，客户端重新发起长链接。

<img src="asset\长轮询.png" alt="图片"  />

链接：https://mp.weixin.qq.com/s/94ftESkDoZI9gAGflLiGwg

#### 2、Nacos如何避免读写冲突

并发写冲突通过对相同的 `service` 服务加锁 `synchronized(service)` 解决。

基于 `Copy on write` 思想解决读写冲突。

Nacos在更新实例列表的时候，采用 **CopyOnWrite** 思想，将传入的实例列表 List<Instance> ips 与旧的实例列表比对，分别得出需要添加、更新、和删除的实例，然后做一些相关的操作，得到最终新实例列表并替换原来的旧实例列表。

更新过程中的旧实例列表不受影响，客户端依然可以读取，更新完成后才能读取到新实例列表。
————————————————
原文链接：https://blog.csdn.net/Anenan/article/details/125763247

### 系统设计

#### 1、高并发系统设计的三大原则

- **高性能** ：系统的处理请求的速度很快，响应时间很短。
  - 数据库 
    - 分库分表&读写分离
    - NoSQL
    - SQL优化
  - 缓存
  - 消息队列 （待重构）
  - 负载均衡
  - 池化技术
  - 零拷贝
  - ......
- **高可用** ：系统几乎可以一直正常提供服务。也就是说系统具备较高的无故障运行的能力。
  - 限流
  - 降级
  - 熔断
  - 排队
  - 集群
  - 超时和重试机制
  - 灾备设计
  - 异地多活
- **可扩展** ：流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双 11 活动、明星离婚、明星恋爱等热点事件。
  - 分层架构：面向流程拆分
  - SOA、微服务：面向服务拆分
  - 微内核架构：面向功能拆分

[实现高并发秒杀的几种方式](https://mp.weixin.qq.com/s/c8DhRLDkcvyk1Tdb5RIO6g)

[如何设计一个高并发系统，这篇文章告诉你](https://blog.csdn.net/Liu_csdn_csdn/article/details/129908655)

[Java服务限流算法的6种实现](https://www.jb51.net/article/284213.htm)

[java通过信号量实现限流](https://www.jb51.net/program/29064675b.htm)

#### 2、灰度发布

**灰度发布的思想就是先分配一小部分请求流量到新版本，看看有没有问题，没问题的话，再一点点地增加流量，最终让所有流量都切换到新版本。**

灰度发布是能够平滑过渡的一种发布方式，灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。

光有灰度发布还不够，如果在灰度发布过程中（灰度期）发现了新版本有问题，我们还需要有**回滚机制**来应对。类似于数据库事务回滚，系统发布回滚就是将新版本回退到老版本。

回滚通常的做法是怎样的呢？

1. 提前备份老版本，新版本遇到问题之后，重新部署老版本。
2. 同时部署一套新版本，一套旧版本，两者规模相同新版本出问题之后，流量全部走老版本（蓝绿发布）。

不过， 灰度发布和回滚也不是银弹，毕竟计算机世界压根不存在银弹。在一些要求非常严格的系统（如交易系统、消防系统、医疗系统）中，灰度发布和回滚使用不当就会带来非常严重的生产问题。

#### 3、设计一个抢红包系统

https://mp.weixin.qq.com/s/VG_Wcxte8avnXzn4bPXiGA

#### 4、什么是 PV、UV？

1、PV(访问量)：即Page View, 具体是指网站的是页面浏览量或者点击量；

2、UV(独立访客)：即Unique Visitor，访问您网站的一台电脑客户端为一个访客。根据IP地址来区分访客数，在一段时间内重复访问，也算是一个UV；UV价值=销售额/访客数。意思是每位访客带来多少销售额；UV价值越大，产品越迎合消费者需求，只有一定的推广投入才会带来相对应的UV；

#### 5、秒杀系统的核心瓶颈？

秒杀系统的核心瓶颈主要包括以下几个方面：

1. 数据库性能：秒杀系统需要处理大量的用户请求，因此数据库的读写性能必须足够高，以确保能够及时地处理用户的请求。在高并发的场景下，常常会出现数据库连接池满或者死锁等问题，导致系统响应变慢或者崩溃。

2. 网络延迟：由于秒杀活动通常是全国范围内的，并且参与人数众多，因此网络延迟也是一个非常重要的因素。如果网络延迟过大，用户可能无法及时收到最新的抢购结果，从而导致抢购失败。

3. 系统资源限制：秒杀系统需要占用大量的系统资源，包括CPU、内存、带宽等等。如果系统资源不足，可能会导致系统负载过高，甚至崩溃。

4. 安全性：秒杀系统往往会吸引大量的黑客攻击，例如DDoS攻击、爬虫攻击等等。如果系统安全性不高，可能会被攻击者攻陷，导致系统瘫痪或者数据泄漏。

综上所述，秒杀系统的核心瓶颈是数据库性能和网络延迟，如果解决不好这两个问题，就很难保证秒杀系统的正常运行和稳定性。同时，也需要考虑系统资源限制和安全性等方面的因素。

#### 6、给你一个系统，后台的逻辑已经实现了，但是前端加载很慢，怎么检测？

为了检测一个系统中前端加载的速度慢的问题，可以采取以下几个步骤：

1. 使用开发者工具：在现代浏览器中，使用开发者工具可以很容易地检查网站或应用程序的性能。在开发者工具中，可以使用Network选项卡来检查每个文件的加载时间，从而找出哪些文件会导致前端加载缓慢。
2. 测试网站或应用程序：使用网站或应用程序并测试它们的响应时间和加载速度是另一个确定前端加载速度慢的方法。尝试访问不同页面，并注意页面之间的切换速度和加载时间。
3. 使用PageSpeed Insights：PageSpeed Insights是Google提供的一款免费工具，可用于检测网站的性能和速度问题。该工具会分析网站的各个方面，包括前端加载速度、图片优化、代码压缩等，并给出改进建议。
4. 检查前端代码：有时候，前端加载速度慢可能是因为前端代码中存在错误或低效的代码。检查前端代码并进行修复可以帮助提高加载速度。
5. 优化图片：图片通常是前端加载速度变慢的罪魁祸首。通过使用适当的格式（如WebP）和压缩图像，可以减少图像文件的大小，从而改善前端加载速度。

#### 7、如何提高一个接口的吞吐量？

以下是提高接口吞吐量的一些方法：

1. 优化代码：通过对代码进行调试和优化，减少不必要的计算和I/O操作，提高代码效率，从而提高接口吞吐量。

2. 使用缓存：将常用数据缓存在内存中或者使用分布式缓存（例如Redis），可以避免频繁访问数据库，提高数据读取效率。

3. 负载均衡：通过负载均衡技术将请求分发到多个服务器上处理，有效地提高了系统的吞吐量。

4. 异步处理：使用异步处理技术（如Future、Promise、CompletableFuture等）可以避免阻塞等待结果，提高线程利用率，进而提高系统吞吐量。

5. 数据库优化：对数据库进行索引优化、SQL语句优化等操作，可以减少数据库访问时间，提高数据处理效率。读写分离、分库分表。

6. 并发控制：通过锁机制、CAS等技术，保证并发访问时的数据安全性，避免数据冲突，提高系统吞吐量。

7. CDN加速：使用CDN加速服务，将静态资源（如图片、视频等）缓存在离用户最近的节点上，可以提高访问速度，减轻服务器压力，提高系统吞吐量。

总之，提高接口吞吐量需要从多个方面进行考虑和优化，综合使用多种技术手段可以达到更好的效果。

#### 8、登陆业务中，同时来了两个相同的号码进行登陆注册，如何避免？

为了避免同时来了两个相同的号码进行登陆注册，可以考虑以下几种方案：

1. 验证手机号唯一性：在用户进行注册时，通过后台数据库验证该手机号是否已经被注册，如果已经被注册，则提示用户该手机号已经被注册。

2. 防止重复提交表单：在前端添加防止重复提交表单的功能，防止用户重复点击注册按钮，导致多次提交注册请求。

3. 用户注册时需要输入验证码：在用户进行注册时，要求用户输入验证码，确保用户是真实的，并且可以防止机器人自动注册。

4. 使用短信验证：在用户进行注册时，通过短信验证身份，确保用户使用的手机号是真实有效的，并且只能使用一个手机号进行注册。

5. 数据库级别的唯一索引：在数据库中建立一个唯一索引，确保每个手机号只能注册一次。当有第二个相同的手机号进行注册时，数据库会自动拒绝注册请求。

以上几种方案可以单独或者结合使用，从而达到防止同时来了两个相同的号码进行登陆注册的效果。

#### 9、Java业务系统中统计大数据量的总金额应该使用什么方案？

Java业务系统中统计大数据量的总金额，可以考虑使用以下两种方案：

1. 基于数据库的聚合查询：在数据库中存储销售数据，并使用SQL语句进行聚合查询。例如，可以编写类似于“SELECT SUM(amount) FROM sales WHERE date >= '2023-04-01' AND date <= '2023-04-20'”的SQL语句来查询指定日期范围内的销售总额。

2. 基于分布式计算框架的数据处理：使用分布式计算框架（如Hadoop、Spark等）对销售数据进行处理和计算。这种方案适用于数据量非常大的情况，可以利用分布式计算框架的优势，实现并行计算和高效处理。具体实现需要根据实际业务需求和数据特点进行选择。

综上所述，针对Java业务系统中需要统计大数据量的总金额，可以选择基于数据库的聚合查询或基于分布式计算框架的数据处理方案。具体选择需要根据实际情况进行权衡和判断。

#### 10、100个商品，1亿个人抢购，Redis可以接住吗？

Redis可以接住这样的高并发请求，但需要根据具体情况进行调优和优化。以下是一些可能需要考虑的方面：

1. 内存大小：Redis是基于内存缓存的，需要根据实际业务数据量和并发量来配置Redis的内存大小。如果内存不足，会导致性能下降或出现错误。

2. Redis集群：对于大规模应用场景，可以选择使用Redis集群来提高并发处理能力。Redis集群可以分摊负载，提高可用性和容错性。

3. 数据模型设计：合理的数据模型设计可以提高Redis的读写效率，例如使用哈希表等数据结构来存储商品信息。

4. 缓存策略：针对高并发场景，可以采用逐出策略或淘汰策略来控制缓存空间的使用，防止出现OOM（Out of Memory）错误。

综上所述，Redis可以接住100个商品、1亿人的抢购请求，但需要根据实际情况进行调优和优化。

#### 11、如果每秒一千个登录请求如何处理？

每秒一千个登录请求是一个相当高的并发量，对于系统的性能和稳定性都是一个挑战。在这种情况下，可以采用以下优化方案来提高系统的并发处理能力：

1. 使用缓存：在系统中使用缓存来存储用户的登录信息，避免每次都去访问数据库。可以选择Redis等内存数据库作为缓存，使用LRU算法进行缓存逐出。

2. 分布式部署：将系统进行分布式部署，使用负载均衡器（如Nginx）来实现请求的分发和负载均衡。这样可以将请求分散到多个服务器上，减轻单台服务器的负担。

3. 应用程序优化：对于应用程序进行一些优化，例如使用连接池来管理数据库连接、使用线程池来管理线程等，能够提高系统的并发处理能力。

4. 使用消息队列优化：将登录信息预先发送到队列当中进行削峰限流，后台启动一个线程池去异步处理登录请求，这样就可以避免瞬间高并发对系统造成的冲击。

5. 数据库优化：对于数据库进行一些优化，例如建立索引、使用分表分库等，可以提高数据库的查询效率和承载能力。

6. 合理设置超时时间：对于登录请求设置合理的超时时间，防止因请求过多或响应时间过长导致系统负荷过大。

综合以上几点，可以有效地提高系统的并发处理能力，保证系统的性能和稳定性。

#### 12、分布式链路跟踪系统架构

一个请求经过了这些服务后其中出现了一个调用失败的问题，只知道有异常，但具体的异常在哪个服务引起的就需要进入每一个服务里面看日志，这样的处理效率是非常低的。

![img](https://images2018.cnblogs.com/blog/273387/201805/273387-20180503114828367-447292513.png)

[各大厂分布式链路跟踪系统架构对比](http://www.taodudu.cc/news/show-142986.html?action=onClick)

[分布式链路追踪系统原理](http://www.taodudu.cc/news/show-148038.html?action=onClick)

[分布式链路跟踪解决方案](https://zhuanlan.zhihu.com/p/596188935)

#### 13、服务降级和熔断

服务降级和服务熔断是在分布式系统中常用的容错机制，它们的目的都是防止故障扩散和提高系统的可用性，但它们有一些区别。

服务降级（Service Degradation）是指在面对系统资源紧张、性能下降或故障情况时，主动降低某些服务的质量或功能，以保证核心功能的可用性。通过牺牲次要功能或给用户提供更简化的服务，来减少系统负载或响应时间，从而避免整个系统的崩溃。服务降级是一种可控的降低服务质量的策略，可以根据具体情况进行调整，以平衡系统的可用性和性能。

服务熔断（Service Circuit Breaking）是一种自动触发的容错机制，用于预防因依赖服务不可用导致的系统雪崩效应。当依赖的服务出现故障或超时时，服务熔断器会快速返回错误响应，而不是继续请求该服务。当错误请求达到一定阈值时，服务熔断器将进入开路状态，此时后续的请求将直接失败，不再访问依赖的服务，从而保护整个系统的稳定性。服务熔断是一种自动断开与故障服务的连接，并提供快速失败响应的机制，以避免资源浪费和请求堆积。

服务降级和服务熔断的区别可以总结如下：

1. 触发方式不同：服务降级是手动或配置触发的，可以根据具体情况人工调整；而服务熔断是自动触发的，根据错误请求的数量或比例来判断是否进入开路状态。

2. 作用范围不同：服务降级更关注在资源紧张或故障情况下保证核心功能的可用性，通常只会针对某些非核心功能进行降级；而服务熔断更关注避免故障扩散和系统雪崩效应，会将整个服务断开。

3. 控制粒度不同：服务降级可以根据具体情况选择性地降低某些服务的质量或功能；而服务熔断是全局的，一旦触发熔断状态，所有请求都会被快速失败。

综上所述，服务降级和服务熔断是两种不同的容错机制，用于不同的场景和目的。服务降级更注重保证核心功能的可用性，而服务熔断则更注重防止故障扩散和系统雪崩效应。

[服务降级方案](https://www.maro.ink/2018/06/08/fu-wu-jiang-ji-fang-an/)

[服务熔断处理](https://gudaoxuri.gitbook.io/microservices-architecture/wei-fu-wu-hua-zhi-ji-shu-jia-gou/services-circuit)

#### 14、资源隔离

资源隔离是指在计算机系统中，对不同的应用程序或用户之间分配和管理资源，以保证它们互不干扰、相互隔离的技术手段。下面列举了几种实现资源隔离的常见方法：

1. 进程级隔离：将不同的应用程序运行在独立的进程中，每个进程拥有自己独立的内存空间和系统资源，通过操作系统的进程调度和管理来实现资源隔离。

2. 资源池分配：

3. 虚拟化：通过虚拟化技术，将物理资源（如CPU、内存、存储）抽象为多个逻辑资源，并为每个应用程序或用户分配一定数量的逻辑资源，从而实现资源隔离。常见的虚拟化技术包括虚拟机（VM）和容器（Container）。

   - 虚拟机：利用虚拟机监控程序（如VMware、VirtualBox等），将物理服务器划分为多个独立的虚拟机，每个虚拟机都运行着完整的操作系统和应用程序，各自具有独立的资源。每个虚拟机之间互不干扰，实现了资源的隔离。

   - **容器**：利用容器化技术（如Docker、Kubernetes等），将应用程序及其依赖的所有组件封装在一个独立的容器中。容器之间共享操作系统内核，但每个容器都拥有自己独立的文件系统、网络和进程空间，实现了资源的隔离。

4. 权限管理：通过权限管理机制，对不同用户或应用程序进行权限的限制和划分，以确保资源的安全和隔离。例如，操作系统可以通过访问控制列表（ACL）或角色基于访问控制（RBAC）来管理用户对文件和资源的访问权限。

5. 资源配额：通过设置资源配额，限制每个应用程序或用户能够使用的资源数量。例如，可以设置CPU利用率、内存使用量、存储空间等资源的配额，防止一个应用程序占用过多的资源而影响其他应用程序的正常运行。

6. 网络隔离：通过网络隔离技术，将不同的应用程序或用户隔离在不同的网络环境中，避免彼此之间的干扰和攻击。常见的网络隔离方式包括虚拟局域网（VLAN）、子网划分、防火墙等。

这些方法可以单独或结合使用，根据具体场景和需求选择合适的资源隔离策略来保证系统的安全性、稳定性和可靠性。

#### 15、如何在服务不停机的情况下去升级服务？

在服务不停机的情况下进行服务升级，通常可以采用以下几种方法：

1. 平滑升级：先启动新版本的服务实例并让其与旧版本服务并存一段时间，等待新服务实例初始化完成并达到稳定状态后再逐步将流量切换到新服务实例上。在整个升级过程中，旧版本服务实例会逐渐退出操作，并且可以随时回滚至旧版本服务。这种方式需要人工监控整个升级过程，保证升级期间服务的稳定性和可靠性。

2. 蓝绿部署：将服务部署在两个完全相同的环境中（蓝色环境和绿色环境），其中一个环境运行旧版本服务，另一个运行新版本服务。在升级时，先将流量切换至新版本服务部署的环境中，等待新服务实例初始化并达到稳定状态后再将流量全部切换至新版本服务。在整个升级过程中，只需切换流量即可，不需要手动干预，因此该方式更为自动化和可靠。

3. 滚动升级：逐步升级服务，将部分请求路由到新版本服务中，剩余请求继续路由至旧版本服务。在新版本服务表现良好且稳定后，逐步增加新版本服务的请求比例，直至全部流量都路由至新版本服务。在整个升级过程中，可以对新版本服务进行监控和回滚，保证升级期间服务的稳定性和可靠性。

需要注意的是，在进行服务升级时，要保证服务的稳定性和可用性，尽量减少用户感知到的影响。此外，为了更好地保障安全性，建议在升级前备份所有数据，以便在出现问题时快速回滚至原来的状态。

#### 系统设计列表

[如何从零搭建10万级 QPS 大流量、高并发优惠券系统](https://mp.weixin.qq.com/s/iZ9BX6cCCp_TB-SC3knuew)

[vivo 全球商城：优惠券系统架构设计与实践](https://www.cnblogs.com/vivotech/p/15117264.html)

[你会设计交易系统吗(概念篇)？](https://juejin.cn/post/6844903794099273742)

[你会设计交易系统吗(实干篇)？](https://juejin.cn/post/6844903800340217864)

[2022 春节抖音视频红包系统设计与实现](https://mp.weixin.qq.com/s/IMfVI7rdcTun3DK1wbqOQw)

[微信红包的技术原理是怎样的？](https://www.zhihu.com/question/22623475/answer/2541075908?utm_id=0)

[如何设计百万人抽奖系统](https://mp.weixin.qq.com/s/4OqYCnEV3xTmXYGT2w7ltg)

[如何设计一个百万级用户的抽奖系统？](https://juejin.cn/post/6844903847031226382)

### 智力题

[牛客智力题汇总](https://www.nowcoder.com/discuss/353157075649896448)

[拓跋阿秀智力题汇总](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html)

> - 1、三人三鬼过桥
> - 2、赛马找最快的马匹（腾讯高频题）
> - 3、给定随机函数，生成别的随机数
> - 4、砝码称轻重，找出最轻的
> - 5、利用空瓶换饮料，最多喝几瓶
>   - [第一种思路](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html#第一种思路)
>   - [第二种思路](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html#第二种思路)
> - 6、毒药毒白鼠，找出哪个瓶子中是毒药
>   - [参考回答](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html#参考回答)
> - 7、利用烧绳子计算时间
> - 8、在24小时里面时针分针秒针可以重合几次
> - 9、100个奴隶猜帽子颜色
> - 10、 小猴子搬香蕉
> - 11、高楼扔鸡蛋（经典问题）
>   - [1、暴力法](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html#_1、暴力法)
>   - [2、二分法](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html#_2、二分法)
>   - [3、均匀法](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html#_3、均匀法)
>   - [4、最优解法](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html#_4、最优解法)
> - 12、N只蚂蚁走树枝，问总距离或者总时间
> - 13、N个强盗分配M个金币，求方案使得自己分配最多
> - 14、火枪手决斗，谁活下来的概率大？
> - 15、先手必胜的问题
> - [16、掰巧克力问题或者参加辩论赛](https://interviewguide.cn/notes/03-hunting_job/02-interview/06-intelligence.html#_16、掰巧克力问题或者参加辩论赛)

#### 1、64匹马，8个跑道，选最快的4匹马，最少需要比赛几次？

​		最少需要10次或11次。

#### 2、100瓶饮料中有1瓶毒药，最少需要几只老鼠能测试出来？

7只，因为2^7=128>100

​		例如：4瓶一瓶毒，需要两只，分别喝1，2和2，3，判断老鼠状态：00，01，10，11.（用二进制代表不同老鼠喝完之后的毒药）

​		https://view.inews.qq.com/k/20220105A04YJT00?web_channel=wap&openApp=false&pgv_ref=baidutw

#### 3、有20个外观一样的硬币，其中有一个假币比真币要重些。用天平称的办法去找，至少几次能保证假硬币找出来?

先把20个硬币分成(7,7,6),把两个7个一组的放在天平上称,可找出有假币的一组,再把7分成(3,3,1),可找出有假币的一组,再把3分成(1,1,1)，可找出假币，需3次；

如假币在6个一组里,则把6分成(2,2,2),把两个2个一组的放在天平上称,可找出假币一组,再把2成(1,1)，可找出假币，需3次；

所以用天平称，至少称3次能保证找出次品硬币。

#### 4、10瓶药，一瓶是假药，所以重一点，每瓶装了很多粒药，给电子称，如何一次找出假药？

将10瓶药编好号，第1号取一粒，第2号取2粒，第三号取3粒....第10号取10粒，用天秤称得重量为x，用x-550得出的结果是那瓶假药。

（标上序号,1--10,依次从10瓶药中,取出不等量的药品（十分之一、十分之二``````）,把取出的药品称一下,根据结果就可以找到不合格的药.）

#### 5、一条不均匀的绳子烧完要一小时,怎么用绳子算出一小时十五分钟？

要3根绳子
第一条点一头,第二条两头一起点着,两条同时点.
等第二条绳子烧完时,（已过半小时）马上将第一条绳子的没点着的一端也点着.
等第一条绳子烧完时,（又过了15分钟）马上将第三条绳子的两端点着.
等第三条绳子烧完时,（又过了半小时）
总共1小时15分钟.

#### 6、5L的瓶子和4L的瓶子如何装出3L的水？

**通用解法： 用小的桶不断往大桶填水**

1、首先先将4L的瓶子装满水，然后将水倒进5L的瓶子

2、然后再将4L的瓶子装满再倒满5L的瓶子，此时4L的瓶子里刚好剩下3L水。

#### 7、5L的瓶子和3L的瓶子如何装出4L的水？

方案一：

1、首先先将5L的瓶子装满水，然后导入3L的瓶子里，此时5L的瓶子里剩下2L的水；

2、然后倒空3L的瓶子，再将5L的瓶子里的水倒入3L的瓶子；

3、然后再装满5L的水，再将3L的瓶子倒满，此时，5L的瓶子里剩下4L水。

方案二：

通用解法： 用小的桶不断往大桶填水

1、用3升的杯子装满水倒入5升的杯子

2、再用3升的杯子装满水将5升的杯子装满,这时3升的杯子里还剩下1升水

3、将5升杯子里的水倒掉,将那1升水倒入5升的杯子,然后用3升的杯子装满水再倒入5升的杯子里,这时候就有4升水啦

#### 8、高楼扔鸡蛋问题

有2个鸡蛋，从100层楼上往下扔，以此来测试鸡蛋的硬度。比如鸡蛋在第9层没有摔碎，在第10层摔碎了，那么鸡蛋不会摔碎的临界点就是9层。

问：如何用最少的尝试次数，测试出鸡蛋不会摔碎的临界点？

**假设第一次扔在第x层：**

如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x-1层。

这样一来，我们总共尝试了x-1+1 = x次，刚刚好没有超出假设次数。

因此，要想尽量楼层跨度大一些，又要保证不超过假设的尝试次数x，那么第一次扔鸡蛋的最优选择就是第x层。

那么算最坏情况，第二次你只剩下x-1次机会，按照上面的说法，你第二次尝试的位置必然是X+（X-1）；

以此类推我们可得：

x + (x-1) + (x-2) + ... + 1 = 100

这个方程式不难理解：

左边的多项式是各次扔鸡蛋的楼层跨度之和。由于假设尝试x次，所以这个多项式共有x项。（其中 `x+(x-1)` 是当第一个鸡蛋在 `x` 层没碎时，此时第二次扔的位置为x + (x - 1)，因为只剩下x-1次机会，这样第一个鸡蛋用了2次，第二个鸡蛋就必须在x-2次数测出）。

右边是总的楼层数100。

下面我们来解这个方程：

x + (x-1) + (x-2) + ... + 1 = 100 转化为

(x+1)*x/2 = 100

最终x向上取整，得到 x = 14

因此，最优解在最坏情况的尝试次数是14次，第一次扔鸡蛋的楼层也是14层。

最后，让我们把第一个鸡蛋没碎的情况下，所尝试的楼层数完整列举出来：

14，27， 39， 50， 60， 69， 77， 84， 90， 95， 99， 100

> 第一个鸡蛋扔的次数 + 第二个鸡蛋扔的次数 = x
>
> 1 + 13
>
> 2 + 12
>
> ...
>
> 13 + 1

举个例子验证下：

假如鸡蛋不会碎的临界点是65层，那么第一个鸡蛋扔出的楼层是14，27，50，60，69。这时候啪的一声碎了。

第二个鸡蛋继续，从61层开始，61，62，63，64，65，66，啪的一声碎了。

因此得到不会碎的临界点65层，总尝试次数是 6 + 6 = 12 < 14 。

- 如果第一次扔鸡蛋刚好在第77层碎了，则此时第二个鸡蛋只需要从70-76再扔一遍即可，即14次便能得到答案。

#### 9、一个工人每天需要被支付1/7根金条，工作七天，给一块金条只能切两刀，如何切可以完成？

切成 1/7、2/7和4/7即可。

### 场景题

[海量数据处理面试题](https://interviewguide.cn/notes/03-hunting_job/02-interview/07-01-massive_data.html)

#### 1、在100G文件中找出出现次数最多的100个IP。

​       对于100G的文件，先算算能有多少条IP呢？每条IP最长为15个字节，则100G/15=6.7G条，IP一共有多少种呢，不考虑IPv6，约有       2564=232条=4G条，那么最极端的情况是每种IP都有，每个都出现那么一两条。

​        要解决该问题首先要找到一种分类方式，把重复出现的IP都放到一个文件里面，一共分成100份，这可以通过把IP对100取模得到，具体方法如去掉IP中的点转化为一个long型变量，这样取模为0,1,2…99的IP都分到一个文件了，那么这个分就能保证每一文件都能载入[内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)吗？这可不一定，万一模为9的IP特别多怎么办，可以再对这一类IP做一次取模，直到每个小文件足够载入内存为止。这个分类很关键，如果是随便分成100份，相同的IP被分在了不同的文件中，接下来再对每个文件统计次数并做归并，这个思路就没有意义了，起不到“大而化小，各个击破，缩小规模，逐个解决”的效果了。

​        好了，接下来把每个小文件载入内存，建立[哈希](https://so.csdn.net/so/search?q=哈希&spm=1001.2101.3001.7020)表unordered_map<string,int>，将每个IP作为关键字映射为出现次数，这个哈希表建好之后也得先写入硬盘，因为内存就那么多，一共要统计100个文件呢。

​        在统计完100个文件之后，我再建立一个小顶堆，大小为100，把建立好并存在硬盘哈希表载入内存，逐个对出现次数排序，挑出出现次数最多的100个，由于次数直接和IP是对应的，找出最多的次数也就找出了相应的IP。

​        这只是个大致的算法，还有些细节，比如第90到110大的元素出现次数一样呢，就随机舍弃掉10个吗？整个的时间复杂度分类O(n)，建哈希表O(n)，挑出出现最多次数的O(nlogk)

####  2、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M，要求返回频数最高的100个词。

- **思考过程**

（1）此处1G文件远远大于1M内存，分治法，先hash映射把大文件分成很多个小文件，具体操作如下：读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件(记为f0,f1,…,f4999)中，这样每个文件大概是200k左右（每个相同的词一定被映射到了同一文件中）

（2）对于每个文件fi，都用hash_map做词和出现频率的统计，取出频率大的前100个词（怎么取？topK问题，建立一个100个节点的最小堆），把这100个词和出现频率再单独存入一个文件

（3）根据上述处理，我们又得到了5000个文件，归并文件取出top100（Top K 问题，比较最大的前100个频数）

- **堆排序找Top K**

借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。即借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。所以，我们最终的时间复杂度是：O（N） + N’ * O（logK），（N为1000万，N’为300万）

#### 3、CPU利用率过高如何排查？

通常会收到监控系统告警，相关服务器负载异常，cpu使用率过高

原因：可能是业务代码死循环、GC频繁、线程阻塞等

**问题排查**

1、执行top 命令查看占用cpu最多的Java进程。

```
top
```

2、根据pid找到对应cpu占用最多的Java线程。

```shell
top -Hp 4861
```

3、将10进制线程id转换为16进制。

```sh
[root@node1 ~]# printf '%x\n' 4861
12fd
```

4、通过`jstack` 命令找到对应问题现场堆栈信息。

```sh
jstack 4851|grep 12fd -C 10
```

**解决问题**

对于CPU占用率飙高的场景，刚才列举的测试代码只是一种情况，还有如下可能。

1. 业务线程出现大量阻塞，比如synchronized锁，可以检索状态为BLOCKED的线程找到堆栈信息，然后分析。

2. 网络IO或者磁盘IO阻塞导致的，排查方法和上面一样。

3. GC线程频繁导致，线程的标识为GC task thread，对于这种情况可能是年轻代设置不合理、大对象分配过多，old区存活对象过多，具体问题具体分析。

————————————————
原文链接：https://blog.csdn.net/sinat_32873711/article/details/128157147

链接：https://blog.csdn.net/yunzhonghefei/article/details/89207243

#### 4、10亿int整型数，一台可用内存为1GB的机器，时间复杂度要求O(n)，统计只出现一次的数?

答：首先分析多大的内存能够表示10亿的数呢？一个int型占4字节，10亿就是40亿字节（很明显就是4GB），也就是如果完全读入内存需要占用4GB，而题目只给1GB内存，显然不可能将所有数据读入内存。

>  1GB = 2^10MB = 2^20KB = 2^30B = 1_073_741_824B ≈ 10亿字节

我们先不考虑时间复杂度，仅考虑解决问题。那么接下来的思路一般有两种。

**位图法：**用一个bit位来标识一个int整数。

**分治法：**分批处理这10亿的数。

一种是位图法，如果各位老司机有经验的话很快会想到int整型数是4字节（Byte），也就是32位（bit），如果能用一个bit位来标识一个int整数那么存储空间将大大减少。另一种是分治法，内存有限，我想办法分批读取处理。下面大致分析一下两种思路。

**位图法（Bitmap）**

位图法是基于int型数的表示范围这个概念的，用一个bit位来标识一个int整数，若该位为1，则说明该数出现；若该位为0，则说明该数没有出现。一个int整型数占4字节（Byte），也就是32位（bit）。那么把所有int整型数字表示出来需要2^32 bit的空间，换算成字节单位也就是2^32/8 = 2^29 Byte，大约等于512MB

这下就好办了，只需要用512MB的内存就能存储所有的int的范围数。

<img src="asset\bitmap.png" alt="img" style="zoom:80%;" />

BitMap 表示

(1). 如何判断int数字放在哪一个tmp数组中：将数字直接除以32取整数部分(x/32)，例如：整数8除以32取整等于0，那么8就在tmp[0]上；

(2). 如何确定数字放在32个位中的哪个位：将数字mod32取模(x%32)。上例中我们如何确定8在tmp[0]中的32个位中的哪个位，这种情况直接mod上32就ok，又如整数8，在tmp[0]中的第8 mod上32等于8，那么整数8就在tmp[0]中的第八个bit位（从右边数起）。

然后我们怎么统计只出现一次的数呢？每一个数出现的情况我们可以分为三种：0次、1次、大于1次。也就是说我们需要用2个bit位才能表示每个数的出现情况。此时则三种情况分别对应的bit位表示是：`00、01、11`

我们顺序扫描这10亿的数，在对应的双bit位上标记该数出现的次数。最后取出所有双bit位为01的int型数就可以了。

**分治法**

分治法目前看到的解决方案有哈希分桶（Hash Buckets）和归并排序两种方案。

哈希分桶的思想是先遍历一遍，按照hash分N桶（比如1000桶），映射到不同的文件中。这样平均每个文件就10MB，然后分别处理这1000个文件，找出没有重复的即可。一个相同的数字，绝对不会跨文件，有hash做保证。因为算法具体还不甚了解，这里先不做详细介绍。
————————————————
原文链接：https://blog.csdn.net/qq_35290785/article/details/98672144

### 算法

#### 1、O(n)和o(n)的区别？

> O(g(n)): 是增长次数小于等于g(n)的函数集合
>
> Θ (g(n)): 是增长次数等于g(n)的函数集合
>
> Ω(g(n)):  是增长次数大于等于g(n)的函数集合

O(n) 和 o(n) 都是算法复杂度的概念，表示算法执行时间随输入规模 n 的增加而变化的趋势。

O(n) 表示算法的最坏时间复杂度在 n 的规模下是线性增长的，也就是说，当输入规模为 n 时，算法的执行时间最多是 n 的某个常数倍，比如 2n、3n、4n 等等。其中，O 是一个上限符号，表示“不超过”。

o(n) 则表示算法的最坏时间复杂度在 n 的规模下是小于线性增长的，也就是说，当输入规模为 n 时，算法的执行时间最多是 n 的某个常数倍与一个小于 1 的常数的乘积，比如 0.5n、0.8n 等等。其中，o 是一个下限符号，表示“小于”。

简单来说，O(n) 和 o(n) 都表示算法的时间复杂度是线性级别的，但是 O(n) 还允许有常数因子的存在，而 o(n) 不允许存在常数因子，因此 o(n) 更加严格。

> T(n) = aT(n/b) + f (n)        f (n) ∈ Θ(nd) 
>
> 1. a < b^d              T(n) ∈ Θ(nd) 
> 2. a = b^d              T(n) ∈ Θ(nd lg n ) 
> 3. a > b^d              T(n) ∈ Θ(nlog b a) 
>
> 快排：T(n)=2T(n/2)+n => T(n)∈Θ(nlogn)

#### 2、判断一个点是否在指定区域内？

第一种是**射线法**，算法思想非常巧妙：从待判断的点向某一个方向引射线，计算和多边形交点的个数，如果个数是偶数或者0则点在多边形外，如果是奇数，则在多边形内，如下图：

<img src="asset\射线法.png" alt="img" style="zoom:80%;" />

两种特殊情况：

> 1. 射线经过顶点：当射线经过顶点时，判断就会出现异常情况。
> 2. 点在边上：这种情况也不能用交点个数的奇偶性来判断了，要快速地判断这个点是否在边上。

具体算法步骤：

> // 判断依据：求解从该点向右发出的水平线射线与多边形各边的交点，当交点数为奇数，则在内部
>         //不过要注意几种特殊情况：1、点在边或者顶点上;2、点在边的延长线上;3、点出发的水平射线与多边形相交在顶点上
>         /**
>         * 具体步骤如下：
>                 * 循环遍历各个线段：
>                 *  1、判断点是否在当前边上(斜率相同,且该点的x值在两个端口的x值之间),若是则返回true
>                         *  2、否则判断由该点发出的水平射线是否与当前边相交,若不相交则continue
>                         *  3、若相交,则判断是否相交在顶点上(边的端点是否在给定点的水平右侧).若不在,则认为此次相交为穿越,交点数+1 并continue
>                                 *  4、若交在顶点上,则判断上一条边的另外一个端点与当前边的另外一个端点是否分布在水平射线的两侧.若是则认为此次相交为穿越,交点数+1.
>                                 */
> 原文链接：https://blog.csdn.net/qq_25800311/article/details/83116338

值得一提的是射线法对于带岛的多边形依然有效：

<img src="asset\带岛屿的多边形.png" alt="img" style="zoom:80%;" />

改进：传统的射线法一开始就直接计算点和多边形的交点个数，这样的话，会花费大量的时间来作拓扑关系的判断，我们可以首先计算出最小外包矩形，迅速排除不在矩形内部的点，然后再做上面的判断。

![img](asset\闭合路线.png)

我们可以把多边形可以看做是一条从某点出发的闭合路，可以观察到在内部的点永远都在路的同一边。

给定线段的两个点P0(x0,y0)和P1(x1,y1)，目标点P(x,y),它们有如下的关系

```java
(y - y0) (x1 - x0) - (x - x0) (y1 - y0)
```

如果答案小于0则说明P在线段的右边，大于0则在左边，等于0说明在线段上。

除了上面两种，还有很多方法

比如**面积法**：就是计算所有边和目标点组成的三角形面积和是否等于总的多边形面积，如果相等，则点在该区域的内部。

这种方法计算量较大，多边形的面积计算也是比较麻烦；

还有**夹角法**：判断所有边和目标点的夹角和是否为360度，计算量同样很大。

https://blog.csdn.net/brilliantyoho/article/details/17681091

#### 3、排序算法

排序大的分类可以分为两种：内排序和外排序。放在内存的称为内排序，需要使用外存的称为外排序。

排序算法的[时间复杂度](https://so.csdn.net/so/search?q=时间复杂度&spm=1001.2101.3001.7020)和空间复杂度

| **排序算法**     | **平均时间复杂度** | **最坏时间复杂度** | **最好时间复杂度** | **空间复杂度** | **稳定性** |
| ---------------- | ------------------ | ------------------ | ------------------ | -------------- | ---------- |
| **冒泡排序**     | O(n²)              | O(n²)              | O(n)               | O(1)           | 稳定       |
| **直接选择排序** | O(n²)              | O(n²)              | O(n)               | O(1)           | 不稳定     |
| **直接插入排序** | O(n²)              | O(n²)              | O(n)               | O(1)           | 稳定       |
| **快速排序**     | O(nlogn)           | O(n²)              | O(nlogn)           | O(nlogn)       | 不稳定     |
| **堆排序**       | O(nlogn)           | O(nlogn)           | O(nlogn)           | O(1)           | 不稳定     |
| **希尔排序**     | O(nlogn)           | O(ns)              | O(n)               | O(1)           | 不稳定     |
| **归并排序**     | O(nlogn)           | O(nlogn)           | O(nlogn)           | O(n)           | 稳定       |
| **计数排序**     | O(n+k)             | O(n+k)             | O(n+k)             | O(n+k)         | 稳定       |
| **基数排序**     | O(N*M)             | O(N*M)             | O(N*M)             | O(M)           | 稳定       |

**注**：

1 归并排序可以通过手摇算法将[空间复杂度](https://so.csdn.net/so/search?q=空间复杂度&spm=1001.2101.3001.7020)降到O(1)，但是时间复杂度会提高。

2 基数排序时间复杂度为O(N*M)，其中N为数据个数，M为数据位数。

链接：https://blog.csdn.net/pange1991/article/details/85460755

#### 4、判断一个圆和矩形是否重叠

链接：https://blog.csdn.net/qq_41685265/article/details/107674368

#### 5、哈夫曼编码

[哈夫曼编码原理与实现](https://mp.weixin.qq.com/s?__biz=MjM5OTEyODg2MA==&mid=2649905579&idx=1&sn=7aeb8eb24ff1fb4c8125d7335b642338&chksm=bec6c3d889b14aceb20a64dba210f7987fbc32707b49a635a143c336c3cbd1d1709d3d1bf9c3&scene=27)

[哈夫曼编码详解](https://blog.csdn.net/m0_57126456/article/details/121040310)

#### 6、AC自动机

AC自动机：https://zhuanlan.zhihu.com/p/146369212?utm_id=0

### 其他

#### 1、总结

项目、实习一定需要总结，背诵下来，项目里有挑战的事情、前因后果、遇到的难点，实习的收获、个人的成长等，这些问题都是高频题，如果提前总结的话，面试的时候可以侃侃而谈，一般面试官问这些问题的时候，我一般就直接讲个 10 分钟，这样面试就过去 1/4 了。

一些原理的介绍，前往不要讲一两句就结束了，能多深入多深入，多发散多发散，多水点面试时长，最好讲到面试官打断你，这样面试绝大部分时间都是被你掌控的。

算法也是，即使你会，也要拖一会，一般拖到个 45min 左右就不会给你出第二个算法题了，这也算一个小技巧？

八股按照 JVM、Java、Mysql、Redis、计网、OS 的优先级（个人根据面试提问频率总结）着重复习。

不知道什么情况，感觉秋招问的比暑期简单一点？可能是实习和项目经历丰富，大部分面试有个二三十分钟都是介绍这个。

链接：https://www.nowcoder.com/discuss/532303076607197184?sourceSSR=users

#### 2、说一说你平时如何学习？

1. 阅读技术书籍和博客文章

我会定期阅读一些技术书籍和博客文章，包括行业内的权威出版物和社区贡献者的文章。这些资源不仅可以帮助我了解最新的技术趋势和最佳实践，而且有助于提高我的问题解决能力和编程技巧。

2. 刻意练习

我认为刻意练习是非常重要的。我会选择一些开源项目或自己的个人项目，然后尝试用新学到的东西来改进它们。这样可以让我在实际应用中掌握更深入的知识，并且可以在错误和挑战中学习。

3. 参加培训课程和技术会议

我也会尽可能多地参加培训课程、技术会议和研讨会等活动，以获取最新的知识和技能。这些活动通常可以提供与其他专业人士交流的机会，从而扩展我的专业网络。

4. 与其他人交流

我认为与其他人交流是一种非常有效的学习方式。我会积极加入技术社区和论坛，与其他开发者交流、分享和讨论。这样可以让我学习到其他人的经验和见解，并且可以扩展我的专业网络。

总之，我认为持续学习非常重要，并且不断尝试新的学习方法可以让自己变得更有创造力和适应性。

#### 2、说下你平时看的一些技术博客，书籍

1. 博客

- 码农翻身：这是一个非常不错的中文开发者博客，作者在其中分享了很多关于Java、Web开发和数据库等方面的经验和技巧。
- InfoQ：这是一个国际性的技术博客，在其中可以找到有关软件开发、架构和DevOps等方面的最新动态和趋势。
- Baeldung：这是一个非常受欢迎的Java技术博客，它提供了很多深入的文章和教程，涵盖了Java生态系统的各个方面。

2. 书籍

- 《Effective Java》：这是由Joshua Bloch编写的一本经典Java编程指南。它提供了大量实用的编程技巧和最佳实践，对于想要成为高水平Java开发人员的人来说是一本必备书籍。
- 《Java并发编程实战》：这是一本非常出色的Java多线程编程指南，它提供了丰富的多线程编程技术和工具，帮助读者学习如何写出安全、高效的多线程程序。
- 《Spring实战》：作为目前最为流行的Java框架之一，Spring框架的使用在日常开发中非常普遍。这本书介绍了Spring框架的各个方面，包括基础知识、高级应用和集成测试等内容。
